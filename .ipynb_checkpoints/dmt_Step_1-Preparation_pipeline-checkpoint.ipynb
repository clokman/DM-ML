{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION\n",
    "\n",
    "If you would like to skip right to data preparation without going through how all the underlying functions, please skip section two.\n",
    "\n",
    "This is a notebook that currently consists of 2 sections:\n",
    "1. **Functions**: Although unconventional in a Jupyter notebook, a preprocessing library were coded and explained in this section. Because the notebook style provides a clear overview of what has been done, this was intended for allowing an easier look under the hood when tuning or debugging of functnnos were needed. Having said that, this section is now converted into an external library and can be found at https://github.com/clokman/DM-ML/tree/master/preprocessor\n",
    "2. **Data preparation**: Formatting and preprocessing of datasets in the project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIST OF CONTENTS\n",
    "  \n",
    "Functions (Preprocessor Package)\n",
    "1. [Functions and testing them on demo data](#functions) \n",
    "\n",
    "Data Preparation\n",
    "1. [Intake data](#intake-data) \n",
    "2. [Daily data](#daily-data) \n",
    "3. [Fitbit data](#fitbit-data)\n",
    "4. [Final steps](#final-steps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Jupyter Usage\n",
    "**IMPORTANT, please read before beginning.**\n",
    "\n",
    "**Common error #1**:<br>\n",
    "\"name VARIBABLE_NAME is not defined. If a cell does not run properly, this is probably due it being dependent on a previous cell, and that previous cell has not been ran by Jupyter kernel yet. In such cases, it is recommended to run all previous cells first, and then trying to run the cell again.\n",
    "\n",
    "**Common error #2**:<br>\n",
    "Something is strange is going on; everything looks right, but it doesn't work. This may be due cells being ran in wrong order. For instance, if you had went back and ran a cell, it may have overwritten a variable that a cell at the end of the notebook may be working with (although the variable names are usually distinct in sections, this could still be an issue within sections). Once again, it is recommended to run all previous cells first (in the right order), and then trying to run the cell again.\n",
    "\n",
    "**How to run all necessary cells in order to satisfy dependencies between them**:<br>\n",
    "- All cells up until the selected cell can be ran by going to \"Cell -> Run all above\".\n",
    "- Multiple cells can also be selected and can be ran at the same time by using the appropriate multiple selection hotkey and then the \"Run\" hotkey (see shortcuts section from Help menu).\n",
    "- Finally, is something seems quite wrong, the best option could be to go to \"Menu -> Kernel -> Restart and Run All\" -- This is generally useful, but does not always produce the right result. \n",
    "- And sometimes the best solution may be to run all the necessary cells manually in a sequential manner.\n",
    "\n",
    "\n",
    "**How to use functions?**\n",
    "I am doing my best to document them as concisely as possilbe. While in the edit mode, **'TAB' key completes function and variable names, and pressing SHIFT+TAB while cursor is 'within' a function shows docstrings (i.e., quick documentation)**. Pressing SHIFT+TAB 2 times will show more a mor detailed tooltip. With these two shortcuts, it should be quite easy to use the homebrewed functions in this notebook without having to go to their source code to understand them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META\n",
    "\n",
    "TODO:\n",
    "- Use classes: Convert functions to methods.\n",
    "- Bug: append_column function only works properly for unique variable names/unique variable lists. If either is entered more than once, it adds header row as a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"functions\"></a>\n",
    "# PART I: FUNCTIONS (PREPROCESSOR PACKAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, a Python package for data manipulation and preprocessing, \"Preprocessor\" is created. Preprocessor package allows datasets to be stored as nested lists and contains various dataset modification functions. Due to its list-based approach, it offers an alternative approach to numpy. <font color=red> As of June 2017, this package is no more updated on this notebook, and its latest version can be found at:</font> https://github.com/clokman/DM-ML/tree/master/preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import demo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo dataset will be used for debugging the functions in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "demo_data = list(csv.reader(open(\"data//original_data//intake-vragenlijst-v2.csv\", encoding=\"utf8\"), delimiter=\";\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split headers and data \n",
    "**get_headers | get_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the set of functions in this project, it is desirable to NOT separate headers row from data. This is taken care of within functions by using the following functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_headers(dataset):\n",
    "    return(dataset[0])\n",
    "\n",
    "def get_data(dataset):\n",
    "    return(dataset[1:len(dataset)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace headers\n",
    "**replace_headers()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: <br>\n",
    "replace_headers(NEW_HEADERS_LIST, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets usually come with automatically generated headers which needs to be replaced with proper ones. This function takes care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_headers(header_replacements, dataset):\n",
    "    # Replace headers with those in the header_replacements list\n",
    "    for i, header in enumerate(header_replacements): \n",
    "            dataset[0][i] = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a list taken from 'survey features.xlsx'        \n",
    "replacements = [\"date\", \"consent\", \"id\", \"sex\", \"age\", \"edu\", \"timezone_change\", \"sleep_disorder\", \"nightshift\", \"psy_disorder\", \"wake\", \"young_kids\", \"partn\", \"btptr_1\", \"btptr_2\", \"btptr_3\", \"btptr_4\", \"btptr_5\", \"btptr_6\", \"btptr_7\", \"btptr_8\", \"btptr_9\", \"ats_1\", \"atbr_1\", \"sq_1\", \"sq_2\", \"sq_3\", \"sq_4\", \"sq_5\", \"sq_6\", \"atbr_2\", \"atbr_3\", \"ats_2\", \"ats_3\", \"chron_1\", \"chron_2\", \"chron_3\", \"chron_4\", \"chron_5\", \"chron_6\", \"chron_7\", \"chron_8\", \"sc_1\", \"sc_2\", \"sc_3\", \"sc_4\", \"sc_5\", \"sc_6\", \"sc_7\", \"sc_8\", \"sc_9\", \"sc_10\", \"sc_11\", \"sc_12\", \"sc_13\"]\n",
    "replace_headers(header_replacements=replacements, dataset=demo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_data headers row:\n",
      "['date', 'consent', 'id', 'sex', 'age', 'edu', 'timezone_change', 'sleep_disorder', 'nightshift', 'psy_disorder', 'wake', 'young_kids', 'partn', 'btptr_1', 'btptr_2', 'btptr_3', 'btptr_4', 'btptr_5', 'btptr_6', 'btptr_7', 'btptr_8', 'btptr_9', 'ats_1', 'atbr_1', 'sq_1', 'sq_2', 'sq_3', 'sq_4', 'sq_5', 'sq_6', 'atbr_2', 'atbr_3', 'ats_2', 'ats_3', 'chron_1', 'chron_2', 'chron_3', 'chron_4', 'chron_5', 'chron_6', 'chron_7', 'chron_8', 'sc_1', 'sc_2', 'sc_3', 'sc_4', 'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'sc_12', 'sc_13']\n",
      "\n",
      "demo_data:\n",
      "['2017/04/01 8:35:57 p.m. EET', 'Ja, ik neem deel', 'EM11', 'Vrouw', '44', 'HBO', 'Nee', 'Nee', 'Nee', 'Nee', 'Ja', 'Nee', 'Soms', 'soms', '(bijna) altijd', '(bijna) altijd', 'soms', '(bijna) nooit', 'soms', '(bijna) altijd', '(bijna) nooit', '(bijna) altijd', '(bijna) nooit', '(bijna) nooit', 'binnen een kwartier', 'nooit', 'nooit', 'nooit', 'een beetje', 'erg goed', '(bijna) nooit', '(bijna) nooit', 'vaak', '(bijna) altijd', 'helemaal eens', 'helemaal oneens', 'helemaal oneens', 'helemaal eens', 'oneens', 'helemaal eens', 'helemaal eens', 'helemaal oneens', 'even vaak eens als oneens', 'even vaak eens als oneens', 'helemaal oneens', 'helemaal oneens', 'oneens', 'eens', 'even vaak eens als oneens', 'eens', 'oneens', 'eens', 'even vaak eens als oneens', 'even vaak eens als oneens', 'oneens']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"demo_data headers row:\\n\" + str(demo_data[0]))\n",
    "print(\"\\ndemo_data:\\n\" + str(demo_data[1]) + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting columns based on their header names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions requires data headers and data to be split beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find column/index of a given header\n",
    "**get_header_index()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:<br>\n",
    "get_header_index(HEADER_NAME_STRING, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a get_header_index function needs to be built in order to match header name to an index number in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_header_index(header_query, dataset):\n",
    "    headers = get_headers(dataset)\n",
    "    # find index number of given keyword header_name in demo_data headers\n",
    "    current_index = 0\n",
    "    if header_query in headers:     # if the keyword is in headers list\n",
    "        for header in headers:      # iterate over headers list\n",
    "            if header != header_query:   # until the query is matched\n",
    "                current_index += 1       # keep incrementing index counter\n",
    "            else: \n",
    "                return current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_header_index(\"edu\", demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select a column with its name \n",
    "**select_column()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:<br>\n",
    "select_column(HEADER_NAME, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that the corresponding index position of a given header can be found in the data... \n",
    "- Columns can be selected (i.e., returned) by entring their header names.\n",
    "- requires: get_header_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_column (header_query, dataset):\n",
    "    headers = get_headers(dataset)\n",
    "    data = get_data(dataset)\n",
    "    \n",
    "    if header_query not in headers: # if the queried keyword is not in the headers list, return error \n",
    "        print(\"ERROR: Header not found in dataset.\\nError occured while processing header_query: \"+ header_query)\n",
    "        raise ValueError('String not found in headers. Please enter a different column name. (See console output for last processed input string.)')\n",
    "\n",
    "    header_index = get_header_index(header_query, dataset)\n",
    "    column = [row[header_index] for row in data]   # assign the column matching the current_index from headers list to a variable\n",
    "    return column                 # return the column sans header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HBO', 'WO', 'WO', 'WO', 'WO', 'HBO', 'HBO', 'WO', 'WO', 'MBO', 'WO']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function:        \n",
    "select_column(\"edu\", demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print a column line by line\n",
    "**print_columns()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_column_vertically(target_column_name, dataset):\n",
    "    '''\n",
    "    Prints each variable of a column to a new line in console.\n",
    "    \n",
    "    Parameters:\n",
    "        target_column (str): Header of the column to be printed\n",
    "        dataset            : dataset to column is in\n",
    "    \n",
    "    Returns:\n",
    "        Strings printed to console\n",
    "        \n",
    "    Examples:\n",
    "        print_column_vertically(\"date\", long_data)\n",
    "    \n",
    "    '''\n",
    "    selected_column = select_column(target_column_name, dataset)\n",
    "    for i, value in enumerate(selected_column):\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Use case***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['date'], ['2017/03/30 12:20:57 AM UTC+0200'], ['2017/03/31 1:38:41 AM UTC+0200'], ['2017/04/01 12:00:27 AM UTC+0200'], ['2017/04/01 12:46:28 PM UTC+0200'], ['2017/04/02 9:02:20 PM UTC+0200'], ['2017/04/04 1:14:43 AM UTC+0200'], ['2017/04/05 2:53:39 AM UTC+0200'], ['2017/04/05 2:38:53 PM UTC+0200'], ['2017/04/07 4:07:06 AM UTC+0200'], ['2017/04/09 11:20:17 PM UTC+0200'], ['2017/04/10 12:40:08 PM UTC+0200']]\n"
     ]
    }
   ],
   "source": [
    "long_data = [[\"date\"], ['2017/03/30 12:20:57 AM UTC+0200'], ['2017/03/31 1:38:41 AM UTC+0200'], ['2017/04/01 12:00:27 AM UTC+0200'], ['2017/04/01 12:46:28 PM UTC+0200'], ['2017/04/02 9:02:20 PM UTC+0200'], ['2017/04/04 1:14:43 AM UTC+0200'], ['2017/04/05 2:53:39 AM UTC+0200'], ['2017/04/05 2:38:53 PM UTC+0200'], ['2017/04/07 4:07:06 AM UTC+0200'], ['2017/04/09 11:20:17 PM UTC+0200'], ['2017/04/10 12:40:08 PM UTC+0200']]\n",
    "print(long_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is too hard to read. Line by line printing is necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/03/30 12:20:57 AM UTC+0200\n",
      "2017/03/31 1:38:41 AM UTC+0200\n",
      "2017/04/01 12:00:27 AM UTC+0200\n",
      "2017/04/01 12:46:28 PM UTC+0200\n",
      "2017/04/02 9:02:20 PM UTC+0200\n",
      "2017/04/04 1:14:43 AM UTC+0200\n",
      "2017/04/05 2:53:39 AM UTC+0200\n",
      "2017/04/05 2:38:53 PM UTC+0200\n",
      "2017/04/07 4:07:06 AM UTC+0200\n",
      "2017/04/09 11:20:17 PM UTC+0200\n",
      "2017/04/10 12:40:08 PM UTC+0200\n"
     ]
    }
   ],
   "source": [
    "print_column_vertically(\"date\", long_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print multiple columns\n",
    "**print_columns()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to print values of multiple columns based on their names. Useful for testing and debugging.\n",
    "\n",
    "Usage:<br>\n",
    "print_columns(COLUMN_NAMES_LIST, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_columns(column_names, dataset):\n",
    "    '''\n",
    "    Prints columns with specified column names in a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        column_names: A list of strings or string of header name(s) in a column.\n",
    "        dataset: The dataset variable. It must be already read, and must contain headers.  \n",
    "    \n",
    "    Returns:\n",
    "        Prints strings to console line by line:\n",
    "            __column_name1__ is: __column1_values__\n",
    "            __column_name2__ is: __column2_values__\n",
    "            \n",
    "    Usage:\n",
    "        print_columns([\"day\", \"month\"], sample_data)  # print multiple column names\n",
    "        print_columns(\"day\", sample_data)             # print a single column name \n",
    "    '''\n",
    "    if type(column_names) is list:  # if the query is a list...\n",
    "        for i, column_name in enumerate(column_names):\n",
    "            print(\"\\n\" + column_name + \" is: \" + str(select_column(column_name, dataset)))            \n",
    "    \n",
    "    elif type(column_names) is str:  # if the query is a string (i.e., if a single column name is entered)...\n",
    "        column_name = column_names\n",
    "        print(\"\\n\" + column_name + \" is: \" + str(select_column(column_name, dataset)))\n",
    "    \n",
    "    else:  # if the query is not a list or single string, return error \n",
    "        raise ValueError('1: column_names must be a list of strings or a single string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "day is: ['1', '3', '4']\n",
      "\n",
      "month is: ['June', 'May', 'Jun']\n"
     ]
    }
   ],
   "source": [
    "sample_data = [['day', 'month'], ['1', 'June'], ['3', 'May'], ['4', 'Jun']]\n",
    "print_columns([\"day\", \"month\"], sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "day is: ['1', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "print_columns(\"day\", sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview dataset in a compact format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preview_data(dataset, depth=0):\n",
    "    \"\"\"\n",
    "    Transposes and prints data for easy previewing.\n",
    "    \n",
    "    Usage:\n",
    "        function(DATASET, DEPTH_int)\n",
    "\n",
    "    Args:\n",
    "        DATASET: This is a database that contains headers. The database must have already been tokenized and to a variable.\n",
    "        DEPTH: The number of rows to print. (Rows will appear as lines next to column names in the transposed output).\n",
    "\n",
    "    Returns:\n",
    "        A line-by-line print of columns in a table. This is a transposed version of the table.\n",
    "\n",
    "    Errors:\n",
    "        01: User likely entered integer, string, or boolean instead of dataset.  \n",
    "        \n",
    "    Examples:\n",
    "        preview_data(my_dataset)\n",
    "        preview_data(my_dataset, 5) # displays all columns 5 rows deep\n",
    "\n",
    "        > output\n",
    "    \"\"\"\n",
    "    # Check if input is a dataset\n",
    "    if type(dataset) is str or type(dataset) is int or type(dataset) is bool:\n",
    "        raise ValueError(\"01: Argument 1 must be a dataset.\")\n",
    "    \n",
    "    # Import regex module for later use in function\n",
    "    import re\n",
    "    \n",
    "    # If the number of rows to be displayed is not specified, set it to display all rows. \n",
    "    if depth == 0:\n",
    "        depth = len(dataset)\n",
    "    \n",
    "    # Select the number of rows sepecified by user \n",
    "    selected_rows   = dataset[0:depth]\n",
    "    column_headers  = dataset[0]\n",
    "    \n",
    "    # Store each column in a list item\n",
    "    extracted_columns = []\n",
    "    for header in column_headers:\n",
    "        extracted_columns.append(select_column(header, dataset))\n",
    "        \n",
    "    #Title and subtitle\n",
    "    print(\"Transposed Table (Columns in original data => Rows in output)\")\n",
    "    print(\"Displaying up to \" + str(depth) + \" values per column.\")\n",
    "    print(\"=============================================================\\n\")\n",
    "    \n",
    "    # Print selected columns line by line, and clear unnecessary characters\n",
    "    for i, column in enumerate(extracted_columns):\n",
    "        output = str(column_headers[i]) + \": \" + str(column[0:depth])\n",
    "        output = re.sub(\"[\\[\\],]\", \"\", output)\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display frequencies of values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_summary(column_name ,dataset, print_values=False):\n",
    "    '''    \n",
    "    Return (or print) the number of occurences for each value in the specified column in a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        column_name (str)   : Target column name from the dateset headers.\n",
    "        dataset     (var)   : Variable that holds the dataset. Headers must be included.\n",
    "        print_values (bool) : Specifies whether to return or print variables\n",
    "    \n",
    "    Returns:\n",
    "        If print_values == False (default) --> A dictionary object\n",
    "        If print_values == True            --> *Line by line* output to console (and no dictionary object returns) \n",
    "    \n",
    "    Examples:\n",
    "        my_data = [[\"id\", \"number\"],[\"John\", 0], [\"John\", 12], [\"Someone else\", 7]]\n",
    "        column_summary(column_name=\"id\", dataset=my_data, print_values=True)\n",
    "        > John\n",
    "        > Someone else\n",
    "    '''    \n",
    "    column_summaries = {}\n",
    "    selected_column = select_column(column_name, dataset)\n",
    "\n",
    "    for value in selected_column:\n",
    "        if value not in column_summaries:\n",
    "            column_summaries[value] = 1\n",
    "        else:\n",
    "            column_summaries[value] += 1\n",
    "    \n",
    "    if print_values == True:\n",
    "        for value in column_summaries:\n",
    "            print(value)\n",
    "    else:\n",
    "        return(column_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n",
      "Someone else\n"
     ]
    }
   ],
   "source": [
    "my_data = [[\"id\", \"number\"],[\"John\", 0], [\"John\", 12], [\"Someone else\", 7]]\n",
    "column_summary(column_name=\"id\", dataset=my_data, print_values=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing columns\n",
    "**replace_column()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:<br>\n",
    "replace_column(REPLACEMENT_COLUMN_VALUES_LIST, TARGET_COLUMN_HEADER_STRING, DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mostly for internal use. Use translate_values() instead for a more useful version for value replacements.\n",
    "- Function to replace values in a column in a dataset. Useful when re-writing a column after converting it to something else. (For instance, after converting likert scale responses from strings to integers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_column(replacement_column, target_column_header, dataset):\n",
    "    data = get_data(dataset)\n",
    "\n",
    "    target_index = get_header_index(target_column_header, dataset)\n",
    "    for i, row in enumerate(data):\n",
    "        row[target_index] = replacement_column[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 'June'], [20, 'May'], [30, 'Jun']]\n"
     ]
    }
   ],
   "source": [
    "sample_data = [['day', 'month'], ['1', 'June'], ['3', 'May'], ['4', 'Jun']]\n",
    "replacement_column = [10,20,30]\n",
    "\n",
    "new_data = replace_column(replacement_column, \"day\", sample_data)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform values in columns to custom values\n",
    "**transform_column_values()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Usage:<br>\n",
    "replace values(REPLACEMENTS_DICTIONARY, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_column_values(target_replacement_dictionary, target_column_headers_list, dataset):\n",
    "    '''\n",
    "    Replaces values in columns by using a dictionary of conversions (e.g., in order to quantify likert scales).\n",
    "    \n",
    "    Parameters:\n",
    "        target_replacement_dictionary (dict) : A dictionary in which *keys* are old (target) values ...\n",
    "                                             : ... and dictionary *values* are new (replacement) values.\n",
    "        target_column_headers_list    (str)  : A list of headers as a list of strings, which specifies in which columns ...\n",
    "                                             : ... the transformation will occur.\n",
    "        dataset                       (var)  : A variable that holds the dataset. Headers must be included.\n",
    "        \n",
    "    Returns:\n",
    "        Transformed the original dataset, and also returns it.\n",
    "        Assignment of output to a variable is not necessary; inputted dataset will be changed without assignment as well.\n",
    "        \n",
    "    Examples:\n",
    "        transform_column_values(replacements_dictionary, [\"sc_9\", \"sc_10\"], demo_data)\n",
    "        transform_column_values({\"yes\":1, \"no\":2}, \"consent\", demo_data)\n",
    "    '''\n",
    "    \n",
    "    # If target_column_headers_list is not a list but a string (i.e., target is a single column)...\n",
    "    # Convert this string to a single list item so that the upcoming lines in the function can still take it as input.\n",
    "    if type(target_column_headers_list) is str:                    # If parameter is string\n",
    "        target_column_headers_list = [target_column_headers_list]  # Convert it to a list\n",
    "    \n",
    "    # Separate headers from data\n",
    "    headers_list = get_headers(dataset)\n",
    "    data = get_data(dataset)\n",
    "    \n",
    "    # Separate the dictionary to targets and replacements\n",
    "    targets_list = []\n",
    "    replacements_list = []\n",
    "    for i, key in enumerate(target_replacement_dictionary):          # iterate over each item in the input dictionary\n",
    "        targets_list.append(key)                                     # add keys to targets list\n",
    "        replacements_list.append(target_replacement_dictionary[key]) # add values to replacements list\n",
    "    \n",
    "    # Extract values of the specified column in the given dataset by using a separate headers variable\n",
    "    columns = {}\n",
    "    for i, target_column_header in enumerate(target_column_headers_list):\n",
    "        columns[target_column_header] = select_column(target_column_header, dataset) # and not 'data'; the headers in 'dataset' is necesary for the select_column() to work.\n",
    "    \n",
    "    # Search targets in each of the extracted columns, and when the target values are found, replace them with their counterparts specifie in the dictionary. \n",
    "    for column in columns:\n",
    "        for i, target in enumerate(targets_list):\n",
    "            for j, value in enumerate(columns[column]):\n",
    "                if value == target:\n",
    "                    columns[column][j] = replacements_list[i]\n",
    "    \n",
    "    # Replace columns within a copy of the provided dataset and return this dataset\n",
    "    for col_name, col_values in columns.items():       \n",
    "        replace_column(col_values, col_name, dataset) # and not 'data' but 'dataset', which includes headers\n",
    "    \n",
    "    return(dataset) # and not 'data' but 'dataset', which includes headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of target columns as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "\n",
      "sc_9 is: ['oneens', 'even vaak eens als oneens', 'eens', 'eens', 'oneens', 'oneens', 'even vaak eens als oneens', 'eens', 'helemaal oneens', 'oneens', 'eens']\n",
      "\n",
      "sc_10 is: ['eens', 'eens', 'even vaak eens als oneens', 'oneens', 'oneens', 'eens', 'oneens', 'eens', 'oneens', 'oneens', 'even vaak eens als oneens']\n",
      "\n",
      "Transformed data:\n",
      "\n",
      "sc_9 is: [1, 3, 2, 2, 1, 1, 3, 2, 4, 1, 2]\n",
      "\n",
      "sc_10 is: [2, 2, 3, 1, 1, 2, 1, 2, 1, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data:\")\n",
    "print_columns([\"sc_9\", \"sc_10\"], demo_data)\n",
    "\n",
    "replacements_dictionary = {\"oneens\":1, \"eens\":2, \"even vaak eens als oneens\":3, \"helemaal oneens\":4, \"x\":5}\n",
    "transform_column_values(replacements_dictionary, [\"sc_9\", \"sc_10\"], demo_data)\n",
    "\n",
    "print(\"\\nTransformed data:\")\n",
    "print_columns([\"sc_9\", \"sc_10\"], demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single column as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "\n",
      "sc_11 is: ['even vaak eens als oneens', 'even vaak eens als oneens', 'oneens', 'eens', 'even vaak eens als oneens', 'eens', 'even vaak eens als oneens', 'oneens', 'eens', 'eens', 'even vaak eens als oneens']\n",
      "\n",
      "Transformed data:\n",
      "\n",
      "sc_11 is: [3, 3, 1, 2, 3, 2, 3, 1, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data:\")\n",
    "print_columns(\"sc_11\", demo_data)\n",
    "\n",
    "transform_column_values(replacements_dictionary, \"sc_11\", demo_data)\n",
    "\n",
    "print(\"\\nTransformed data:\")\n",
    "print_columns(\"sc_11\", demo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform specific parts of strings (substrings) in a column\n",
    "**transform_column_substring()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_column_substring(target_substring, replacement_substring, target_headers_list, dataset):\n",
    "    '''\n",
    "    Replaces substring for all values in a column and returns the transformed dataset.\n",
    "    Accepts regex as target_substring.\n",
    "    \n",
    "    Parameters:\n",
    "        target_substring (str, regex)     : The old substring\n",
    "        replacement_substring (str)       : The new substring\n",
    "        target_headers_list   (str, list) : A list of he headers of the target columns. A single string value can also be inputted. \n",
    "        dataset                           : The variable that holds the dataset. Headers must be included in the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        The transformed dataset\n",
    "        (Variable assignment is unnecessary, the original dataset is changed once the function is run)\n",
    "    \n",
    "    Examples:\n",
    "        transform_column_substring(\"a.m.\", \"AM\", \"time\", my_data)\n",
    "        transform_column_substring(\"[Aa].[Mm].\", \"AM\", \"time\", my_data)\n",
    "                \n",
    "        # Remove the dots from all values in the specified columns:\n",
    "        transform_column_substring(\"\\.\", \"\", [\"calories\", \"steps\"], my_data)\n",
    "    '''\n",
    "    import re\n",
    "\n",
    "    if type(target_headers_list) is str:           # If a single value is inputted as target column header (and not a list)\n",
    "        target_headers_list = [target_headers_list]   # Convert this to a list with one item so the rest of the function can work correctly.\n",
    "    \n",
    "    for target_column_name in target_headers_list:                   # For each column in the inputted list\n",
    "        selected_column = select_column(target_column_name, dataset) # Select the column\n",
    "        for i, string in enumerate(selected_column):                 # And change the substring\n",
    "            selected_column[i] = re.sub(target_substring, replacement_substring, string)\n",
    "\n",
    "        replace_column(selected_column, target_column_name, dataset) # Rewrite the column with its new version\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Example:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'time'], ['1', '10 a.m.'], ['2', '8 a.m.'], ['3', '4 A.M.']]\n",
      "[['id', 'time'], ['1', '10 AM'], ['2', '8 AM'], ['3', '4 A.M.']]\n",
      "[['id', 'time'], ['1', '10 AM'], ['2', '8 AM'], ['3', '4 AM']]\n"
     ]
    }
   ],
   "source": [
    "my_data = [ [\"id\", \"time\"], [\"1\", \"10 a.m.\"], [\"2\", \"8 a.m.\"], [\"3\", \"4 A.M.\"] ]\n",
    "\n",
    "print(my_data)\n",
    "\n",
    "transform_column_substring(\"a.m.\", \"AM\", \"time\", my_data)\n",
    "print(my_data)\n",
    "\n",
    "transform_column_substring(\"[Aa].[Mm].\", \"AM\", [\"time\"], my_data)\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['calories', 'steps'], ['1.242', '12.32'], ['2.300', '21.10'], ['500', '1.20']]\n",
      "[['calories', 'steps'], ['1242', '1232'], ['2300', '2110'], ['500', '120']]\n"
     ]
    }
   ],
   "source": [
    "my_data = [ \n",
    "    # These values are clearly wrong: Dots should not be there, as such small values do not make sense in this context.\n",
    "    [\"calories\", \"steps\"], \n",
    "    [\"1.242\",    \"12.32\"], \n",
    "    [\"2.300\",    \"21.10\"], \n",
    "    [\"500\",      \"1.20\"] ]\n",
    "print(my_data)\n",
    "\n",
    "# Remove the dots from all values in the specified columns.\n",
    "transform_column_substring(\"\\.\", \"\", [\"calories\", \"steps\"], my_data)\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform strings in a column to integers or floats (where possible)\n",
    "**transform_column_type()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, tokenize it, and read it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_column_type(target_headers, target_type, dataset):\n",
    "    '''\n",
    "    Transforms a column of string integers or floats to integers or floats.\n",
    "    \n",
    "    Parameters:\n",
    "        target_headers    : Header(s) of the columns to transformed to integers. \n",
    "                            Can be a list of strings (for multiple columns) or a single string (for a single column).\n",
    "        target_type (str)\n",
    "            \"int\"         : Converts all values in the selected columns from strings to integers.\n",
    "            \"float\"       : Converts strings to float values. \n",
    "        \n",
    "        dataset           : A dataset that is read to a variable. It must contain headers.\n",
    "    \n",
    "    Returns:\n",
    "        Transformed dataset\n",
    "        Note: If function is run without any variable assignment, it still changes the original dataset variable. \n",
    "    \n",
    "    Usage:\n",
    "        transform_column_type(\"numbers_column\", \"int\", my_data)\n",
    "        transform_column_type([\"small_numbers\", \"large_numbers\"], \"float\", my_data)\n",
    "    '''\n",
    "    try:\n",
    "        if type(target_headers) is str:\n",
    "            target_headers = [target_headers]\n",
    "        \n",
    "        for header_name in target_headers:\n",
    "            selected_column = select_column(header_name, dataset)\n",
    "            if target_type is \"int\":\n",
    "                selected_column = [ int(value) for value in selected_column ]\n",
    "            elif target_type is \"float\":\n",
    "                selected_column = [ float(value) for value in selected_column ]\n",
    "            replace_column(selected_column, header_name, dataset)\n",
    "    except:\n",
    "        raise ValueError(\"Unable to transform column values to target type. Column values are not strings that are convertible to target type?\")\n",
    "        \n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Usage: Transform single column to integers***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['letters', 'numbers'], ['a', 1], ['b', 2], ['c', 3]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [[\"letters\", \"numbers\"], [\"a\", \"1\"], [\"b\", \"2\"], [\"c\",\"3\"]] # <- Notice the number strings \n",
    "transform_column_type(\"numbers\", \"int\", my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Usage: Transform multiple columns to integers***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = [[\"letters\", \"small numbers\", \"large numbers\"], [\"a\", \"1\", \"100\"], [\"b\", \"2\", \"200\"], [\"c\",\"3\", \"300\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['letters', 'small numbers', 'large numbers'],\n",
       " ['a', 1, 100],\n",
       " ['b', 2, 200],\n",
       " ['c', 3, 300]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [[\"letters\", \"small numbers\", \"large numbers\"], [\"a\", \"1\", \"100\"], [\"b\", \"2\", \"200\"], [\"c\",\"3\", \"300\"]]\n",
    "transform_column_type([\"small numbers\", \"large numbers\"], \"int\", my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Variable assignment***:\n",
    "- The function changes the dataset by default.\n",
    "- If it is assigned to a variable, it would do that AND also assign the new dataset to a new variable. This is most likely not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['letters', 'numbers'], ['a', 1], ['b', 2], ['c', 3]]\n"
     ]
    }
   ],
   "source": [
    "my_data = [[\"letters\", \"numbers\"], [\"a\", \"1\"], [\"b\", \"2\"], [\"c\",\"3\"]] # <- Notice the number strings \n",
    "x = transform_column_type(\"numbers\", \"int\", my_data)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Column with Missing Values Replaced with Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missingval_return_replaced(missing_value_query, replacement_value, target_column_header, dataset):\n",
    "    '''\n",
    "    Returns the inputted column with a version of itself that has its missing values replaced with the given value.\n",
    "    NaN values will be replaced no matter which missing_value_query is entered, so in such caes, it can also be just \n",
    "    an empty string (i.e., \"\").\n",
    "    '''\n",
    "    selected_column = select_column(target_column_header, dataset)\n",
    "    \n",
    "    for i, each_row in enumerate(selected_column):\n",
    "        # If row is a missing value or a NaN value (NaN values are never equal to themselves), replace it.\n",
    "        if each_row == missing_value_query or each_row != each_row:\n",
    "            selected_column[i] = replacement_value\n",
    "    return selected_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Column Without Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missingval_return_without(missing_value_query, target_column_header, dataset):\n",
    "    '''\n",
    "    Returns the inputted column with a version of itself that has its missing values removed. \n",
    "    It should be noted that this new column will be shorter after removal of missing values. \n",
    "    \n",
    "    If the missing value is NaN (and  not 'NaN'), missing_value_query can take any value (e.g., \"\"\"), and the function \n",
    "    will still return without NaN values.\n",
    "    '''\n",
    "    selected_column = select_column(target_column_header, dataset)\n",
    "    \n",
    "    transformed_column = []\n",
    "    for i, each_row in enumerate(selected_column):\n",
    "        # If row is not a missing value or a NaN value (NaN values are never equal to themselves), append it to new column\n",
    "        if each_row != missing_value_query and each_row == each_row:\n",
    "            transformed_column.append(selected_column[i]) # append it to the new list\n",
    "    return transformed_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse times given in hh:mm format\n",
    "**parse_hour_minute()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_hour_minute(target_columns_list, ymd_column_name, dataset):\n",
    "    \"\"\"\n",
    "    Transforms string object in hh:mm format to a datetime.datetime object.\n",
    "    \n",
    "    Parameters:\n",
    "        target_columns_list (lst): A list of strings containing the headers of target columns.      \n",
    "        ymd_column_name     (str): The column that holds the year, month, and date information as a 'datetime' object.\n",
    "        dataset             (var): The variable that the dataset is stored in. Headers of the dataset must be\n",
    "                                   included in the dataset variable.\n",
    "        \n",
    "    Returns:\n",
    "        Rewrites the inputted dataset.\n",
    "        (Variable assignment is not necessary.)\n",
    "    \n",
    "    Errors:\n",
    "        [Error 1] Because this function transforms it input variable (\"i.e., dataset\") into an object it cannot process\n",
    "            (i.e., string --> datetime format), it cannot be run twice consequently.\n",
    "    \n",
    "    Examples:\n",
    "        parse_hour_minute([time1, time2], my_dataset)\n",
    "    \"\"\"\n",
    "    \n",
    "    for column_name in target_columns_list:\n",
    "        if type(column_name) is not str:\n",
    "            raise ValueError(\"[Error 1] Non-string header name is found in target headers list. Please check your headers.\")\n",
    "    \n",
    "    import datetime\n",
    "    import pandas # Necessary for creating NaT (Not a time) values.\n",
    "    \n",
    "    for column_name in target_columns_list:                    # for each column\n",
    "\n",
    "        selected_column = select_column(column_name, dataset)  \n",
    "        \n",
    "        for i, time in enumerate(selected_column):              # and for each value in each of these columns\n",
    "            try:\n",
    "                dates = select_column(ymd_column_name, dataset)\n",
    "                time_full = (str(dates[i].year) + \".\" + str(dates[i].month) + \".\" + str(dates[i].day) + \" \" + str(time))\n",
    "\n",
    "                selected_column[i] = datetime.datetime.strptime(time_full, \"%Y.%m.%d %H:%M\")\n",
    "            except:                         # If time cannot be converted (e.g., because it's a \"NA\" value)...\n",
    "                selected_column[i] = pandas.NaT   # Just copy-paste the problematic value (e.g., a NA value) in the new column\n",
    "        replace_column(selected_column, column_name, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append column to dataset\n",
    "**append_column()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:<br>\n",
    "- append_column(NEW_COLUMN_VARIABLES_LIST, NEW_COLUMN_NAME_STRING, DATASET)\n",
    "- Changes the inputted dataset when ran (no need for assigning the output to a variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_column (new_column_values, new_column_name, dataset):\n",
    "    # Check for duplicate header names\n",
    "    headers = get_headers(dataset)\n",
    "    if new_column_name in headers:  # if this duplicate check is not included, things go wrong (the duplicate header gets added to column values—a strange behavior, but it is prevented with not allowing duplicate headers). \n",
    "        print(\"ERROR: Header name already in dataset. Re-run all code up to this point or change header name.\\nError occured while processing new_column_name: \" + str(new_column_name))\n",
    "        raise ValueError(\"Header name already in dataset. Please choose a different name. If name is correct, try re-running all code up to this point. (See console output for last header name processed.)\")\n",
    "    \n",
    "    # Append the inputted column to specified dataset   \n",
    "    new_column = new_column_values           # pass argument to variable\n",
    "    new_column.insert(0, new_column_name)    # new column = merging of column name and column values\n",
    "    for i, row in enumerate(dataset):        # for each row in the dataset...\n",
    "        row.append(new_column[i])            # ...append the new column at the end (original dataset is already changed with this line, and there is no additional action [e.g., variable re-assignment] needed to change the dataset). \n",
    "    return dataset                           # output the changed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['day', 'month', 'year'], ['1', 'June', 2149], ['3', 'May', 2150], ['4', 'Jun', 2151]]\n"
     ]
    }
   ],
   "source": [
    "sample_data  = [['day', 'month'], ['1', 'June'], ['3', 'May'], ['4', 'Jun']]\n",
    "years_column = [2149,2150,2151]\n",
    "\n",
    "append_column(years_column, \"year\", sample_data)\n",
    "print(sample_data) # changes the original data set without a need to assign the output to a new variable, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate scale scores \n",
    "**calculate_scores()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:\n",
    "calculate_scores(STRING_LIST_OF_QUESTION_NAMES, DATASET)\n",
    "\n",
    "- This function calculates the row sums for given columns, which can be used to calculate scale/questionnaire scores.\n",
    "\n",
    "- It works by taking column names and dataset as input, and returning a list of integers which is the sum of each row of the given column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [3]\n",
      "2 [3]\n",
      "10 [3]\n",
      "20 [3]\n",
      "30 [3]\n",
      "100 [3]\n",
      "200 [3]\n",
      "300 [3]\n",
      "{'column1': [0, 0, 1], 'column2': [0, 0, 0], 'column3': [0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# TESTING VARIOUS POSSIBILITIES. THIS CELL IS NOT THE MAIN FUNCTION. \n",
    "\n",
    "columns = {\"column1\":[1,2,3], \"column2\":[10,20,30], \"column3\":[100,200,300]}\n",
    "\n",
    "count_values = [3]\n",
    "#count_values = None\n",
    "\n",
    "#filter_values = [10, 2, 3]\n",
    "filter_values = None\n",
    "\n",
    "if count_values == None:\n",
    "    count_values = [None]\n",
    "elif type(count_values) != list:\n",
    "    try:\n",
    "        count_values = [count_values]\n",
    "    except:\n",
    "        raise ValueError(\"[2] 'count_values' parameter is not convertible to list.\")\n",
    "\n",
    "if filter_values == None:\n",
    "    filter_values = [None]\n",
    "elif type(filter_values) != list:\n",
    "    try:\n",
    "        filter_values = [filter_values]\n",
    "    except:\n",
    "        raise ValueError(\"[3] 'filter_values' parameter is not convertible to list.\")\n",
    "\n",
    "if count_values != [None]:\n",
    "    for each_key, each_column in columns.items():\n",
    "        for i, each_value in enumerate(each_column):\n",
    "            if each_value not in count_values:\n",
    "                print(each_value, count_values)\n",
    "                columns[each_key][i]=0 \n",
    "            else:\n",
    "                columns[each_key][i]=1\n",
    "\n",
    "\n",
    "if filter_values != [None]:\n",
    "    for each_key, each_column in columns.items():\n",
    "        for i, each_value in enumerate(each_column):\n",
    "            if each_value not in filter_values:\n",
    "                print(each_value, filter_values)\n",
    "                columns[each_key][i]=0 \n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_scores(scale_columns_list, dataset, count_values=None, filter_values=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        QUESTION HEADERS: This must be a list of strings that hold the header names for target questions. \n",
    "        DATASET: The variable that holds the dataset to process.\n",
    "        COUNT_VALUES (List of int or float, int, float): Counts the number of occurences for given values.\n",
    "        FILTER_VALUES (List of int or float, int, float): Values to filter. All other values are be converted to 0. \n",
    "    \n",
    "    Returns:\n",
    "        A LIST of INTEGERS that holds the calculated scores.\n",
    "    \n",
    "    Raises:.\n",
    "        ValueError: [1] All values in the target rows (except the headers) must be either integers or strings that are convertible to strings. \n",
    "    \"\"\"\n",
    "    #########################    \n",
    "    ###  INITIALIZATION  ###\n",
    "    #########################\n",
    "    # Prepare count_values parameter for internal use\n",
    "    if count_values == None:\n",
    "        count_values = [None]\n",
    "    elif type(count_values) != list:\n",
    "        try:\n",
    "            count_values = [count_values]\n",
    "        except:\n",
    "            raise ValueError(\"[2] 'count_values' parameter is not convertible to list.\")\n",
    "\n",
    "    # Prepare filter_values parameter for internal use\n",
    "    if filter_values == None:\n",
    "        filter_values = [None]\n",
    "    elif type(filter_values) != list:\n",
    "        try:\n",
    "            filter_values = [filter_values]\n",
    "        except:\n",
    "            raise ValueError(\"[3] 'filter_values' parameter is not convertible to list.\")\n",
    "\n",
    "    ###############################    \n",
    "    ###  DICTIONARY OF COLUMNS  ###\n",
    "    ###############################\n",
    "    # Make a dictionary of columns to be included in the score calculation (keys are column headers, values are column rows)\n",
    "    columns = {}\n",
    "    for column_name in scale_columns_list:\n",
    "        current_column = select_column(column_name, dataset)\n",
    "        for i, element in enumerate(current_column):\n",
    "            try:\n",
    "                current_column[i] = float(element) # For compatibility with NaN values, this must be float\n",
    "            except:\n",
    "                raise ValueError(\"[1] Scores are not integers or floats (or not strings that are convertible to float). A non-number string exists in the data?\")        \n",
    "                break\n",
    "        columns[column_name] = current_column\n",
    " \n",
    "\n",
    "    #########################    \n",
    "    ###  TRANSFORMATIONS  ###\n",
    "    #########################\n",
    "    # Change all dictionary values that is given in count_values parameter to 1, and all others to 0\n",
    "    if count_values != [None]:\n",
    "        for each_key, each_column in columns.items():\n",
    "            for i, each_value in enumerate(each_column):\n",
    "                if each_value not in count_values:\n",
    "                    columns[each_key][i]=0 \n",
    "                else:\n",
    "                    columns[each_key][i]=1\n",
    "\n",
    "    # Keep all dictionary values that is given in the filter_values parameter, and make all other values 0\n",
    "    if filter_values != [None]:\n",
    "        for each_key, each_column in columns.items():\n",
    "            for i, each_value in enumerate(each_column):\n",
    "                if each_value not in filter_values:\n",
    "                    columns[each_key][i]=0         \n",
    "        \n",
    "    ###################    \n",
    "    ### CALCULATION ###\n",
    "    ###################\n",
    "    current_and_previous_column = [] # temporary variable necessary for column additions in the for loop below \n",
    "    sum_of_each_row_so_far = []      # will ultimately hold scores of each row                         \n",
    "                                             \n",
    "    for column_key, column_values in columns.items(): # For each column (which are now in the 'columns' dictionary)\n",
    "        # To begin, add all values of the first row for all columns to 'sum_of_each_row_so_far'.\n",
    "        # (At this point, the for loop's index = 0 (i.e., the first column/key in dictionary))\n",
    "        \n",
    "        if len(sum_of_each_row_so_far) == 0:             \n",
    "            for value in column_values:\n",
    "                sum_of_each_row_so_far.append(value)\n",
    "        # (By the time the for loop reaches this 'else', index = 1 instead of 0 (i.e., the second key/column in dictionary)).\n",
    "        else:\n",
    "            current_and_previous_column = list(zip(sum_of_each_row_so_far, column_values)) # Pair values of the first rows of columns (stored in 'sum_of_each_row_so_far') and the values of the next row.\n",
    "            for i, pair in enumerate(current_and_previous_column):\n",
    "                sum_of_each_row_so_far[i] = sum(pair) # Sum the current row (index = 1) and the previous row (index  = 0)\n",
    "                                      # After this calculation, let 'sum_of_each_row_so_far' become the result of this sum; \n",
    "                                      # And in the next iteration, use this sum as the input (i.e., the previous row) when adding the next row to it. \n",
    "    return sum_of_each_row_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores of four participants (row sums of given columns):[-1.0, -1.0, 4.0, 3.0]\n",
      "filtered scores of four participants (filtered row sums of given columns):[1.0, 0, 1.0, 1.0]\n",
      "counts of scores for four participants:[2, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "sample_data_2 = [\n",
    "    ['participant_id', 'question_1', 'question_2', 'question_3'], \n",
    "    ['#1',             '0',           '-2',        '1'], # responses of participant 1\n",
    "    ['#2',             '2',           '-3',        '0'], # responses of participant 2\n",
    "    ['#3',             '4',           '-1',        '1'], # responses of participant 3\n",
    "    ['#4',             '1',           '0',         '2']  # responses of participant 4\n",
    "]\n",
    "\n",
    "scores = calculate_scores([\"question_1\", \"question_2\", \"question_3\"], sample_data_2)\n",
    "print(\"scores of four participants (row sums of given columns):\" + str(scores))\n",
    "\n",
    "scores = calculate_scores([\"question_1\", \"question_2\", \"question_3\"], sample_data_2, filter_values=[1])\n",
    "print(\"filtered scores of four participants (filtered row sums of given columns):\" + str(scores))\n",
    "\n",
    "scores = calculate_scores([\"question_1\", \"question_2\", \"question_3\"], sample_data_2, count_values=[0,1])\n",
    "print(\"counts of scores for four participants:\" + str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Functions in Repeating-Row Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These functions can be used in datasets where groups of rows represent one subject. \n",
    "- For instance, in some datasets (e.g., daily data), one participant may occupy 20 rows, and then the next 20 rows would belong to the next participant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example data (and its preparation) to use in this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimized, one-line code\n",
    "import csv; demo_daily_data = list(csv.reader(open(\"data//original_data//dagelijkse-vragenlijst-v3.csv\", encoding=\"UTF8\"), delimiter=\";\")); headers_list = [\"date\", \"id\", \"bed_time\", \"late\", \"late_reason\", \"wake_time\", \"sleep_transition\", \"sleep_struggle\", \"night_wake\", \"wake_earlier\", \"wake_earlier_problem\", \"sleep_quality\", \"physical_activity\", \"mental_digital_activity\", \"social_activity\", \"light\", \"presleep_description\", \"temptation_smoking\", \"temptation_eating\", \"temptation_chat\", \"temptation_coffee\", \"temptation_social_media\", \"temptation_internet\", \"temptation_tv\", \"temptation_alcohol\", \"temptation_soft_drink\", \"temptation_cleaning\", \"temptation_shopping\", \"temptation_other\", \"bed_time_plan\", \"steps\", \"sun_hours\"];replace_headers(headers_list, demo_daily_data); transform_column_substring(\",\", \".\", \"sun_hours\", demo_daily_data); transform_column_type(\"steps\", \"int\", demo_daily_data); transform_column_type(\"sun_hours\", \"float\", demo_daily_data); print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide rows in a column based on a grouping criteria (e.g., participant ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def divide_column_by_criteria(row_grouping_criteria_header, target_column_name, dataset, output=\"list\"):\n",
    "    '''\n",
    "    Divides a column to multiple parts based on the division criteria provided (e.g., grouping rows based on participant ...\n",
    "    IDs that are spread to multiple rows). Ignores capitalization differences in criteria names.\n",
    "    \n",
    "    Parameters:\n",
    "        row_grouping_criteria_header (str): Header of the column that contains the criteria that will be used when creating groups \n",
    "                                            of rows (e.g., Participant ID)\n",
    "        target_column_name    (str): The column that will be divided into groups\n",
    "        dataset               (var): A variable containing a dataset with headers\n",
    "        output                (arg): \n",
    "            \"list\" (default): turns on the list mode, which returns the output as a list that is in the same order with the \n",
    "                              inputted data (if the rows of the row grouping criteria column has no interruption [i.e., \n",
    "                              this shouldn't happen in data: \n",
    "                              participant A's id for 10 rows, and then participant B's id, and then participant A's again.])\n",
    "            \"dict\"          : returns a dictionary instead of a list. Does not preserve order.\n",
    "    \n",
    "    Returns:\n",
    "        A list of lists containing subgroups made out of the inputted column. \n",
    "    \n",
    "    Examples:\n",
    "       divided_column = divide_column_by_criteria(\"id\", \"procrastination_minutes\", daily_data)\n",
    "\n",
    "    '''\n",
    "    # Compatibilty column for history_nback function. Can be ignored.\n",
    "    if row_grouping_criteria_header is None:\n",
    "        return [select_column(target_column_name, dataset)]\n",
    "    \n",
    "    \n",
    "    # Initialize criteria that is going to be used to divide the columns, and initialize the target column to be divided \n",
    "    target_column   = select_column(target_column_name, dataset)\n",
    "    criteria_column = select_column(row_grouping_criteria_header, dataset)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Make all elements in the criteria column (e.g., participant ids) lowecase, so instead of creating different groups for\n",
    "    # ... each capitalization style of the criteria, one group is created. \n",
    "    for i, row in enumerate(criteria_column):\n",
    "        criteria_column[i] = row.lower()\n",
    "\n",
    "    # Reduce all items in the criteria column to their unique ocurences \n",
    "    criteria = set(criteria_column)\n",
    "    \n",
    "    # Divide the target column based on given criteria\n",
    "    grouped_rows_dict = {}\n",
    "    for criterion in criteria:\n",
    "       \n",
    "        grouped_rows_dict[criterion] = []\n",
    "        \n",
    "        counter = range(0,len(criteria_column))\n",
    "        for i, criterion_value, target_value in zip(counter, criteria_column, target_column):\n",
    "            if criterion_value == criterion:\n",
    "                grouped_rows_dict[criterion].append(target_value)\n",
    "    \n",
    "    # Return a version of the inputted column that is divided per the criteria column\n",
    "    if output == \"list\":\n",
    "       # Order dictionary return order based on row order in the column\n",
    "        divider_column = select_column(row_grouping_criteria_header, dataset)\n",
    "        groups_order = []\n",
    "        for criterion in criteria_column:\n",
    "            if criterion not in groups_order:\n",
    "                groups_order.append(criterion)\n",
    "       \n",
    "        grouped_rows_ordered_list = []\n",
    "        #for group_key, group_values in grouped_rows_dict.items():\n",
    "        #    for group_name in groups_order:\n",
    "        #        if group_key is group_name:\n",
    "        #            grouped_rows_ordered_list.append(grouped_rows_dict[group_key])\n",
    "        \n",
    "        for group_name in groups_order:\n",
    "                for group_key, group_values in grouped_rows_dict.items():\n",
    "                    if group_key is group_name:\n",
    "                        grouped_rows_ordered_list.append(grouped_rows_dict[group_key])\n",
    "              \n",
    "        return grouped_rows_ordered_list\n",
    "    elif output == \"dict\":\n",
    "        return grouped_rows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3], [12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5], [12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8], [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3], [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7], [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1], [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4], [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5], [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0], [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1]]\n",
      "\n",
      "{'wh18': [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1], 'ha61': [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1], 'ab64': [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3], 'gw98': [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7], 'gh93': [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3], 'mj87': [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5], 'pm61': [12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0], 'em11': [12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5], 'he46': [12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4], 'ft12': [12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8]}\n",
      "\n",
      "\n",
      "id is: ['AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'AB64', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'EM11', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'FT12', 'gh93', 'gh93', 'gh93', 'gh93', 'gh93', 'gh93', 'gh93', 'Gh93', 'gh93', 'gh93', 'gh93', 'Gh93', 'gh93', 'gh93', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'GW98', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'HA61', 'he46', 'he46', 'he46', 'HE46', 'he46', 'he46', 'he46', 'he46', 'he46', 'he46', 'HE46', 'he46', 'he46', 'he46', 'he46', 'he46', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'MJ87', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'PM61', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18', 'wh18']\n"
     ]
    }
   ],
   "source": [
    "x = divide_column_by_criteria(\"id\", \"sun_hours\", demo_daily_data)\n",
    "y = divide_column_by_criteria(\"id\", \"sun_hours\", demo_daily_data, \"dict\")\n",
    "\n",
    "print(x)\n",
    "print(\"\")\n",
    "print(y)\n",
    "print(\"\")\n",
    "print_columns(\"id\", demo_daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return a vector or column's values n values ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def history_nback(target_column_name_or_target_var, n_back, input=\"list\", dataset=None, row_grouping_criteria_header=None):\n",
    "    '''\n",
    "    Displays a vector's n-back element. Vector can be a column specified by its name in the parameters, \n",
    "    ... or it can be a vector that holds a vector.\n",
    "    \n",
    "    Parameters:\n",
    "        target_column_name_or_target_var (str or var): A column specified by its name in the parameters, or a vector that holds a target vector.\n",
    "        n_back(int): Number of elements to go back when selecting the previous value. \n",
    "        \n",
    "        input (arg):\n",
    "            \"list\" (default): Processes input as a vector that holds a list\n",
    "            \"column\": Processes input as a vector that holds a dataset\n",
    "        \n",
    "        dataset (var): vector that holds that a dataset with headers. Must be provided if target is a column name.\n",
    "                \n",
    "        row_grouping_criteria_header: If a dataset is given, a row grouping criteria can also be defined. Can also be left blank.\n",
    "        \n",
    "    Returns:\n",
    "        A list containing previous values of elements\n",
    "        \n",
    "    Examples:\n",
    "        my_list = [1, 2, 3, 4, 7]\n",
    "        my_list_one_back   = history_nback(my_list, 1)\n",
    "        > [0, 1, 2, 3, 4]\n",
    "        \n",
    "        history_nback(\"value_column\", 2, \"column\", dataset=my_data)\n",
    "        history_nback(\"value_column\", 2, \"column\", dataset=my_data, row_grouping_criteria_header=\"id\")\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # If input is not a vector, select the specified column from the dataset. \n",
    "    if input is \"column\":\n",
    "        vectors_list = divide_column_by_criteria(row_grouping_criteria_header, target_column_name_or_target_var, dataset)\n",
    "\n",
    "    # If input is a vector, initialize internal vectors accordingly.\n",
    "    elif input is \"list\":\n",
    "        vectors_list = [target_column_name_or_target_var]\n",
    "    \n",
    "    vectors_list_with_nbacks   = []\n",
    "    for each_vector in vectors_list:\n",
    "        # Assign a x-back previous values of a column or vector to a new vector.\n",
    "        current_nbacks = []\n",
    "        for i, each_element in enumerate(each_vector):\n",
    "            current_nbacks.append(each_vector[i-n_back])\n",
    "        current_nbacks[0:n_back] = [float(\"NaN\")]*n_back   # replace meaningless values with 0\n",
    "        vectors_list_with_nbacks.append(current_nbacks)\n",
    "    \n",
    "    unified_vector_with_nbacks = []\n",
    "    for each_vector in vectors_list_with_nbacks:\n",
    "        unified_vector_with_nbacks.extend(each_vector)\n",
    "    \n",
    "    return(unified_vector_with_nbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use history_nback on a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 1, 2, 3, 4]\n",
      "[nan, nan, 1, 2, 3]\n",
      "[nan, nan, nan, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 3, 4, 7]\n",
    "my_list_one_back = history_nback(my_list, 1)\n",
    "my_list_two_back = history_nback(my_list, 2)\n",
    "my_list_three_back = history_nback(my_list, 3)\n",
    "\n",
    "print(my_list_one_back)\n",
    "print(my_list_two_back)\n",
    "print(my_list_three_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use history_nback on a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, 1, 2, 3, 4, -1, -2, -3, -4, 10, 11]\n",
      "[nan, nan, 1, 2, nan, nan, -1, -2, nan, nan, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "my_data = [\n",
    "    [\"id\", \"value\"], \n",
    "    [\"john\", 1], [\"JOHN\", 2], [\"John\", 3], [\"john\", 4],  # <-- Note the capitazliation deifferences (they are no problem)\n",
    "    [\"michael\", -1], [\"michael\", -2], [\"michael\", -3], [\"michael\", -4], \n",
    "    [\"james\", 10], [\"james\", 11], [\"james\", 12], [\"james\", 13]\n",
    "]\n",
    "\n",
    "nback_all    = history_nback(\"value\", 2, \"column\", dataset=my_data)\n",
    "nback_per_id = history_nback(\"value\", 2, \"column\", dataset=my_data, row_grouping_criteria_header=\"id\")\n",
    "\n",
    "print(nback_all)    # this is possibly the wrong usage if a dataset consists of multi-row cases. It is perfectly OK to\n",
    "                    # ... use if the column does not contain multi-row cases. \n",
    "print(nback_per_id) # note that the n-back behavior is reset each time a row with a different id starts to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sun_hours is: [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1]\n",
      "\n",
      "One day before\n",
      "[nan, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1]\n",
      "\n",
      "Two days before\n",
      "[nan, nan, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4]\n",
      "\n",
      "Three days before\n",
      "[nan, nan, nan, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4]\n"
     ]
    }
   ],
   "source": [
    "one_days_before   = history_nback(\"sun_hours\", 1, input=\"column\", dataset=demo_daily_data)\n",
    "two_days_before   = history_nback(\"sun_hours\", 2, \"column\"      , demo_daily_data) \n",
    "three_days_before = history_nback(\"sun_hours\", 3, \"column\"      , demo_daily_data)\n",
    "\n",
    "print_columns(\"sun_hours\", demo_daily_data)\n",
    "\n",
    "print(\"\\nOne day before\")\n",
    "print(one_days_before)\n",
    "print(\"\\nTwo days before\")\n",
    "print(two_days_before)\n",
    "print(\"\\nThree days before\")\n",
    "print(three_days_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return n-day cumulative history of a vector or column's values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def history_cumulative(target_column_name, n_back, dataset, row_grouping_criteria_header=None, zero_floored_summation=0):\n",
    "    '''\n",
    "    Calculates the cumulative sums of past x days for each value in the inputted column. Optionally, \n",
    "    also takes a row grouping criteria (for instance, to calculate cumulative history of each participant id \n",
    "    within themselves).\n",
    "    \n",
    "    Parameters:\n",
    "        target_column_name (str)  : The name of the header that needs to be targeted.\n",
    "        \n",
    "        n_back (int)   : Number of days to go back when calculating cumulative sums.\n",
    "        \n",
    "        dataset (var): A variable that contains a dataset with headers.\n",
    "        \n",
    "        row_grouping_criteria_header (str): The header of the column that will be used for grouping the multi-row variable in \n",
    "        the target column. When a grouping criteria header is provided, this simply divides the column into multiple lists \n",
    "        within a list. \n",
    "        \n",
    "        zero_floored_summation(0,1): Performs the cumulative summation in a sequential manner, and sets a floor value for \n",
    "        calculation. Useful in cases where negative values are not possible (e.g., sleep deficit calculations).  \n",
    "    \n",
    "    Returns:\n",
    "         A list containing integers or floats\n",
    "    \n",
    "    Examples:\n",
    "        history_cumulative(\"value\", 3, my_data, \"id\")\n",
    "        sleep_debts = history_cumulative(\"value\", 5, sleep_debt_changes, \"id\", zero_floored_summation=1)\n",
    "    '''\n",
    "    # Make an iterative summation function for calculating variables that cannot go below a certain value (e.g., sleep debt) \n",
    "    def sum_iterative(vector_to_iterate, floor_value=None):\n",
    "        vector = vector_to_iterate\n",
    "\n",
    "        vector_summed_so_far = 0\n",
    "        current_sum = 0\n",
    "        for i in range(1, len(vector)):\n",
    "            if i == 1:\n",
    "                current_sum = vector[i-1] + vector[i]\n",
    "            elif i > 1:\n",
    "                current_sum = vector_summed_so_far + vector[i] \n",
    "            if floor_value != None:\n",
    "                if current_sum < floor_value:\n",
    "                    current_sum = 0\n",
    "\n",
    "            vector_summed_so_far = current_sum\n",
    "\n",
    "        return(vector_summed_so_far)\n",
    "\n",
    "    # Will give an error if row_grouping_criteria_header is None. Needs to be fixed.\n",
    "    # Divide the given column with multi-row subjects to groups based on grouping criteria (e.g., id)\n",
    "    grouped_rows_list = divide_column_by_criteria(row_grouping_criteria_header, target_column_name, dataset)\n",
    "    \n",
    "    cumulative_history_values_for_all_groups = []\n",
    "    # For each group of values/rows in the current vector/column (rows are grouped by row_grouping_criteria_header) \n",
    "    for each_group in grouped_rows_list:\n",
    "\n",
    "        # Create a dictionary that holds historical versions of the current group of rows/values in the current column\n",
    "        historical_versions_of_current_group_init = {} # This dictionary has no proper key names yet, so its named _init\n",
    "        for i in range(0,n_back):\n",
    "            historical_versions_of_current_group_init[i] = history_nback(each_group, i)\n",
    "\n",
    "        # If the value is NaN, replace it with 0. This is necessary for cumulative calculations up to n'th day, \n",
    "        # or first n values would be NaN (desirable for values n days ago, but not for cumulative history)  \n",
    "        #for each_key, each_list in historical_versions_of_current_group_init.items():\n",
    "        #    for i, each_item in enumerate(each_list):\n",
    "        #        if each_item != each_item:\n",
    "        #            historical_versions_of_current_group_init[each_key][i] = 0 \n",
    "\n",
    "        # Update the dictionary so that it holds historical versions of the current group of rows/values in the column.\n",
    "        historical_versions_of_current_group = {} \n",
    "        for key, value in historical_versions_of_current_group_init.items():\n",
    "            historical_versions_of_current_group[str(key) + \" days ago\"] = historical_versions_of_current_group_init[key]\n",
    "        #print(historical_versions_of_current_group[\"2 days ago\"])\n",
    "\n",
    "        # Sum all values in last x days to get the cumulative history\n",
    "        previous_n_values_of_each_value = []\n",
    "        n_day_cumulative_sums_of_each_value = []\n",
    "        for i, item in enumerate(historical_versions_of_current_group[\"0 days ago\"]): # for each column stored in the dictionary with representative length\n",
    "            for key, value in historical_versions_of_current_group.items():           # and for each value in these columns \n",
    "                previous_n_values_of_each_value.append(historical_versions_of_current_group[key][i])    # add this value to a list\n",
    "                # For some reason, the items in this previous_n_values_of_each_value vector is reversed. This must be corrected.\n",
    "                reversed_previous_n_values_of_each_value = list(reversed(previous_n_values_of_each_value)) \n",
    "            if zero_floored_summation==0:\n",
    "                n_day_cumulative_sums_of_each_value.append(sum_iterative(reversed_previous_n_values_of_each_value))  # sum this list (which now consists of all values of column)\n",
    "            elif zero_floored_summation==1:\n",
    "                n_day_cumulative_sums_of_each_value.append(sum_iterative(reversed_previous_n_values_of_each_value, floor_value=0))\n",
    "            previous_n_values_of_each_value = []                                   # reset list for next aggregation and summation operation\n",
    "        \n",
    "        cumulative_history_values_for_all_groups.append(n_day_cumulative_sums_of_each_value)\n",
    "    \n",
    "    cumulative_history_values_for_all_groups_as_one_list = []\n",
    "    for each_group_history in cumulative_history_values_for_all_groups:\n",
    "        cumulative_history_values_for_all_groups_as_one_list.extend(each_group_history)\n",
    "        \n",
    "    return (cumulative_history_values_for_all_groups_as_one_list)                        # return all of these sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "\n",
      "value is: [1, 2, 3, 4, -1, -2, -3, -4, 10, 11, 12, 13]\n",
      "\n",
      "Cumulative two-day histories for 'value' (per id) are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan, 6, 9, nan, nan, -6, -9, nan, nan, 33, 36]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [\n",
    "    [\"id\",  \"value\"], \n",
    "    [\"john\",     1], \n",
    "    [\"JOHN\",     2], \n",
    "    [\"John\",     3], \n",
    "    [\"john\",     4],  # <-- Note the capitazliation differences (they are no problem)\n",
    "    [\"michael\", -1], \n",
    "    [\"michael\", -2], \n",
    "    [\"michael\", -3], \n",
    "    [\"michael\", -4], \n",
    "    [\"james\",   10], \n",
    "    [\"james\",   11], \n",
    "    [\"james\",   12], \n",
    "    [\"james\",   13]\n",
    "]\n",
    "\n",
    "print(\"Original data:\")\n",
    "print_columns(\"value\",my_data)\n",
    "print(\"\\nCumulative two-day histories for 'value' (per id) are:\") \n",
    "history_cumulative(\"value\", 3, my_data, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "value is: [-8, 3, -12, 1, 2, 10, -16, 3, 1, 1, 1, 1]\n",
      "[nan, nan, nan, 1, nan, nan, nan, 3, nan, nan, nan, 4]\n"
     ]
    }
   ],
   "source": [
    "sleep_debt_changes = [\n",
    "    [\"id\",  \"value\"], \n",
    "    [\"john\",   -8], \n",
    "    [\"JOHN\",    3], \n",
    "    [\"John\",   -12], \n",
    "    [\"john\",    1],  # <-- Note the capitalization deifferences (they are no problem)\n",
    "    [\"michael\", 2], \n",
    "    [\"michael\", 10], \n",
    "    [\"michael\",-16], \n",
    "    [\"michael\", 3], \n",
    "    [\"james\",   1], \n",
    "    [\"james\",   1], \n",
    "    [\"james\",   1], \n",
    "    [\"james\",   1]\n",
    "]\n",
    "print_columns(\"value\",sleep_debt_changes)\n",
    "sleep_debts = history_cumulative(\"value\", 4, sleep_debt_changes, \"id\", zero_floored_summation=1)\n",
    "print(sleep_debts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"intake-data\"></a>\n",
    "# INTAKE QUESTIONNAIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and perform initial formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, tokenize it, and read it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "intake_data = list(csv.reader(open(\"data//original_data//intake-vragenlijst-v2.3.csv\", encoding=\"utf8\"), delimiter=\";\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headers have long string values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben je in de afgelopen twee weken een tijdzone gepasseerd?\n"
     ]
    }
   ],
   "source": [
    "print(intake_data[0][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace headers with names / codes from 'survey features.xlsx':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'consent', 'id', 'sex', 'age', 'edu', 'timezone_change', 'sleep_disorder', 'nightshift', 'psy_disorder', 'wake', 'young_kids', 'partn', 'bptrt_1', 'bptrt_2', 'bptrt_3', 'bptrt_4', 'bptrt_5', 'bptrt_6', 'bptrt_7', 'bptrt_8', 'bptrt_9', 'ats_1', 'atbr_1', 'sq_1', 'sq_2', 'sq_3', 'sq_4', 'sq_5', 'sq_6', 'atbr_2', 'atbr_3', 'ats_2', 'ats_3', 'chron_1', 'chron_2', 'chron_3', 'chron_4', 'chron_5', 'chron_6', 'chron_7', 'chron_8', 'sc_1', 'sc_2', 'sc_3', 'sc_4', 'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'sc_12', 'sc_13']\n"
     ]
    }
   ],
   "source": [
    "header_replacements = [\"date\", \"consent\", \"id\", \"sex\", \"age\", \"edu\", \"timezone_change\", \"sleep_disorder\", \"nightshift\", \"psy_disorder\", \"wake\", \"young_kids\", \"partn\", \"bptrt_1\", \"bptrt_2\", \"bptrt_3\", \"bptrt_4\", \"bptrt_5\", \"bptrt_6\", \"bptrt_7\", \"bptrt_8\", \"bptrt_9\", \"ats_1\", \"atbr_1\", \"sq_1\", \"sq_2\", \"sq_3\", \"sq_4\", \"sq_5\", \"sq_6\", \"atbr_2\", \"atbr_3\", \"ats_2\", \"ats_3\", \"chron_1\", \"chron_2\", \"chron_3\", \"chron_4\", \"chron_5\", \"chron_6\", \"chron_7\", \"chron_8\", \"sc_1\", \"sc_2\", \"sc_3\", \"sc_4\", \"sc_5\", \"sc_6\", \"sc_7\", \"sc_8\", \"sc_9\", \"sc_10\", \"sc_11\", \"sc_12\", \"sc_13\"]\n",
    "replace_headers(header_replacements, intake_data)\n",
    "print(intake_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is used when transforming responses encoded as string in the dataset to integers. \n",
    "- Conversions follow the specifications in the 'Survey features.xlsx' file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helemaal oneens / oneens / even vaak eens als oneens / eens / helemaal eens\t0 / 1 / 2 / 3 / 4\n",
    "type_1 = {\n",
    "    \"helemaal eens\":4,\n",
    "    \"vaak\":4,    # additional item instead of helemaal eens, as is used in some questions\n",
    "    \"eens\":3,\n",
    "    \"even vaak eens als oneens\":2,\n",
    "    \"oneens\":1,\n",
    "    \"helemaal oneens\":0,\n",
    "}\n",
    "\n",
    "# helemaal oneens / oneens / even vaak eens als oneens / eens / helemaal eens\t0/ -1/ -2/ -3/ -4\n",
    "type_1_reverse = {\n",
    "    \"helemaal eens\":-4,\n",
    "    \"vaak\":-4,           # additional item instead of helemaal eens, as is used in some questions\n",
    "    \"eens\":-3,\n",
    "    \"even vaak eens als oneens\":-2,\n",
    "    \"oneens\":-1,\n",
    "    \"helemaal oneens\":0\n",
    "}\n",
    "\n",
    "# (bijna) nooit / soms / regelmatig / vaak / (bijna) altijd\t0 / 1 / 2 / 3 / 4\n",
    "type_2 = {\n",
    "    \"(bijna) altijd\":4,\n",
    "    \"vaak\":3,\n",
    "    \"regelmatig\":2,\n",
    "    \"soms\":1,\n",
    "    \"(bijna) nooit\":0\n",
    "}\n",
    "\n",
    "# (bijna) nooit / soms / regelmatig / vaak / (bijna) altijd\t0/ -1/ -2/ -3/ -4\n",
    "type_2_reverse = {\n",
    "    \"(bijna) altijd\":-4,\n",
    "    \"vaak\":-3,\n",
    "    \"regelmatig\":-2,\n",
    "    \"soms\":-1,\n",
    "    \"(bijna) nooit\":0\n",
    "}\n",
    "\n",
    "# OLD VERSION WITH WRONG VALUES. KEPT FOR REFERENCE PURPOSES IN CASE OF ERRORS.\n",
    "# helemaal oneens / oneens / even vaak eens als oneens / eens / helemaal eens\t0/ -1/ -2/ -3/ -4\n",
    "# type_1_reverse = {\n",
    "#    \"helemaal eens\":0,\n",
    "#    \"vaak\":0,           # additional item instead of helemaal eens, as is used in some questions\n",
    "#    \"eens\":-1,\n",
    "#    \"even vaak eens als oneens\":-2,\n",
    "#    \"oneens\":-3,\n",
    "#    \"helemaal oneens\":-4\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedtime Procrastination Trait (BPTRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 9 items\n",
    "- Normal items: 1, 4, 5, 6, 8\n",
    "- Reverse items: 2, 3, 7, 9\n",
    "- Conversion dictionary type: 2\n",
    "- Sum: ranges from -16 to +20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bptrt_all_items = [\"bptrt_1\", \"bptrt_2\", \"bptrt_3\", \"bptrt_4\", \"bptrt_5\", \"bptrt_6\", \"bptrt_7\", \"bptrt_8\", \"bptrt_9\"]  \n",
    "bptrt_regular_items = [\"bptrt_1\", \"bptrt_4\", \"bptrt_5\", \"bptrt_6\", \"bptrt_8\"]\n",
    "bptrt_reverse_items = [\"bptrt_2\", \"bptrt_3\", \"bptrt_7\", \"bptrt_9\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its original form, responses are strings and therefore not continuous:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bptrt_1's raw form is: ['soms', 'vaak', 'vaak', 'regelmatig', 'regelmatig', 'regelmatig', 'vaak', '(bijna) altijd', '(bijna) nooit', 'soms', 'vaak']\n",
      "\n",
      "bptrt_2's raw form is: ['(bijna) altijd', 'vaak', 'soms', 'vaak', 'regelmatig', 'regelmatig', 'regelmatig', '(bijna) nooit', 'vaak', 'soms', 'regelmatig']\n",
      "\n",
      "bptrt_3's raw form is: ['(bijna) altijd', 'regelmatig', 'soms', 'vaak', 'vaak', 'soms', 'regelmatig', 'vaak', 'vaak', '(bijna) altijd', 'soms']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"bptrt_1's raw form is: \" + str(select_column('bptrt_1', intake_data)))\n",
    "print(\"\\nbptrt_2's raw form is: \" + str(select_column('bptrt_2', intake_data)))\n",
    "print(\"\\nbptrt_3's raw form is: \" + str(select_column('bptrt_3', intake_data)))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But likert scales are continous measurements, and they also require integers for calculating their scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conversion from string to integer can be accomplished by using the appropriate conversion dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bptrt_1 is: [1, 3, 3, 2, 2, 2, 3, 4, 0, 1, 3]\n",
      "\n",
      "bptrt_2 is: [-4, -3, -1, -3, -2, -2, -2, 0, -3, -1, -2]\n",
      "\n",
      "bptrt_3 is: [-4, -2, -1, -3, -3, -1, -2, -3, -3, -4, -1]\n",
      "\n",
      "bptrt_4 is: [1, 1, 1, 1, 1, 3, 1, 4, 1, 0, 3]\n",
      "\n",
      "bptrt_5 is: [0, 1, 3, 1, 1, 2, 2, 1, 1, 0, 3]\n",
      "\n",
      "bptrt_6 is: [1, 3, 2, 1, 1, 2, 2, 4, 1, 0, 3]\n",
      "\n",
      "bptrt_7 is: [-4, 0, 0, -2, -1, -2, -1, 0, -2, 0, 0]\n",
      "\n",
      "bptrt_8 is: [0, 1, 3, 1, 1, 2, 1, 2, 1, 0, 3]\n",
      "\n",
      "bptrt_9 is: [-4, -4, -2, -3, -2, -1, -2, -1, -2, -4, -1]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(type_2, bptrt_regular_items, intake_data)\n",
    "intake_data = transform_column_values(type_2_reverse, bptrt_reverse_items, intake_data)\n",
    "\n",
    "print_columns(bptrt_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aversivenes To Sleep (ATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 items\n",
    "- Normal items: 1\n",
    "- Reverse items: 2, 3\n",
    "- Conversion dictionary type: 2\n",
    "- Sum: ranges from -8 to +4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ats_all_items = [\"ats_1\", \"ats_2\", \"ats_3\",]\n",
    "ats_regular_items = [\"ats_1\"]\n",
    "ats_reverse_items = [\"ats_2\", \"ats_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ats_1's raw form is: ['(bijna) nooit', 'vaak', '(bijna) nooit', 'soms', '(bijna) nooit', 'regelmatig', 'soms', 'regelmatig', '(bijna) nooit', '(bijna) nooit', 'soms']\n"
     ]
    }
   ],
   "source": [
    "print(\"ats_1's raw form is: \" + str(select_column('ats_1', intake_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ats_1 is: [0, 3, 0, 1, 0, 2, 1, 2, 0, 0, 1]\n",
      "\n",
      "ats_2 is: [-3, -3, 0, -1, -1, -3, -2, 0, 0, 0, -1]\n",
      "\n",
      "ats_3 is: [-4, -3, -4, -1, -4, -3, -2, -4, -2, -3, -3]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(type_2, ats_regular_items, intake_data)\n",
    "intake_data = transform_column_values(type_2_reverse, ats_reverse_items, intake_data)\n",
    "\n",
    "print_columns(ats_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aversiveness to Bedtime Routine (ATBR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 items\n",
    "- Normal items: 1, 2, 3\n",
    "- Conversion dictionary type: 2\n",
    "- Sum: ranges from 0 to 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atbr_all_items = [\"atbr_1\", \"atbr_2\", \"atbr_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atbr_1's raw form is: ['(bijna) nooit', '(bijna) nooit', '(bijna) nooit', 'soms', 'soms', 'vaak', 'soms', 'vaak', '(bijna) nooit', '(bijna) nooit', 'soms']\n"
     ]
    }
   ],
   "source": [
    "print(\"atbr_1's raw form is: \" + str(select_column('atbr_1', intake_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "atbr_1 is: [0, 0, 0, 1, 1, 3, 1, 3, 0, 0, 1]\n",
      "\n",
      "atbr_2 is: [0, 0, 0, 1, 1, 3, 1, 4, 0, 0, 3]\n",
      "\n",
      "atbr_3 is: [0, 4, 1, 1, 1, 2, 1, 4, 1, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(type_2, atbr_all_items, intake_data)\n",
    "\n",
    "print_columns(atbr_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep Quality (SQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6 items\n",
    "- Normal items: 1, 2, 3, 4, 5\n",
    "- Reverse items: 6\n",
    "- Conversion type: Unique\n",
    "- Sum: ranges from -4 to +19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq_all_items = [\"sq_1\", \"sq_2\", \"sq_3\", \"sq_4\", \"sq_5\", \"sq_6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special transformation dictionary for SQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this questionnaire has many unique response options, it has its own dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq_type_1 = {\n",
    "        \"binnen een kwartier\": 0,\n",
    "        \"binnen een half uur\": 1,\n",
    "        \"binnen een uur\": 2,\n",
    "        \"na meer dan een uur\": 4}\n",
    "    \n",
    "sq_type_2 = {\n",
    "    \"nooit\": 0,\n",
    "    \"1 nacht per week\": 1,\n",
    "    \"1 keer per nacht\": 1,      # This item is added as correction, as this value exists in the data, possibly as a result of erroneus encoding of answers during data collection.\n",
    "    \"2-3 nachten per week\": 2,\n",
    "    \"4-5 nachten per week\": 3,\n",
    "    \"6-7 nachten per week\": 4 }\n",
    "\n",
    "sq_type_3 = {\n",
    "    \"nooit\": 0,\n",
    "    \"1 keer per nacht\": 1,\n",
    "    \"2-3 keer per nacht\": 2,\n",
    "    \"4-5 keer per nacht\": 3,\n",
    "    \"6 keer of vaker per nacht\": 4}\n",
    "\n",
    "sq_type_4 = {\n",
    "    \"nooit\": 0, \n",
    "    \"1 nacht per week\": 1, \n",
    "    \"1 keer per nacht\": 1,      # This item is added as correction, as this value exists in the data, possibly as a result of erroneus encoding of answers during data collection.\n",
    "    \"2-3 nachten per week\": 2, \n",
    "    \"4-5 nachten per week\": 3, \n",
    "    \"(bijna) elke nacht\": 4}\n",
    "\n",
    "sq_type_5 = {\n",
    "    \"helemaal niet\": 0,\n",
    "    \"een beetje\": 1,\n",
    "    \"enigszins\": 2,\n",
    "    \"vaak\": 3,\n",
    "    \"heel vaak\": 4}\n",
    "\n",
    "sq_type_6 = {\n",
    "    \"erg slecht\": 0,\n",
    "    \"slecht\": -1,\n",
    "    \"redelijk goed\": -2,\n",
    "    \"goed\": -3,\n",
    "    \"erg goed\": -4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq_1's raw form is: ['binnen een kwartier', 'binnen een uur', 'binnen een kwartier', 'binnen een kwartier', 'binnen een half uur', 'binnen een uur', 'binnen een half uur', 'binnen een kwartier', 'binnen een half uur', 'binnen een kwartier', 'binnen een half uur']\n"
     ]
    }
   ],
   "source": [
    "print(\"sq_1's raw form is: \" + str(select_column(\"sq_1\", intake_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sq_1 is: [0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 1]\n",
      "\n",
      "sq_2 is: [0, 1, 0, 1, 1, 2, 1, 0, 0, 0, 2]\n",
      "\n",
      "sq_3 is: [0, 2, 2, 3, 0, 0, 2, 0, 2, 2, 1]\n",
      "\n",
      "sq_4 is: [0, 0, 0, 1, 2, 0, 2, 0, 3, 1, 1]\n",
      "\n",
      "sq_5 is: [1, 4, 0, 1, 1, 2, 1, 1, 3, 0, 1]\n",
      "\n",
      "sq_6 is: [-4, -2, -3, -2, -3, -2, -2, -3, -1, -2, -1]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(sq_type_1, [\"sq_1\"], intake_data)\n",
    "intake_data = transform_column_values(sq_type_2, [\"sq_2\"], intake_data)\n",
    "intake_data = transform_column_values(sq_type_3, [\"sq_3\"], intake_data)\n",
    "intake_data = transform_column_values(sq_type_4, [\"sq_4\"], intake_data)\n",
    "intake_data = transform_column_values(sq_type_5, [\"sq_5\"], intake_data)\n",
    "intake_data = transform_column_values(sq_type_6, [\"sq_6\"], intake_data)\n",
    "\n",
    "print_columns(sq_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chronotype (CHRON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8 items\n",
    "- Normal items: 2, 3, 5, 8\n",
    "- Reverse items: 1, 4, 6, 7\n",
    "- Conversion type: 1\n",
    "- Sum: ranges from -16 to +16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chron_all_items     = [\"chron_1\", \"chron_2\", \"chron_3\", \"chron_4\", \"chron_5\", \"chron_6\", \"chron_7\"]\n",
    "chron_regular_items = [\"chron_2\", \"chron_3\", \"chron_5\", \"chron_8\"]\n",
    "chron_reverse_items = [\"chron_1\", \"chron_4\", \"chron_6\", \"chron_7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chron_1's raw form is: ['helemaal eens', 'even vaak eens als oneens', 'even vaak eens als oneens', 'eens', 'even vaak eens als oneens', 'eens', 'even vaak eens als oneens', 'oneens', 'even vaak eens als oneens', 'even vaak eens als oneens', 'even vaak eens als oneens']\n"
     ]
    }
   ],
   "source": [
    "print(\"chron_1's raw form is: \" + str(select_column(\"chron_1\", intake_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chron_1 is: [-4, -2, -2, -3, -2, -3, -2, -1, -2, -2, -2]\n",
      "\n",
      "chron_2 is: [0, 3, 1, 1, 0, 4, 2, 2, 1, 1, 2]\n",
      "\n",
      "chron_3 is: [0, 4, 2, 2, 1, 1, 1, 3, 2, 2, 3]\n",
      "\n",
      "chron_4 is: [-4, 0, -3, -1, -2, 0, 0, 0, -2, -3, -1]\n",
      "\n",
      "chron_5 is: [1, 3, 2, 1, 2, 1, 3, 1, 2, 1, 2]\n",
      "\n",
      "chron_6 is: [-4, -2, -2, -3, -2, -1, -2, -2, -3, -3, -2]\n",
      "\n",
      "chron_7 is: [-4, -1, -2, -2, -2, -3, -2, -2, -2, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(type_1, chron_regular_items, intake_data)\n",
    "intake_data = transform_column_values(type_1_reverse, chron_reverse_items, intake_data)\n",
    "\n",
    "print_columns(chron_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Control Trait  (SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 13 items\n",
    "- Normal items: 1, 6, 8, 11\n",
    "- Reverse items: 2, 3, 4, 5, 7, 9, 10, 12, 13\n",
    "- Conversion type: 1\n",
    "- Sum: ranges from -36 to +16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_all_items = [\"sc_1\", \"sc_2\", \"sc_3\", \"sc_4\", \"sc_5\", \"sc_6\", \"sc_7\", \"sc_8\", \"sc_9\", \"sc_10\", \"sc_11\", \"sc_12\", \"sc_13\"]\n",
    "sc_regular_items = [\"sc_1\", \"sc_6\", \"sc_8\", \"sc_11\"]\n",
    "sc_reverse_items = [\"sc_2\", \"sc_3\", \"sc_4\", \"sc_5\", \"sc_7\", \"sc_9\", \"sc_10\", \"sc_12\", \"sc_13\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of string responses to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_1's raw form is: ['even vaak eens als oneens', 'oneens', 'oneens', 'eens', 'even vaak eens als oneens', 'oneens', 'oneens', 'oneens', 'even vaak eens als oneens', 'eens', 'even vaak eens als oneens']\n"
     ]
    }
   ],
   "source": [
    "print(\"sc_1's raw form is: \" + str(select_column(\"sc_1\", intake_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sc_1 is: [2, 1, 1, 3, 2, 1, 1, 1, 2, 3, 2]\n",
      "\n",
      "sc_2 is: [-2, -3, -3, -3, -2, -3, -3, -2, -3, -1, -2]\n",
      "\n",
      "sc_3 is: [0, 0, -3, -1, -1, -3, -2, -3, -1, 0, -1]\n",
      "\n",
      "sc_4 is: [0, 0, 0, -1, -1, 0, -1, 0, 0, 0, -2]\n",
      "\n",
      "sc_5 is: [-1, -2, -2, -3, -1, -3, -3, -4, -3, -2, -2]\n",
      "\n",
      "sc_6 is: [3, 2, 2, 3, 3, 1, 2, 1, 2, 1, 2]\n",
      "\n",
      "sc_7 is: [-2, -2, -3, -1, -1, -4, -4, -4, -1, -1, -3]\n",
      "\n",
      "sc_8 is: [3, 1, 1, 2, 2, 0, 1, 0, 2, 3, 2]\n",
      "\n",
      "sc_9 is: [-1, -2, -3, -3, -1, -1, -2, -3, 0, -1, -3]\n",
      "\n",
      "sc_10 is: [-3, -3, -2, -1, -1, -3, -1, -3, -1, -1, -2]\n",
      "\n",
      "sc_11 is: [2, 2, 1, 3, 2, 3, 2, 1, 3, 3, 2]\n",
      "\n",
      "sc_12 is: [-2, -2, -3, -3, -2, -3, -3, -3, -2, -1, -2]\n",
      "\n",
      "sc_13 is: [-1, 0, -2, -3, -1, -3, -2, -2, -1, -1, -2]\n"
     ]
    }
   ],
   "source": [
    "intake_data = transform_column_values(type_1, sc_regular_items, intake_data)\n",
    "intake_data = transform_column_values(type_1_reverse, sc_reverse_items, intake_data)\n",
    "\n",
    "print_columns(sc_all_items, intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating questionnaire scores and adding them to data\n",
    "**sc_scores | ats_scores | atbr_scores | sq_scores | chron_scores | sc_scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bptrt_scores = calculate_scores(bptrt_all_items, intake_data) # Bedtime Procrastination Trait (BPTRT) scores\n",
    "ats_scores   = calculate_scores(ats_all_items, intake_data)   # Aversiveness to Sleep (ATS) scores\n",
    "atbr_scores  = calculate_scores(atbr_all_items, intake_data)  # Aversiveness to Bedtime Routine (ATBR) scores\n",
    "sq_scores    = calculate_scores(sq_all_items, intake_data)    # Sleep Quality (SQ) scores\n",
    "chron_scores = calculate_scores(chron_all_items, intake_data) # Chronotype (CHRON) scores\n",
    "sc_scores    = calculate_scores(sc_all_items, intake_data)    # Self Control Trait (SC) scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scale_names =  [\"bptrt_score\",   \"ats_score\", \"atbr_score\",  \"sq_score\",  \"chron_score\",  \"sc_score\"]\n",
    "all_scores      =  [ bptrt_scores,   ats_scores,   atbr_scores,   sq_scores,   chron_scores,   sc_scores]\n",
    "\n",
    "for scale_name, participant_scores in zip(all_scale_names, all_scores): # iterate over two lists simulateneously\n",
    "    append_column(participant_scores, scale_name, intake_data)          # and use this iteration to change parameter values of append_column command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bptrt_score is: [-13.0, 0.0, 8.0, -5.0, -2.0, 5.0, 2.0, 11.0, -6.0, -8.0, 11.0]\n",
      "\n",
      "ats_score is: [-7.0, -3.0, -4.0, -1.0, -5.0, -4.0, -3.0, -2.0, -2.0, -3.0, -3.0]\n",
      "\n",
      "atbr_score is: [0.0, 4.0, 1.0, 3.0, 3.0, 8.0, 3.0, 11.0, 1.0, 0.0, 7.0]\n",
      "\n",
      "sq_score is: [-3.0, 7.0, -1.0, 4.0, 2.0, 4.0, 5.0, -2.0, 8.0, 1.0, 5.0]\n",
      "\n",
      "chron_score is: [-15.0, 5.0, -4.0, -5.0, -5.0, -1.0, 0.0, 1.0, -4.0, -5.0, 1.0]\n",
      "\n",
      "sc_score is: [-2.0, -8.0, -16.0, -8.0, -2.0, -18.0, -15.0, -21.0, -3.0, 2.0, -11.0]\n"
     ]
    }
   ],
   "source": [
    "print_columns(all_scale_names, intake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['date', 'consent', 'id', 'sex', 'age', 'edu', 'timezone_change', 'sleep_disorder', 'nightshift', 'psy_disorder', 'wake', 'young_kids', 'partn', 'bptrt_1', 'bptrt_2', 'bptrt_3', 'bptrt_4', 'bptrt_5', 'bptrt_6', 'bptrt_7', 'bptrt_8', 'bptrt_9', 'ats_1', 'atbr_1', 'sq_1', 'sq_2', 'sq_3', 'sq_4', 'sq_5', 'sq_6', 'atbr_2', 'atbr_3', 'ats_2', 'ats_3', 'chron_1', 'chron_2', 'chron_3', 'chron_4', 'chron_5', 'chron_6', 'chron_7', 'chron_8', 'sc_1', 'sc_2', 'sc_3', 'sc_4', 'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'sc_12', 'sc_13', 'bptrt_score', 'ats_score', 'atbr_score', 'sq_score', 'chron_score', 'sc_score'], ['2017/04/01 8:35:57 p.m. EET', 'Ja, ik neem deel', 'EM11', 'Vrouw', '44', 'HBO', 'Nee', 'Nee', 'Nee', 'Nee', 'Ja', 'Nee', 'Soms', 1, -4, -4, 1, 0, 1, -4, 0, -4, 0, 0, 0, 0, 0, 0, 1, -4, 0, 0, -3, -4, -4, 0, 0, -4, 1, -4, -4, 0, 2, -2, 0, 0, -1, 3, -2, 3, -1, -3, 2, -2, -1, -13.0, -7.0, 0.0, -3.0, -15.0, -2.0]]\n"
     ]
    }
   ],
   "source": [
    "print(intake_data[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data including all changes made up to this point (transposed for ease of viewing; columns -> rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 12 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: '2017/04/01 8:35:57 p.m. EET' '2017/04/01 8:15:27 p.m. EET' '2017/04/01 9:01:28 a.m. EET' '2017/04/01 5:17:20 p.m. EET' '2017/04/01 9:29:43 p.m. EET' '2017/04/01 11:08:39 p.m. EET' '2017/04/01 10:53:53 a.m. EET' '2017/04/01 12:22:06 a.m. EET' '2017/04/01 7:35:17 p.m. EET' '2017/04/01 8:55:08 a.m. EET' '2017/04/01 8:14:46 p.m. EET'\n",
      "consent: 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel' 'Ja ik neem deel'\n",
      "id: 'EM11' 'GH93' 'AB64' 'FT12' 'MJ87' 'PM61' 'JL25' 'GW98' 'HA61' 'WH18' 'HE46'\n",
      "sex: 'Vrouw' 'Man' 'Vrouw' 'Man' 'Vrouw' 'Man' 'Vrouw' 'Man' 'Man' 'Vrouw' 'Man'\n",
      "age: '44' '54' '49' '51' '23' '25' '44' '28' '51' '70' '44'\n",
      "edu: 'HBO' 'WO' 'WO' 'WO' 'WO' 'HBO' 'HBO' 'WO' 'WO' 'MBO' 'WO'\n",
      "timezone_change: 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee'\n",
      "sleep_disorder: 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee'\n",
      "nightshift: 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee'\n",
      "psy_disorder: 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee'\n",
      "wake: 'Ja' 'Ja' 'Ja' 'Nee' 'Nee' 'Ja' 'Ja' 'Nee' 'Ja' 'Nee' 'Ja'\n",
      "young_kids: 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee' 'Nee'\n",
      "partn: 'Soms' 'Soms' 'Niet van toepassing' 'Niet van toepassing' 'Niet van toepassing' 'Nooit' 'Soms' 'Nooit' 'Niet van toepassing' 'Nooit' 'Niet van toepassing'\n",
      "bptrt_1: 1 3 3 2 2 2 3 4 0 1 3\n",
      "bptrt_2: -4 -3 -1 -3 -2 -2 -2 0 -3 -1 -2\n",
      "bptrt_3: -4 -2 -1 -3 -3 -1 -2 -3 -3 -4 -1\n",
      "bptrt_4: 1 1 1 1 1 3 1 4 1 0 3\n",
      "bptrt_5: 0 1 3 1 1 2 2 1 1 0 3\n",
      "bptrt_6: 1 3 2 1 1 2 2 4 1 0 3\n",
      "bptrt_7: -4 0 0 -2 -1 -2 -1 0 -2 0 0\n",
      "bptrt_8: 0 1 3 1 1 2 1 2 1 0 3\n",
      "bptrt_9: -4 -4 -2 -3 -2 -1 -2 -1 -2 -4 -1\n",
      "ats_1: 0 3 0 1 0 2 1 2 0 0 1\n",
      "atbr_1: 0 0 0 1 1 3 1 3 0 0 1\n",
      "sq_1: 0 2 0 0 1 2 1 0 1 0 1\n",
      "sq_2: 0 1 0 1 1 2 1 0 0 0 2\n",
      "sq_3: 0 2 2 3 0 0 2 0 2 2 1\n",
      "sq_4: 0 0 0 1 2 0 2 0 3 1 1\n",
      "sq_5: 1 4 0 1 1 2 1 1 3 0 1\n",
      "sq_6: -4 -2 -3 -2 -3 -2 -2 -3 -1 -2 -1\n",
      "atbr_2: 0 0 0 1 1 3 1 4 0 0 3\n",
      "atbr_3: 0 4 1 1 1 2 1 4 1 0 3\n",
      "ats_2: -3 -3 0 -1 -1 -3 -2 0 0 0 -1\n",
      "ats_3: -4 -3 -4 -1 -4 -3 -2 -4 -2 -3 -3\n",
      "chron_1: -4 -2 -2 -3 -2 -3 -2 -1 -2 -2 -2\n",
      "chron_2: 0 3 1 1 0 4 2 2 1 1 2\n",
      "chron_3: 0 4 2 2 1 1 1 3 2 2 3\n",
      "chron_4: -4 0 -3 -1 -2 0 0 0 -2 -3 -1\n",
      "chron_5: 1 3 2 1 2 1 3 1 2 1 2\n",
      "chron_6: -4 -2 -2 -3 -2 -1 -2 -2 -3 -3 -2\n",
      "chron_7: -4 -1 -2 -2 -2 -3 -2 -2 -2 -1 -1\n",
      "chron_8: 0 4 0 1 0 3 2 1 0 1 2\n",
      "sc_1: 2 1 1 3 2 1 1 1 2 3 2\n",
      "sc_2: -2 -3 -3 -3 -2 -3 -3 -2 -3 -1 -2\n",
      "sc_3: 0 0 -3 -1 -1 -3 -2 -3 -1 0 -1\n",
      "sc_4: 0 0 0 -1 -1 0 -1 0 0 0 -2\n",
      "sc_5: -1 -2 -2 -3 -1 -3 -3 -4 -3 -2 -2\n",
      "sc_6: 3 2 2 3 3 1 2 1 2 1 2\n",
      "sc_7: -2 -2 -3 -1 -1 -4 -4 -4 -1 -1 -3\n",
      "sc_8: 3 1 1 2 2 0 1 0 2 3 2\n",
      "sc_9: -1 -2 -3 -3 -1 -1 -2 -3 0 -1 -3\n",
      "sc_10: -3 -3 -2 -1 -1 -3 -1 -3 -1 -1 -2\n",
      "sc_11: 2 2 1 3 2 3 2 1 3 3 2\n",
      "sc_12: -2 -2 -3 -3 -2 -3 -3 -3 -2 -1 -2\n",
      "sc_13: -1 0 -2 -3 -1 -3 -2 -2 -1 -1 -2\n",
      "bptrt_score: -13.0 0.0 8.0 -5.0 -2.0 5.0 2.0 11.0 -6.0 -8.0 11.0\n",
      "ats_score: -7.0 -3.0 -4.0 -1.0 -5.0 -4.0 -3.0 -2.0 -2.0 -3.0 -3.0\n",
      "atbr_score: 0.0 4.0 1.0 3.0 3.0 8.0 3.0 11.0 1.0 0.0 7.0\n",
      "sq_score: -3.0 7.0 -1.0 4.0 2.0 4.0 5.0 -2.0 8.0 1.0 5.0\n",
      "chron_score: -15.0 5.0 -4.0 -5.0 -5.0 -1.0 0.0 1.0 -4.0 -5.0 1.0\n",
      "sc_score: -2.0 -8.0 -16.0 -8.0 -2.0 -18.0 -15.0 -21.0 -3.0 2.0 -11.0\n"
     ]
    }
   ],
   "source": [
    "preview_data(intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age, sex, and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "age is: ['44', '54', '49', '51', '23', '25', '44', '28', '51', '70', '44']\n",
      "\n",
      "sex is: ['Vrouw', 'Man', 'Vrouw', 'Man', 'Vrouw', 'Man', 'Vrouw', 'Man', 'Man', 'Vrouw', 'Man']\n",
      "\n",
      "edu is: ['HBO', 'WO', 'WO', 'WO', 'WO', 'HBO', 'HBO', 'WO', 'WO', 'MBO', 'WO']\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"age\", \"sex\", \"edu\"], intake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "age is: [44, 54, 49, 51, 23, 25, 44, 28, 51, 70, 44]\n",
      "\n",
      "sex is: [1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "\n",
      "edu is: [3, 4, 4, 4, 4, 3, 3, 4, 4, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "# Transform 'sex' column from 'Vrouw', 'Man' to 'F' and 'M'\n",
    "intake_data = transform_column_values({'Man':0, \"Vrouw\":1, \"Other\":2}, [\"sex\"], intake_data)\n",
    "\n",
    "# Transform 'age' column values to integers:\n",
    "transform_column_type(\"age\", \"int\", intake_data)\n",
    "\n",
    "# Transform 'edu' column values to integers:\n",
    "intake_data = transform_column_values({'Middelbare school':0, \"LBO\":1, \"MBO\":2, \"HBO\":3, \"WO\":4}, [\"edu\"], intake_data)\n",
    "\n",
    "print_columns([\"age\", \"sex\", \"edu\"], intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes-No Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a problematic phrase to a single-word string, in order to be used in the next step.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "consent is: ['Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel', 'Ja, ik neem deel']\n",
      "\n",
      "consent is: ['Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print_columns(\"consent\", intake_data)\n",
    "transform_column_substring(\"Ja, ik neem deel\", \"Yes\", \"consent\", intake_data)\n",
    "print_columns(\"consent\", intake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 12 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: '2017/04/01 8:35:57 p.m. EET' '2017/04/01 8:15:27 p.m. EET' '2017/04/01 9:01:28 a.m. EET' '2017/04/01 5:17:20 p.m. EET' '2017/04/01 9:29:43 p.m. EET' '2017/04/01 11:08:39 p.m. EET' '2017/04/01 10:53:53 a.m. EET' '2017/04/01 12:22:06 a.m. EET' '2017/04/01 7:35:17 p.m. EET' '2017/04/01 8:55:08 a.m. EET' '2017/04/01 8:14:46 p.m. EET'\n",
      "consent: 1 1 1 1 1 1 1 1 1 1 1\n",
      "id: 'EM11' 'GH93' 'AB64' 'FT12' 'MJ87' 'PM61' 'JL25' 'GW98' 'HA61' 'WH18' 'HE46'\n",
      "sex: 1 0 1 0 1 0 1 0 0 1 0\n",
      "age: 44 54 49 51 23 25 44 28 51 70 44\n",
      "edu: 3 4 4 4 4 3 3 4 4 2 4\n",
      "timezone_change: 0 0 0 0 0 0 0 0 0 0 0\n",
      "sleep_disorder: 0 0 0 0 0 0 0 0 0 0 0\n",
      "nightshift: 0 0 0 0 0 0 0 0 0 0 0\n",
      "psy_disorder: 0 0 0 0 0 0 0 0 0 0 0\n",
      "wake: 1 1 1 0 0 1 1 0 1 0 1\n",
      "young_kids: 0 0 0 0 0 0 0 0 0 0 0\n",
      "partn: 1 1 0 0 0 0 1 0 0 0 0\n",
      "bptrt_1: 1 3 3 2 2 2 3 4 0 1 3\n",
      "bptrt_2: -4 -3 -1 -3 -2 -2 -2 0 -3 -1 -2\n",
      "bptrt_3: -4 -2 -1 -3 -3 -1 -2 -3 -3 -4 -1\n",
      "bptrt_4: 1 1 1 1 1 3 1 4 1 0 3\n",
      "bptrt_5: 0 1 3 1 1 2 2 1 1 0 3\n",
      "bptrt_6: 1 3 2 1 1 2 2 4 1 0 3\n",
      "bptrt_7: -4 0 0 -2 -1 -2 -1 0 -2 0 0\n",
      "bptrt_8: 0 1 3 1 1 2 1 2 1 0 3\n",
      "bptrt_9: -4 -4 -2 -3 -2 -1 -2 -1 -2 -4 -1\n",
      "ats_1: 0 3 0 1 0 2 1 2 0 0 1\n",
      "atbr_1: 0 0 0 1 1 3 1 3 0 0 1\n",
      "sq_1: 0 2 0 0 1 2 1 0 1 0 1\n",
      "sq_2: 0 1 0 1 1 2 1 0 0 0 2\n",
      "sq_3: 0 2 2 3 0 0 2 0 2 2 1\n",
      "sq_4: 0 0 0 1 2 0 2 0 3 1 1\n",
      "sq_5: 1 4 0 1 1 2 1 1 3 0 1\n",
      "sq_6: -4 -2 -3 -2 -3 -2 -2 -3 -1 -2 -1\n",
      "atbr_2: 0 0 0 1 1 3 1 4 0 0 3\n",
      "atbr_3: 0 4 1 1 1 2 1 4 1 0 3\n",
      "ats_2: -3 -3 0 -1 -1 -3 -2 0 0 0 -1\n",
      "ats_3: -4 -3 -4 -1 -4 -3 -2 -4 -2 -3 -3\n",
      "chron_1: -4 -2 -2 -3 -2 -3 -2 -1 -2 -2 -2\n",
      "chron_2: 0 3 1 1 0 4 2 2 1 1 2\n",
      "chron_3: 0 4 2 2 1 1 1 3 2 2 3\n",
      "chron_4: -4 0 -3 -1 -2 0 0 0 -2 -3 -1\n",
      "chron_5: 1 3 2 1 2 1 3 1 2 1 2\n",
      "chron_6: -4 -2 -2 -3 -2 -1 -2 -2 -3 -3 -2\n",
      "chron_7: -4 -1 -2 -2 -2 -3 -2 -2 -2 -1 -1\n",
      "chron_8: 0 4 0 1 0 3 2 1 0 1 2\n",
      "sc_1: 2 1 1 3 2 1 1 1 2 3 2\n",
      "sc_2: -2 -3 -3 -3 -2 -3 -3 -2 -3 -1 -2\n",
      "sc_3: 0 0 -3 -1 -1 -3 -2 -3 -1 0 -1\n",
      "sc_4: 0 0 0 -1 -1 0 -1 0 0 0 -2\n",
      "sc_5: -1 -2 -2 -3 -1 -3 -3 -4 -3 -2 -2\n",
      "sc_6: 3 2 2 3 3 1 2 1 2 1 2\n",
      "sc_7: -2 -2 -3 -1 -1 -4 -4 -4 -1 -1 -3\n",
      "sc_8: 3 1 1 2 2 0 1 0 2 3 2\n",
      "sc_9: -1 -2 -3 -3 -1 -1 -2 -3 0 -1 -3\n",
      "sc_10: -3 -3 -2 -1 -1 -3 -1 -3 -1 -1 -2\n",
      "sc_11: 2 2 1 3 2 3 2 1 3 3 2\n",
      "sc_12: -2 -2 -3 -3 -2 -3 -3 -3 -2 -1 -2\n",
      "sc_13: -1 0 -2 -3 -1 -3 -2 -2 -1 -1 -2\n",
      "bptrt_score: -13.0 0.0 8.0 -5.0 -2.0 5.0 2.0 11.0 -6.0 -8.0 11.0\n",
      "ats_score: -7.0 -3.0 -4.0 -1.0 -5.0 -4.0 -3.0 -2.0 -2.0 -3.0 -3.0\n",
      "atbr_score: 0.0 4.0 1.0 3.0 3.0 8.0 3.0 11.0 1.0 0.0 7.0\n",
      "sq_score: -3.0 7.0 -1.0 4.0 2.0 4.0 5.0 -2.0 8.0 1.0 5.0\n",
      "chron_score: -15.0 5.0 -4.0 -5.0 -5.0 -1.0 0.0 1.0 -4.0 -5.0 1.0\n",
      "sc_score: -2.0 -8.0 -16.0 -8.0 -2.0 -18.0 -15.0 -21.0 -3.0 2.0 -11.0\n"
     ]
    }
   ],
   "source": [
    "conversions_dictionary = {\n",
    "    \"Ja\":1, \"Nee\":0, \n",
    "    \"Yes\":1, \"No\":0,\n",
    "    \"Nooit\":0, \"Soms\":1, \"Vaak\":2, \"Altijd\":3, \"Niet van toepassing\":0\n",
    "}\n",
    "\n",
    "transform_column_values(conversions_dictionary, [\"timezone_change\", \"sleep_disorder\", \"nightshift\", \"psy_disorder\", \"wake\", \"young_kids\", \"consent\", \"partn\"], intake_data)\n",
    "preview_data(intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the \"date\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/01 8:35:57 p.m. EET\n",
      "2017/04/01 8:15:27 p.m. EET\n",
      "2017/04/01 9:01:28 a.m. EET\n",
      "2017/04/01 5:17:20 p.m. EET\n",
      "2017/04/01 9:29:43 p.m. EET\n",
      "2017/04/01 11:08:39 p.m. EET\n",
      "2017/04/01 10:53:53 a.m. EET\n",
      "2017/04/01 12:22:06 a.m. EET\n",
      "2017/04/01 7:35:17 p.m. EET\n",
      "2017/04/01 8:55:08 a.m. EET\n",
      "2017/04/01 8:14:46 p.m. EET\n"
     ]
    }
   ],
   "source": [
    "print_column_vertically(\"date\", intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some strings should be converted (e.g., \"a.m.\" --> \"AM) in order to prepare them for parsing with datetime.datetime() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/01 8:35:57 p.m. EET\n",
      "2017/04/01 8:15:27 p.m. EET\n",
      "2017/04/01 9:01:28 a.m. EET\n",
      "2017/04/01 5:17:20 p.m. EET\n",
      "2017/04/01 9:29:43 p.m. EET\n",
      "2017/04/01 11:08:39 p.m. EET\n",
      "2017/04/01 10:53:53 a.m. EET\n",
      "2017/04/01 12:22:06 a.m. EET\n",
      "2017/04/01 7:35:17 p.m. EET\n",
      "2017/04/01 8:55:08 a.m. EET\n",
      "2017/04/01 8:14:46 p.m. EET\n"
     ]
    }
   ],
   "source": [
    "date_column = select_column(\"date\", intake_data)\n",
    "for i, date in enumerate(date_column):\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/01 8:35:57 PM UTC+0200\n",
      "2017/04/01 8:15:27 PM UTC+0200\n",
      "2017/04/01 9:01:28 AM UTC+0200\n",
      "2017/04/01 5:17:20 PM UTC+0200\n",
      "2017/04/01 9:29:43 PM UTC+0200\n",
      "2017/04/01 11:08:39 PM UTC+0200\n",
      "2017/04/01 10:53:53 AM UTC+0200\n",
      "2017/04/01 12:22:06 AM UTC+0200\n",
      "2017/04/01 7:35:17 PM UTC+0200\n",
      "2017/04/01 8:55:08 AM UTC+0200\n",
      "2017/04/01 8:14:46 PM UTC+0200\n",
      "\n",
      " Type of dates is:\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "transform_column_substring(\"a.m.\", \"AM\", \"date\", intake_data)\n",
    "transform_column_substring(\"p.m.\", \"PM\", \"date\", intake_data)\n",
    "transform_column_substring(\"EET\", \"UTC+0200\", \"date\", intake_data)\n",
    "\n",
    "print_column_vertically(\"date\", intake_data)\n",
    "\n",
    "print(\"\\n Type of dates is:\")\n",
    "print(type(select_column(\"date\", intake_data)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-01 20:35:57+02:00\n",
      "2017-04-01 20:15:27+02:00\n",
      "2017-04-01 09:01:28+02:00\n",
      "2017-04-01 17:17:20+02:00\n",
      "2017-04-01 21:29:43+02:00\n",
      "2017-04-01 23:08:39+02:00\n",
      "2017-04-01 10:53:53+02:00\n",
      "2017-04-01 00:22:06+02:00\n",
      "2017-04-01 19:35:17+02:00\n",
      "2017-04-01 08:55:08+02:00\n",
      "2017-04-01 20:14:46+02:00\n",
      "\n",
      " Type of dates is now:\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "date_column = select_column(\"date\", intake_data)\n",
    "\n",
    "for i, date in enumerate(date_column): \n",
    "    date_column[i] = datetime.datetime.strptime(date_column[i], \"%Y/%m/%d %I:%M:%S %p %Z%z\")    \n",
    "\n",
    "replace_column(date_column, \"date\", intake_data)\n",
    "\n",
    "# Print new dates line by line\n",
    "print_column_vertically(\"date\", intake_data)\n",
    "print(\"\\n Type of dates is now:\")\n",
    "print(type(date_column[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"date\" column is now parsed/converted into a datetime object from a string. \n",
    "\n",
    "Datetime objecs can be used in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_column[0].month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes of 'datetime.datetime' objects:\n",
    "- year\n",
    "- month\n",
    "- day\n",
    "- hour\n",
    "- minute\n",
    "- second\n",
    "- microsecond\n",
    "\n",
    "For more on datetime,see: https://docs.python.org/3/library/datetime.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 12 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: datetime.datetime(2017 4 1 20 35 57 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 20 15 27 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 9 1 28 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 17 17 20 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 21 29 43 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 23 8 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 10 53 53 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 0 22 6 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 19 35 17 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 8 55 8 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 1 20 14 46 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "consent: 1 1 1 1 1 1 1 1 1 1 1\n",
      "id: 'EM11' 'GH93' 'AB64' 'FT12' 'MJ87' 'PM61' 'JL25' 'GW98' 'HA61' 'WH18' 'HE46'\n",
      "sex: 1 0 1 0 1 0 1 0 0 1 0\n",
      "age: 44 54 49 51 23 25 44 28 51 70 44\n",
      "edu: 3 4 4 4 4 3 3 4 4 2 4\n",
      "timezone_change: 0 0 0 0 0 0 0 0 0 0 0\n",
      "sleep_disorder: 0 0 0 0 0 0 0 0 0 0 0\n",
      "nightshift: 0 0 0 0 0 0 0 0 0 0 0\n",
      "psy_disorder: 0 0 0 0 0 0 0 0 0 0 0\n",
      "wake: 1 1 1 0 0 1 1 0 1 0 1\n",
      "young_kids: 0 0 0 0 0 0 0 0 0 0 0\n",
      "partn: 1 1 0 0 0 0 1 0 0 0 0\n",
      "bptrt_1: 1 3 3 2 2 2 3 4 0 1 3\n",
      "bptrt_2: -4 -3 -1 -3 -2 -2 -2 0 -3 -1 -2\n",
      "bptrt_3: -4 -2 -1 -3 -3 -1 -2 -3 -3 -4 -1\n",
      "bptrt_4: 1 1 1 1 1 3 1 4 1 0 3\n",
      "bptrt_5: 0 1 3 1 1 2 2 1 1 0 3\n",
      "bptrt_6: 1 3 2 1 1 2 2 4 1 0 3\n",
      "bptrt_7: -4 0 0 -2 -1 -2 -1 0 -2 0 0\n",
      "bptrt_8: 0 1 3 1 1 2 1 2 1 0 3\n",
      "bptrt_9: -4 -4 -2 -3 -2 -1 -2 -1 -2 -4 -1\n",
      "ats_1: 0 3 0 1 0 2 1 2 0 0 1\n",
      "atbr_1: 0 0 0 1 1 3 1 3 0 0 1\n",
      "sq_1: 0 2 0 0 1 2 1 0 1 0 1\n",
      "sq_2: 0 1 0 1 1 2 1 0 0 0 2\n",
      "sq_3: 0 2 2 3 0 0 2 0 2 2 1\n",
      "sq_4: 0 0 0 1 2 0 2 0 3 1 1\n",
      "sq_5: 1 4 0 1 1 2 1 1 3 0 1\n",
      "sq_6: -4 -2 -3 -2 -3 -2 -2 -3 -1 -2 -1\n",
      "atbr_2: 0 0 0 1 1 3 1 4 0 0 3\n",
      "atbr_3: 0 4 1 1 1 2 1 4 1 0 3\n",
      "ats_2: -3 -3 0 -1 -1 -3 -2 0 0 0 -1\n",
      "ats_3: -4 -3 -4 -1 -4 -3 -2 -4 -2 -3 -3\n",
      "chron_1: -4 -2 -2 -3 -2 -3 -2 -1 -2 -2 -2\n",
      "chron_2: 0 3 1 1 0 4 2 2 1 1 2\n",
      "chron_3: 0 4 2 2 1 1 1 3 2 2 3\n",
      "chron_4: -4 0 -3 -1 -2 0 0 0 -2 -3 -1\n",
      "chron_5: 1 3 2 1 2 1 3 1 2 1 2\n",
      "chron_6: -4 -2 -2 -3 -2 -1 -2 -2 -3 -3 -2\n",
      "chron_7: -4 -1 -2 -2 -2 -3 -2 -2 -2 -1 -1\n",
      "chron_8: 0 4 0 1 0 3 2 1 0 1 2\n",
      "sc_1: 2 1 1 3 2 1 1 1 2 3 2\n",
      "sc_2: -2 -3 -3 -3 -2 -3 -3 -2 -3 -1 -2\n",
      "sc_3: 0 0 -3 -1 -1 -3 -2 -3 -1 0 -1\n",
      "sc_4: 0 0 0 -1 -1 0 -1 0 0 0 -2\n",
      "sc_5: -1 -2 -2 -3 -1 -3 -3 -4 -3 -2 -2\n",
      "sc_6: 3 2 2 3 3 1 2 1 2 1 2\n",
      "sc_7: -2 -2 -3 -1 -1 -4 -4 -4 -1 -1 -3\n",
      "sc_8: 3 1 1 2 2 0 1 0 2 3 2\n",
      "sc_9: -1 -2 -3 -3 -1 -1 -2 -3 0 -1 -3\n",
      "sc_10: -3 -3 -2 -1 -1 -3 -1 -3 -1 -1 -2\n",
      "sc_11: 2 2 1 3 2 3 2 1 3 3 2\n",
      "sc_12: -2 -2 -3 -3 -2 -3 -3 -3 -2 -1 -2\n",
      "sc_13: -1 0 -2 -3 -1 -3 -2 -2 -1 -1 -2\n",
      "bptrt_score: -13.0 0.0 8.0 -5.0 -2.0 5.0 2.0 11.0 -6.0 -8.0 11.0\n",
      "ats_score: -7.0 -3.0 -4.0 -1.0 -5.0 -4.0 -3.0 -2.0 -2.0 -3.0 -3.0\n",
      "atbr_score: 0.0 4.0 1.0 3.0 3.0 8.0 3.0 11.0 1.0 0.0 7.0\n",
      "sq_score: -3.0 7.0 -1.0 4.0 2.0 4.0 5.0 -2.0 8.0 1.0 5.0\n",
      "chron_score: -15.0 5.0 -4.0 -5.0 -5.0 -1.0 0.0 1.0 -4.0 -5.0 1.0\n",
      "sc_score: -2.0 -8.0 -16.0 -8.0 -2.0 -18.0 -15.0 -21.0 -3.0 2.0 -11.0\n"
     ]
    }
   ],
   "source": [
    "preview_data(intake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make a class from the dataset to enable easy access to variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Canceled</font> <br>\n",
    "This is intended to enable easy manipulation of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Intake ():\n",
    "#     def __init__(self):\n",
    "#         self.date               = select_column(\"date\", intake_data)\n",
    "#         self.consent            = select_column(\"consent\", intake_data)\n",
    "#         self.id                 = select_column(\"id\", intake_data)\n",
    "#         self.sex                = select_column(\"sex\", intake_data)\n",
    "#         self.age                = select_column(\"age\", intake_data)\n",
    "#         self.timezone_change    = select_column(\"timezone_change\", intake_data)\n",
    "#         self.sleep_disorder     = select_column(\"sleep_disorder\", intake_data)\n",
    "#         self.nightshift         = select_column(\"nightshift\", intake_data)\n",
    "#         self.psy_disorder       = select_column(\"psy_disorder\", intake_data)\n",
    "#         self.wake               = select_column(\"wake\", intake_data)\n",
    "#         self.young_kids         = select_column(\"young_kids\", intake_data)\n",
    "#         self.partn              = select_column(\"partn\", intake_data)\n",
    "#         self.bptrt_scores       = select_column(\"bptrt_score\", intake_data)\n",
    "#         self.ats_scores         = select_column(\"ats_score\", intake_data)\n",
    "#         self.atbr_scores        = select_column(\"atbr_score\", intake_data)\n",
    "#         self.sq_scores          = select_column(\"sq_score\", intake_data)\n",
    "#         self.chron_scores       = select_column(\"chron_score\", intake_data)\n",
    "#         self.sc_scores          = select_column(\"sc_score\", intake_data)\n",
    "# intake = Intake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print (intake.age)\n",
    "# print (intake.sc_scores[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(intake.date[0])\n",
    "# print(intake.date[0].hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"daily-data\"></a>\n",
    "# DAILY QUESTIONNAIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, tokenize it, and read it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "daily_data = list(csv.reader(open(\"data//original_data//dagelijkse-vragenlijst-v4.3.csv\", encoding=\"utf8\"), delimiter=\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tijdstempel', 'Wat is je ID?', 'Hoe laat ging je naar bed gisteren?', 'Ging je gisteren later naar bed dan gepland?']\n"
     ]
    }
   ],
   "source": [
    "print(daily_data[0][0:4]) # Print first headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tijdstempel', 'Wat is je ID?', 'Hoe laat ging je naar bed gisteren?', 'Ging je gisteren later naar bed dan gepland?', 'Indien je gisteren later naar bed ging dan gepland, kun je hier een reden voor geven?', 'Hoe laat stond je op vandaag?', 'Toen je gisteren naar bed ging, viel je in slaap…', 'Had je moeite om in slaap te vallen?', 'Hoe vaak werd je wakker afgelopen nacht? (bijv. om naar het toilet te gaan)', 'Werd je spontaan veel eerder wakker dan nodig? (d.w.z. veel eerder dan je geplande wektijd)', 'Indien je ’s nachts of ’s ochtends vroeg wakker werd, was dit een probleem voor jou?', 'Ongeacht de duur ervan, hoe zou je de kwaliteit van je slaap omschrijven? ', 'In welke mate ben je gisteravond nog fysiek actief geweest de laatste twee uur voor je naar bed ging? (bijv. wandelen, sporten, klussen, huishouden) ', 'In welke mate ben je gisteravond nog mentaal actief geweest de laatste twee uur voordat je naar bed ging? (bijv. boek of mails lezen, werken, studeren)', 'Denkend aan de dag van gisteren, hoeveel sociale interacties heb je gisteren ongeveer gehad? (bijv. gesprek, telefoongesprek, chat)', 'Hoe lang ben je de laatste twee uur voordat je naar bed ging blootgesteld aan fel licht?  (bijv. van TV, computer, tablet, mobieltje, badkamer)', 'Probeer je voor de geest te halen hoe de laatste drie uur voor je bedtijd eruit zagen. Schrijf in steekwoorden op wat je in die periode hebt gedaan.', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Roken]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Eten uit verveling]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Uit verveling een praatje houden, bellen of chatten]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Koffie drinken]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Rondhangen op social media]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Doelloos surfen op het internet]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [TV kijken uit verveling (bijv. zappen)]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Drinken van alcoholische drank]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Drinken van niet-alcoholische drank (bijv. frisdrank)]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Schoonmaken of opruimen uit verveling]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Dingen kopen die je niet strict nodig hebt]', 'Blijvend bij de periode van drie uur voor je bedtijd, heb je één of meerdere van de volgende verleidingen ervaren? [Andere dingen doen die op dat moment niet nuttig of belangrijk waren]', 'Hoe laat ben je van plan naar bed te gaan vanavond?', 'Steps afgelopen dag', 'active_minutes', 'Zonuren afgelopen dag']\n"
     ]
    }
   ],
   "source": [
    "print(daily_data[0]) # Print first headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017/04/10 9:57:26 a.m. EET', 'AB64', '02:00', 'Ja', 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling', '09:30', 'binnen een kwartier', 'Nee', '0 keer', 'Nee', 'Helemaal niet', 'Goed', 'Licht actief', 'Licht actief', '6-sep', 'Minder dan een half uur', 'Theaterbezoek, autorit (bijrijder)', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Toegegeven aan verleiding', 'Geen verleiding ervaren', 'Toegegeven aan verleiding', 'Toegegeven aan verleiding', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', '23:00', '5845', '5', '12,3']\n"
     ]
    }
   ],
   "source": [
    "print(daily_data[1]) # <-- Print an example row from daily dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['questionnaire_timestamp', 'id', 'bed_time', 'late', 'late_reason', 'wake_time', 'sleep_transition', 'sleep_struggle', 'night_wake', 'wake_earlier', 'wake_earlier_problem', 'sleep_quality', 'physical_activity', 'mental_digital_activity', 'social_activity', 'light', 'presleep_description', 'temptation_smoking', 'temptation_eating', 'temptation_chat', 'temptation_coffee', 'temptation_social_media', 'temptation_internet', 'temptation_tv', 'temptation_alcohol', 'temptation_soft_drink', 'temptation_cleaning', 'temptation_shopping', 'temptation_other', 'bed_time_plan', 'steps', 'active_minutes', 'sun_hours'], ['2017/04/10 9:57:26 a.m. EET', 'AB64', '02:00', 'Ja', 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling', '09:30', 'binnen een kwartier', 'Nee', '0 keer', 'Nee', 'Helemaal niet', 'Goed', 'Licht actief', 'Licht actief', '6-sep', 'Minder dan een half uur', 'Theaterbezoek, autorit (bijrijder)', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Toegegeven aan verleiding', 'Geen verleiding ervaren', 'Toegegeven aan verleiding', 'Toegegeven aan verleiding', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', 'Geen verleiding ervaren', '23:00', '5845', '5', '12,3']]\n"
     ]
    }
   ],
   "source": [
    "headers_list = [\n",
    "    \"questionnaire_timestamp\", \"id\", \n",
    "    \n",
    "    \"bed_time\", \"late\", \"late_reason\", \"wake_time\", \"sleep_transition\", \n",
    "    \"sleep_struggle\", \"night_wake\", \"wake_earlier\", \"wake_earlier_problem\", \"sleep_quality\", \n",
    "    \n",
    "    \"physical_activity\", \"mental_digital_activity\", \"social_activity\", \"light\", \"presleep_description\", \n",
    "    \"temptation_smoking\", \"temptation_eating\", \"temptation_chat\", \"temptation_coffee\", \"temptation_social_media\", \n",
    "    \"temptation_internet\", \"temptation_tv\", \"temptation_alcohol\", \"temptation_soft_drink\", \"temptation_cleaning\", \n",
    "    \"temptation_shopping\", \"temptation_other\", \"bed_time_plan\",\n",
    "    \n",
    "    \"steps\", \"active_minutes\", \"sun_hours\"\n",
    "]\n",
    "\n",
    "replace_headers(headers_list, daily_data)\n",
    "\n",
    "print(daily_data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 3 values per column.\n",
      "=============================================================\n",
      "\n",
      "questionnaire_timestamp: '2017/04/10 9:57:26 a.m. EET' '2017/04/11 11:25:39 p.m. EET' '2017/04/12 7:42:47 a.m. EET'\n",
      "id: 'AB64' 'AB64' 'AB64'\n",
      "bed_time: '02:00' '23:45' '23:55'\n",
      "late: 'Ja' 'Ja' 'Ja'\n",
      "late_reason: 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling' '' 'Man kwam thuis en daar wilde ik nog even mee praten'\n",
      "wake_time: '09:30' '07:00' '07:00'\n",
      "sleep_transition: 'binnen een kwartier' 'binnen een kwartier' 'binnen een kwartier'\n",
      "sleep_struggle: 'Nee' 'Nee' 'Nee'\n",
      "night_wake: '0 keer' '6 keer of meer' '2-3 keer'\n",
      "wake_earlier: 'Nee' 'Nee' 'Nee'\n",
      "wake_earlier_problem: 'Helemaal niet' 'Helemaal niet' 'Helemaal niet'\n",
      "sleep_quality: 'Goed' 'Goed' 'Matig'\n",
      "physical_activity: 'Licht actief' 'Licht actief' 'Nauwelijks actief'\n",
      "mental_digital_activity: 'Licht actief' 'Licht actief' 'Nauwelijks actief'\n",
      "social_activity: '6-sep' '6-sep' '10 of meer'\n",
      "light: 'Minder dan een half uur' 'Meer dan een uur' 'Meer dan een uur'\n",
      "presleep_description: 'Theaterbezoek autorit (bijrijder)' 'Tv kijken' 'Poging om Netflix te kijken maar was te moe praten met huisgenoten '\n",
      "temptation_smoking: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_eating: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_chat: 'Toegegeven aan verleiding' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_coffee: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_social_media: 'Toegegeven aan verleiding' 'Toegegeven aan verleiding' 'Geen verleiding ervaren'\n",
      "temptation_internet: 'Toegegeven aan verleiding' 'Toegegeven aan verleiding' 'Geen verleiding ervaren'\n",
      "temptation_tv: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_alcohol: 'Geen verleiding ervaren' 'Toegegeven aan verleiding' 'Toegegeven aan verleiding'\n",
      "temptation_soft_drink: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_cleaning: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_shopping: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_other: 'Geen verleiding ervaren' 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "bed_time_plan: '23:00' '23:30' '23:00'\n",
      "steps: '5845' '7649' '5012'\n",
      "active_minutes: '5' '0' '3'\n",
      "sun_hours: '123' '88' '107'\n"
     ]
    }
   ],
   "source": [
    "preview_data(daily_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert string answers to integers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic string to integer conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform values such as \"8,4\" to \"8.4\", so they are convertible to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Caution: This function can only be ran once.\n",
    "transform_column_substring(\",\", \".\", [\"sun_hours\"], daily_data)\n",
    "print(\"\") # intentional blank output to prevent long output from function return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform 'int' to int and 'float' to float: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "steps is: [5845.0, 7649.0, 5012.0, 2467.0, 2114.0, 2943.0, 2288.0, 3015.0, 3866.0, 4312.0, 2987.0, 2231.0, 2177.0, 5604.0, 6897.0, 8722.0, 3389.0, 2905.0, 3487.0, 5633.0, 8149.0, 7739.0, 6492.0, 8606.0, 2544.0, 20491.0, 8714.0, 15697.0, 6879.0, 4309.0, 19412.0, 1785.0, 10256.0, 5644.0, 8838.0, 4596.0, 14091.0, 2467.0, 3942.0, 6841.0, 5599.0, 9176.0, 3981.0, 5945.0, 22341.0, 3649.0, 11915.0, 16744.0, 2206.0, 12947.0, 16402.0, 19361.0, 14363.0, 4682.0, 11877.0, 6904.0, 2987.0, 4733.0, 2902.0, 3794.0, 12903.0, 8421.0, 6918.0, 6787.0, 5735.0, 17114.0, 18335.0, 3319.0, 9452.0, 2218.0, 2944.0, 3906.0, 3454.0, 5469.0, 2991.0, 4885.0, 3602.0, 4049.0, 2011.0, 6084.0, 5439.0, 13097.0, 3901.0, 8840.0, 4063.0, 4478.0, 5567.0, 3737.0, 22091.0, 6455.0, 4733.0, 20691.0, 17630.0, 3214.0, 2478.0, 4266.0, 3697.0, 10193.0, 9424.0, 6061.0, 9072.0, 14043.0, 15292.0, 13163.0, 5937.0, 7647.0, 11946.0, 7899.0, 3962.0, 9057.0, 3200.0, 6484.0, 5363.0, 5244.0, 3687.0, 14568.0, 5928.0, 3953.0, 8599.0, 4493.0, 2708.0, 6770.0, 8186.0, 10586.0, 6246.0, 8213.0, 3673.0, 6731.0, 5315.0, 3123.0, 3325.0, 3466.0, 15943.0, 4069.0, 2397.0, 5646.0, 5918.0, 5743.0, 5609.0, 2499.0, 11129.0, 7209.0, 8042.0, 4918.0, 10661.0, 4582.0, 3420.0, 3311.0, 3619.0, 4158.0, 2653.0, 2267.0, 3345.0, 3589.0, 4121.0, 2284.0, 5169.0, 8694.0, 6612.0, 3074.0, 10536.0, 2671.0, 2844.0, 2596.0, 2933.0, 3577.0, 3945.0, 2557.0, 4651.0]\n",
      "\n",
      "sun_hours is: [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 5.5, 12.3, 5.3, 8.6, 0.9, 7.7, 2.4, 4.7, 3.4, 7.4, 9.2, 7.1, 12.3, 0.4, 7.8, 12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8, 5.3, 9.4, 9.0, 6.3, 12.5, 0.7, 6.3, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 7.9, 6.7, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 7.5, 12.3, 6.2, 10.3, 0.9, 6.6, 4.8, 4.5, 2.9, 9.9, 10.2, 7.9, 11.5, 0.3, 6.8, 6.8, 1.9, 7.6, 8.0, 12.5, 1.9, 1.6, 0.1, 6.6, 0.6, 6.8, 8.6, 7.6, 6.3, 5.1, 9.8, 1.1, 6.9, 9.7, 2.4, 10.4, 8.1, 8.1]\n",
      "\n",
      "active_minutes is: [5.0, 0.0, 3.0, 1.0, 2.0, 0.0, 6.0, 11.0, 1.0, 9.0, 2.0, 1.0, 0.0, 22.0, 3.0, 2.0, 0.0, 0.0, 2.0, 1.0, 8.0, 7.0, 3.0, 11.0, 1.0, 44.0, 5.0, 31.0, 1.0, 0.0, 20.0, 0.0, 10.0, 1.0, 3.0, 2.0, 15.0, 1.0, 3.0, 5.0, 2.0, 19.0, 9.0, 1.0, 33.0, 3.0, 7.0, 15.0, 0.0, 5.0, 20.0, 23.0, 11.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 5.0, 10.0, 9.0, 5.0, 2.0, 3.0, 17.0, 37.0, 0.0, 13.0, 0.0, 1.0, 3.0, 6.0, 2.0, 1.0, 8.0, 6.0, 3.0, 1.0, 2.0, 4.0, 14.0, 1.0, 6.0, 2.0, 2.0, 3.0, 1.0, 37.0, 2.0, 3.0, 36.0, 20.0, 2.0, 2.0, 3.0, 1.0, 11.0, 6.0, 3.0, 7.0, 18.0, 12.0, 14.0, 3.0, 8.0, 19.0, 9.0, 4.0, 7.0, 2.0, 4.0, 1.0, 2.0, 1.0, 16.0, 5.0, 3.0, 6.0, 4.0, 2.0, 3.0, 5.0, 10.0, 3.0, 9.0, 2.0, 5.0, 3.0, 1.0, 2.0, 3.0, 11.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 0.0, 7.0, 3.0, 4.0, 2.0, 13.0, 4.0, 1.0, 2.0, 5.0, 4.0, 0.0, 1.0, 3.0, 2.0, 3.0, 0.0, 3.0, 6.0, 3.0, 2.0, 16.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "transform_column_type(\"steps\", \"float\", daily_data)\n",
    "transform_column_type(\"sun_hours\", \"float\", daily_data)\n",
    "transform_column_type(\"active_minutes\", \"float\", daily_data)\n",
    "\n",
    "\n",
    "print_columns([\"steps\", \"sun_hours\", \"active_minutes\"], daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific string to integer conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 2 values per column.\n",
      "=============================================================\n",
      "\n",
      "questionnaire_timestamp: '2017/04/10 9:57:26 a.m. EET' '2017/04/11 11:25:39 p.m. EET'\n",
      "id: 'AB64' 'AB64'\n",
      "bed_time: '02:00' '23:45'\n",
      "late: 'Ja' 'Ja'\n",
      "late_reason: 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling' ''\n",
      "wake_time: '09:30' '07:00'\n",
      "sleep_transition: 'binnen een kwartier' 'binnen een kwartier'\n",
      "sleep_struggle: 'Nee' 'Nee'\n",
      "night_wake: '0 keer' '6 keer of meer'\n",
      "wake_earlier: 'Nee' 'Nee'\n",
      "wake_earlier_problem: 'Helemaal niet' 'Helemaal niet'\n",
      "sleep_quality: 'Goed' 'Goed'\n",
      "physical_activity: 'Licht actief' 'Licht actief'\n",
      "mental_digital_activity: 'Licht actief' 'Licht actief'\n",
      "social_activity: '6-sep' '6-sep'\n",
      "light: 'Minder dan een half uur' 'Meer dan een uur'\n",
      "presleep_description: 'Theaterbezoek autorit (bijrijder)' 'Tv kijken'\n",
      "temptation_smoking: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_eating: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_chat: 'Toegegeven aan verleiding' 'Geen verleiding ervaren'\n",
      "temptation_coffee: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_social_media: 'Toegegeven aan verleiding' 'Toegegeven aan verleiding'\n",
      "temptation_internet: 'Toegegeven aan verleiding' 'Toegegeven aan verleiding'\n",
      "temptation_tv: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_alcohol: 'Geen verleiding ervaren' 'Toegegeven aan verleiding'\n",
      "temptation_soft_drink: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_cleaning: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_shopping: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "temptation_other: 'Geen verleiding ervaren' 'Geen verleiding ervaren'\n",
      "bed_time_plan: '23:00' '23:30'\n",
      "steps: 5845.0 7649.0\n",
      "active_minutes: 5.0 0.0\n",
      "sun_hours: 12.3 8.8\n"
     ]
    }
   ],
   "source": [
    "preview_data(daily_data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform a value that is used in two columns into two distinct values. This is necessary for the correct execution of the step folows this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Een beetje': 53, 'Enigszins': 15, 'Helemaal niet': 91, 'Yes': 10}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert \"Ja\" to \"Yes\" for a column\n",
    "transform_column_substring(\"Ja\", \"Yes\", \"wake_earlier_problem\", daily_data)\n",
    "column_summary(\"wake_earlier_problem\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "late is: [1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "\n",
      "sleep_struggle is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "wake_earlier is: [0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
      "\n",
      "sleep_transition is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "night_wake is: [0, 4, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2]\n",
      "\n",
      "wake_earlier_problem is: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "\n",
      "sleep_quality is: [2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "physical_activity is: [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mental_digital_activity is: [1, 1, 0, 3, 1, 2, 1, 1, 1, 2, 1, 0, 3, 1]\n",
      "\n",
      "social_activity is: [2, 2, 3, 1, 2, 2, 2, 1, 2, 1, 2, 1, 3, 2]\n",
      "\n",
      "light is: [1, 3, 3, 3, 3, 3, 2, 2, 2, 0, 2, 3, 3, 3]\n",
      "\n",
      "temptation_smoking is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_eating is: [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0]\n",
      "\n",
      "temptation_chat is: [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_coffee is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_social_media is: [2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2]\n",
      "\n",
      "temptation_internet is: [2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2]\n",
      "\n",
      "temptation_tv is: [0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_alcohol is: [0, 2, 2, 1, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2]\n",
      "\n",
      "temptation_soft_drink is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_cleaning is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "temptation_shopping is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "\n",
      "temptation_other is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# A list of what value to convert what.\n",
    "conversion_dictionary = {\n",
    "    # late, sleep_struggle, wake_earlier\n",
    "    \"Nee\":0,\n",
    "    \"Ja\":1,\n",
    "    \n",
    "    # sleep_transition\n",
    "    \"binnen een kwartier\":0,\n",
    "    \"binnen een half uur\":1,\n",
    "    \"binnen een uur\":2,\n",
    "    \"na meer dan een uur\":3,\n",
    "    \n",
    "    # night_wake\n",
    "    \"0 keer\":0,\n",
    "    \"1 keer\":1,\n",
    "    \"2-3 keer\":2,\n",
    "    \"4-5 keer\":3,\n",
    "    \"6 keer of meer\":4,\n",
    "    \n",
    "    # wake_earlier_problem\n",
    "    'Helemaal niet':0, \n",
    "    'Een beetje':1, \n",
    "    'Enigszins':2, \n",
    "    'Yes':3, # <-- This is the value that is transformed from 'Ja' to 'Yes' in the previous cell.\n",
    "             # If the transformation was not made, another 'Ja' value here would have overwritten the '1' values for late,...\n",
    "             # sleep_struggle, and wake_earlier variables.\n",
    "    \n",
    "    # sleep_quality\n",
    "    'Slecht':0,\n",
    "    'Matig':1,\n",
    "    'Goed':2, \n",
    "    'Erg goed':3,\n",
    "    \n",
    "    # physical_activity, mental_digital_activity\n",
    "    'Nauwelijks actief': 0,\n",
    "    'Licht actief':1,\n",
    "    'Vrij actief':2,\n",
    "    'Zeer actief':3,\n",
    "    \n",
    "    # social_activity \n",
    "    # some erroneous entries exist. they are translated to correct values.\n",
    "    '2-Jan':0,      # 1-2\n",
    "    '1-feb':0,      # 1-2  \n",
    "    '5-Mar':1,      # 3-5\n",
    "    '3-mei':1,      # 3-5\n",
    "    '9-Jun':2,      # 6-9\n",
    "    '6-sep':2,      # 6-9\n",
    "    '10 of meer':3, # 10+\n",
    "    \n",
    "\n",
    "    # light\n",
    "    'Minder dan een kwartier':0,\n",
    "    'Minder dan een half uur':1,\n",
    "    'Minder dan een uur':2,\n",
    "    'Meer dan een uur':3,\n",
    "    \n",
    "    # \"temptation_smoking\", \"temptation_eating\", \"temptation_chat\", \"temptation_coffee\", \"temptation_social_media\", \n",
    "    # \"temptation_internet\", \"temptation_tv\", \"temptation_alcohol\", \"temptation_soft_drink\", \"temptation_cleaning\", \n",
    "    # \"temptation_shopping\", \"temptation_other\", \n",
    "    'Geen verleiding ervaren':0,\n",
    "    'Verleiding ervaren en besloten om er niet aan toe te geven':1,\n",
    "    'Toegegeven aan verleiding':2\n",
    "}\n",
    "\n",
    "# Headers of the columns that will be replaced.\n",
    "target_headers = [\n",
    "    \"late\", \"sleep_struggle\", \"wake_earlier\", \"sleep_transition\", \"night_wake\", \"wake_earlier_problem\", \"sleep_quality\",\n",
    "    \"physical_activity\", \"mental_digital_activity\", \"social_activity\", \"light\",\n",
    "    \"temptation_smoking\", \"temptation_eating\", \"temptation_chat\", \"temptation_coffee\", \"temptation_social_media\", \n",
    "    \"temptation_internet\", \"temptation_tv\", \"temptation_alcohol\", \"temptation_soft_drink\", \"temptation_cleaning\", \n",
    "    \"temptation_shopping\", \"temptation_other\"\n",
    "]\n",
    "\n",
    "# Make the transformation using the conversion dictionary column headers list\n",
    "transform_column_values(conversion_dictionary, target_headers, daily_data)\n",
    "\n",
    "# Print the converted columns as rows\n",
    "print_columns(target_headers, daily_data[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge temptation ratings into a single 'temptation' score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temptation_score is: [6.0, 6.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 1.0, 4.0, 0.0, 4.0, 7.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 6.0, 2.0, 2.0, 6.0, 2.0, 6.0, 2.0, 6.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 6.0, 10.0, 6.0, 7.0, 10.0, 6.0, 6.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 8.0, 8.0, 4.0, 4.0, 4.0, 2.0, 10.0, 3.0, 2.0, 4.0, 8.0, 4.0, 6.0, 6.0, 2.0, 2.0, 4.0, 0.0, 2.0, 2.0, 5.0, 2.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 0.0, 4.0, 6.0, 4.0, 2.0, 4.0, 6.0, 8.0, 4.0, 4.0, 6.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 7.0, 5.0, 6.0, 4.0, 7.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# Note: This function cannot be ran multiple times.\n",
    "\n",
    "temptation_headers = [\n",
    "    \"temptation_smoking\", \"temptation_eating\", \"temptation_chat\", \"temptation_coffee\", \"temptation_social_media\", \n",
    "    \"temptation_internet\", \"temptation_tv\", \"temptation_alcohol\", \"temptation_soft_drink\", \"temptation_cleaning\", \n",
    "    \"temptation_shopping\", \"temptation_other\"\n",
    "]\n",
    "\n",
    "temptation_scores = calculate_scores(temptation_headers, daily_data)\n",
    "append_column(temptation_scores, \"temptation_score\", daily_data)\n",
    "\n",
    "print_columns(\"temptation_score\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Ego Depletion Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ego_depletion is: [0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 3, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "ego_depletions = calculate_scores(temptation_headers, daily_data, count_values=1)\n",
    "append_column(ego_depletions, \"ego_depletion\", daily_data)\n",
    "print_columns(\"ego_depletion\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time and Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the \"questionnaire_timestamp\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/10 9:57:26 a.m. EET\n",
      "2017/04/11 11:25:39 p.m. EET\n",
      "2017/04/12 7:42:47 a.m. EET\n",
      "2017/04/13 8:26:21 a.m. EET\n"
     ]
    }
   ],
   "source": [
    "print_column_vertically(\"questionnaire_timestamp\", daily_data[0:5][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some strings should be converted (e.g., \"a.m.\" --> \"AM) in order to prepare them for parsing with datetime.datetime() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/10 9:57:26 a.m. EET\n",
      "2017/04/11 11:25:39 p.m. EET\n",
      "2017/04/12 7:42:47 a.m. EET\n",
      "2017/04/13 8:26:21 a.m. EET\n",
      "2017/04/14 1:10:28 p.m. EET\n"
     ]
    }
   ],
   "source": [
    "# Preview dates\n",
    "questionnaire_timestamp_column = select_column(\"questionnaire_timestamp\", daily_data)\n",
    "for i, timestamp in enumerate(questionnaire_timestamp_column[0:5]):\n",
    "    print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/04/10 9:57:26 AM UTC+0200\n",
      "2017/04/11 11:25:39 PM UTC+0200\n",
      "2017/04/12 7:42:47 AM UTC+0200\n",
      "2017/04/13 8:26:21 AM UTC+0200\n",
      "\n",
      " Type of time is:\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This function can only be ran once. Once the new values are in the memory, using them as an input will cause an error.\n",
    "# Please re-reun all the previous cells from \"Menu -> Cell -> Run all above to reset the value of the input variable.\n",
    "\n",
    "# Transform a.m. to AM, and p.m., to PM in order to prepare values for datetime.datetime() method.\n",
    "transform_column_substring(\"a.m.\", \"AM\", \"questionnaire_timestamp\", daily_data)\n",
    "transform_column_substring(\"p.m.\", \"PM\", \"questionnaire_timestamp\", daily_data)\n",
    "\n",
    "# Change time zone value to one that is recognizable by datetime function\n",
    "transform_column_substring(\"EET\", \"UTC+0200\", \"questionnaire_timestamp\", daily_data)\n",
    "\n",
    "print_column_vertically(\"questionnaire_timestamp\", daily_data[0:5][0:5])\n",
    "\n",
    "print(\"\\n Type of time is:\")\n",
    "print(type(select_column(\"questionnaire_timestamp\", daily_data)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-10 09:57:26+02:00\n",
      "2017-04-11 23:25:39+02:00\n",
      "2017-04-12 07:42:47+02:00\n",
      "2017-04-13 08:26:21+02:00\n",
      "\n",
      " Type of time is now:\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This function can only be ran once. Once the new values are in the memory, using them as an input will cause an error.\n",
    "# Please re-reun all the previous cells from \"Menu -> Cell -> Run all above to reset the value of the input variable.\n",
    "\n",
    "import datetime\n",
    "\n",
    "questionnaire_timestamp_column = select_column(\"questionnaire_timestamp\", daily_data)\n",
    "\n",
    "for i, date in enumerate(questionnaire_timestamp_column): \n",
    "    questionnaire_timestamp_column[i] = datetime.datetime.strptime(questionnaire_timestamp_column[i], \"%Y/%m/%d %I:%M:%S %p %Z%z\")    \n",
    "\n",
    "replace_column(questionnaire_timestamp_column, \"questionnaire_timestamp\", daily_data)\n",
    "print_column_vertically(\"questionnaire_timestamp\", daily_data[0:5][0:5])\n",
    "\n",
    "print(\"\\n Type of time is now:\")\n",
    "print(type(select_column(\"questionnaire_timestamp\", daily_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"questionnaire_timestamp\" column is now parsed/converted into a datetime object from a string. \n",
    "\n",
    "Datetime objecs can be used in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(questionnaire_timestamp_column[0].day)\n",
    "print(questionnaire_timestamp_column[0].hour)\n",
    "print(questionnaire_timestamp_column[0].minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate 'date' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The questionnaire_timestamp column indicates the date and time when participants filled in the questionnaire.\n",
    "- This is, one day after the events they repor took place.\n",
    "- Therefore, actual date the values refer to in any row is one day before questionnaire_timestamp date\n",
    "\n",
    "\n",
    "- Now, a new 'date' column will be calculated.\n",
    "- This 'date' column will be the primary variable that will be used to calculate other variables, and questionnaire_timestamp will only be left in the dataset for reference and completeness purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questionniare_timestamps = select_column(\"questionnaire_timestamp\", daily_data)\n",
    "\n",
    "import datetime\n",
    "# Store a .timedelta object that coresponds to one day. \n",
    "one_day = datetime.timedelta(days=1)\n",
    "\n",
    "dates = []\n",
    "for each_timestamp in questionniare_timestamps:\n",
    "    current_date = each_timestamp - one_day\n",
    "    dates.append(current_date)\n",
    "\n",
    "append_column(dates, \"date\", daily_data)\n",
    "print(\"\") # Empty output to supress long return output from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The questionnaire_timestamp column:\n",
      "\n",
      "questionnaire_timestamp is: [datetime.datetime(2017, 4, 10, 9, 57, 26, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC')), datetime.datetime(2017, 4, 11, 23, 25, 39, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC')), datetime.datetime(2017, 4, 12, 7, 42, 47, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC'))]\n",
      "\n",
      "The new date column holds dates that are one day before the questionnaire_timestamp dates:\n",
      "\n",
      "date is: [datetime.datetime(2017, 4, 9, 9, 57, 26, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC')), datetime.datetime(2017, 4, 10, 23, 25, 39, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC')), datetime.datetime(2017, 4, 11, 7, 42, 47, tzinfo=datetime.timezone(datetime.timedelta(0, 7200), 'UTC'))]\n"
     ]
    }
   ],
   "source": [
    "print(\"The questionnaire_timestamp column:\")\n",
    "print_columns(\"questionnaire_timestamp\", daily_data[:][0:4])\n",
    "\n",
    "print(\"\\nThe new date column holds dates that are one day before the questionnaire_timestamp dates:\")\n",
    "print_columns(\"date\", daily_data[:][0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse wake, sleep, and planned times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All but  one value in a row of the the daily_data dataset represent measurements from the previous day. \n",
    "- The only value that represents the values from the current day is bed_time_plan.\n",
    "- Therefore its alignment in time would make calculations easier.\n",
    "\n",
    "\n",
    "- This function replaces the old bed_time_plan column with the 'bed_time_plan_aligned' column in the dataset\n",
    "- This is one of the only 'destructive' manupulations in the dataset, and is intended to preven confusion with time variables.\n",
    "- After this function, all values in a row now represent values from yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The misalignment:\n",
      "tonight\n",
      "tomorrow\n",
      "\n",
      "The aligned version:\n",
      "tonight\n",
      "tonight\n"
     ]
    }
   ],
   "source": [
    "# Current situation:\n",
    "btime  = [\"yesterday\", \"tonight\", \"tomorrow\"]  # yesterday\n",
    "bplan  = [\"tonight\",   \"tomorrow\",\"day_after\"] # today - should be made yesterday\n",
    "\n",
    "print(\"The misalignment:\")\n",
    "print(btime[1])\n",
    "print(bplan[1])\n",
    "\n",
    "# What it should be transformed to:\n",
    "# brtime = [yesterday, tonight, tomorrow, day after]\n",
    "# btplan = [0,       , tonight, tomorrow, day_after]\n",
    "\n",
    "print(\"\\nThe aligned version:\")\n",
    "bplan.insert(0, 0)\n",
    "print(btime[1])\n",
    "print(bplan[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed plan tonight (original bed_time_plan column)\n",
      "\n",
      "bed_time_plan is: ['23:00', '23:30', '23:00', '23:30', '23:00', '23:00', '23:00', '23:30', '00:00', '23:00', '00:00', '23:00', '00:00', '23:00', '21:30', '21:30', '21:00', '22:00', '21:30', '21:00', '21:00', '21:30', '21:30', '21:30', '23:00', '21:00', '21:00', '22:00', '23:30', '00:00', '23:00', '22:00', '23:00', '23:00', '23:00', '00:00', '23:00', '23:00', '23:30', '00:00', '22:00', '23:00', '21:00', '05:00', '03:30', '02:00', '03:00', '03:00', '03:00', '03:00', '01:00', '03:00', '03:00', '04:00', '04:30', '04:30', '03:00', '02:00', '02:00', '03:00', '05:00', '00:00', '02:00', '03:00', '02:00', '00:00', '02:00', '01:00', '01:00', '03:00', '01:00', '03:00', '00:00', '00:00', '02:00', '03:00', '00:00', '03:00', '21:45', '21:50', '22:00', '21:50', '22:00', '22:00', '22:00', '22:30', '22:45', '22:45', '22:15', '23:00', '23:00', '23:00', '22:40', '22:30', '22:00', '22:30', '22:00', '00:00', '23:30', '23:00', '23:00', '23:30', '00:30', '00:00', '00:00', '00:00', '23:30', '23:00', '23:30', '23:30', '23:30', '00:00', '23:00', '23:30', '23:30', '01:00', '01:00', '23:30', '23:30', '23:30', '23:30', '01:00', '01:00', '01:00', '00:30', '23:30', '23:30', '23:30', '00:30', '01:00', '00:00', '23:30', '23:00', '23:00', '00:00', '01:00', '23:00', '23:30', '23:30', '00:00', '23:30', '23:30', '00:30', '01:00', '23:30', '23:30', '23:30', '01:00', '00:00', '01:00', '23:30', '23:30', '23:45', '23:30', '23:30', '23:30', '23:45', '23:30', '23:45', '23:45', '23:30', '23:45', '23:30', '23:45', '23:45', '23:45', '23:45', '23:30', '23:30']\n"
     ]
    }
   ],
   "source": [
    "print(\"bed plan tonight (original bed_time_plan column)\")\n",
    "print_columns(\"bed_time_plan\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CAUTION: This function can only be ran once. \n",
    "\n",
    "# Group values in bed_time_plan column by participant id\n",
    "plans_grouped_by_id = divide_column_by_criteria(\"id\", \"bed_time_plan\", daily_data)\n",
    "\n",
    "aligned_plans_per_group  = [] # Will be populated by lists that are bed times of each participant id \n",
    "aligned_plans_unified    = [] # A merged version of aligned_plans_per_group\n",
    "\n",
    "for each_group in plans_grouped_by_id:\n",
    "    \n",
    "    # Extract bed_time_plan column (these are the answers to the question \"When do you plan to go to sleep tonight?\")\n",
    "    #bed_plan_tonight =  select_column(\"bed_time_plan\", daily_data) # first item in this list, belongs to today. \n",
    "                                                                   # the second item belongs to tomorrow.\n",
    "\n",
    "    # Add an empty value as the first value, since this cannot be evaluated as late or early due to the absence of \n",
    "    # a value for the \"bed_time\" column in the first day of the measurement.\n",
    "    each_group.insert(0, \"NA\")      # insert an empty element at the beginning of bed_plan_tonight, \n",
    "                                      # so it is aligned (i.e., it becomes bed_time_plan_aligned).\n",
    "    group_aligned = each_group  # after the alignment, bed_plan_today is now bed_time_plan_aligned  \n",
    "\n",
    "    # After a blank first value is added, list (which will later become a column in dataset) is now 1 item longer \n",
    "    # than all other columsn. Therefore, it's last element should be removed (which is also useless, since it cannot \n",
    "    # be compared due to an actual bed time next day due to being the last entry.)\n",
    "    del group_aligned[-1]  # delete the item in the end to prevent lists/columns being different lengths.\n",
    "    aligned_plans_per_group.append(group_aligned)\n",
    "\n",
    "for each_aligned_group in aligned_plans_per_group:\n",
    "    aligned_plans_unified.extend(each_aligned_group)\n",
    "\n",
    "# Replace the old bed_time_plan column with the 'bed_time_plan_aligned' column in the dataset\n",
    "# THIS COLUMN WILL BE USED INSTEAD OF 'bed_time_plan' column from now on (column was not replaced to preseve the original data)\n",
    "replace_column(aligned_plans_unified, \"bed_time_plan\", daily_data)\n",
    "header_index = get_header_index(\"bed_time_plan\", daily_data)\n",
    "daily_data[0][header_index] = \"bed_time_plan_aligned\" # Change header from bed_time_plan to bed_time_plan_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new bed_time_plan_aligned (i.e., bed plan of yesterday) column as it is printed from the dataset:\n",
      "\n",
      "bed_time_plan_aligned is: ['NA', '23:00', '23:30', '23:00', '23:30', '23:00', '23:00', '23:00', '23:30', '00:00', '23:00', '00:00', '23:00', '00:00', 'NA', '21:30', '21:30', '21:00', '22:00']\n",
      "\n",
      "Is the length of the new bed_time_plan_aligned column the same with other columns?:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"The new bed_time_plan_aligned (i.e., bed plan of yesterday) column as it is printed from the dataset:\")\n",
    "print_columns(\"bed_time_plan_aligned\", daily_data[:][0:20])\n",
    "\n",
    "print(\"\\nIs the length of the new bed_time_plan_aligned column the same with other columns?:\")\n",
    "print( len(select_column(\"bed_time_plan_aligned\", daily_data)) == len(select_column(\"id\", daily_data)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>CANCELED</font> <br>\n",
    "Converting relevant values in rows to current day's values, instead o the previous day's.\n",
    "Instead of this function, bed_time_plan was converted to yesterday's value like all the columns in the rows except itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The 'bed_time' variable reflects the bed time of yesterday, while \"bed_time_planned\" variable reflects the planned \n",
    "# bed time whent the question was asked to the participant. In order to calculate the delay in going to bed, \n",
    "# the difference of these two values must be calculated. This would me much easier if they are on the same row. \n",
    "# Therefore, they are first going to be aligned:\n",
    "    \n",
    "# # Extensive debugging is provided below as the function may still need to be changed.\n",
    "# \n",
    "# # Extract bed_times column (these are the answers to the question \"When did you go to bed last night?\")\n",
    "# bed_yesterday =  select_column(\"bed_time\", daily_data) # first item in this list, belongs to yesterday. The second item belongs to today.\n",
    "# print(\"bed_yesterday (bed_time column)\")\n",
    "# print(bed_yesterday[0:5])\n",
    "# \n",
    "# # Remove the first value, since this cannot be evaluated as late or early due to the absence of a value for the ...\n",
    "# # \"bed_time_plan\" column in the first day of the measurement.\n",
    "# bed_tonight   = bed_yesterday[1:len(bed_yesterday)]  # discard the first item of the bed_yesterday, so it is aligned.\n",
    "# print(\"\\nbed_tonight (bed_time column minus its first element)\")\n",
    "# print(bed_tonight[0:5])\n",
    "# \n",
    "# # After the first value is removed, list (which will later become a column in dataset) should be equalized once again\n",
    "# bed_tonight.append(\"0:00\") # append a zero at the end to prevent lists/columns being different lengths.\n",
    "# print(\"\\nbed_tonight (bed_time column also now has a dummy value at the end after losing its first element)\")\n",
    "# print(bed_tonight[0:5])\n",
    "# \n",
    "# Extract planned bed times (bed_time_plan column)\n",
    "# plan_tonight    =  select_column(\"bed_time_plan\", daily_data) # first item in this list belongs to today\n",
    "# print(\"\\nplan_tonight (bed_time_plan column)\")\n",
    "# print(plan_tonight[0:5])\n",
    "# \n",
    "# # The last item of plan_tonight also becomes 0:00, as there can be no comparisons made with the ...\n",
    "# # actual sleep time in the data, as this measurement is absent from the last day of data collection.\n",
    "# plan_tonight[len(plan_tonight)-1] = \"0:00\" # The last item of plan_tonight also becomes '0' \n",
    "#                                            # as the corresponding sleep time is not available. \n",
    "# print(\"\\nplan_tonight (bed_time_plan column's last value changed to a dummy value at the end as well)\")\n",
    "# print(plan_tonight[0:5])\n",
    "# \n",
    "# print(\"\\n bed_tonight last values\")\n",
    "# print(bed_tonight[len(bed_tonight)-6:len(bed_tonight)])\n",
    "# \n",
    "# print(\"\\n plan_tonight last values\")\n",
    "# print(plan_tonight[len(plan_tonight)-6:len(plan_tonight)])\n",
    "# \n",
    "# # Append new planned bed times as 'plan_tonight' column to the dataset\n",
    "# # THIS COLUMN WILL BE USED INSTEAD OF 'bed_time_plan' column from now on (column was not replaced to preseve the original data)\n",
    "# append_column(plan_tonight,  \"plan_tonight\",  daily_data)\n",
    "# print(\"\\nthe new plan_tonight column\")\n",
    "# print_columns(\"plan_tonight\", daily_data[:][0:6])\n",
    "# \n",
    "# # Append new bed times as 'bed_tonight' column to the dataset\n",
    "# # THIS COLUMN WILL BE USED INSTEAD OF 'bed_time' column from now on (column was not replaced to preseve the original data)\n",
    "# append_column(bed_tonight, \"bed_tonight\", daily_data)\n",
    "# print(\"\\nthe new bed_tonight column\")\n",
    "# print_columns(\"bed_tonight\", daily_data[:][0:6])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert times from string to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, times look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wake times\n",
      "09:30\n",
      "07:00\n",
      "07:00\n",
      "07:00\n",
      "\n",
      "\n",
      "Planned bed times (bed_time_plan_aligned)\n",
      "NA\n",
      "23:00\n",
      "23:30\n",
      "23:00\n",
      "\n",
      "\n",
      "Bed times (bed_time)\n",
      "02:00\n",
      "23:45\n",
      "23:55\n",
      "00:30\n",
      "\n",
      "Type of values\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Wake times\")\n",
    "print_column_vertically(\"wake_time\", daily_data[0:5][0:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Planned bed times (bed_time_plan_aligned)\")\n",
    "print_column_vertically(\"bed_time_plan_aligned\", daily_data[0:5][0:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Bed times (bed_time)\")\n",
    "print_column_vertically(\"bed_time\", daily_data[0:5][0:5])\n",
    "\n",
    "print(\"\\nType of values\")\n",
    "print(type(select_column(\"bed_time\", daily_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to calculate differences with the datetime module, these 'string' times should be converted to datetime objects year, month, and day information also needs to be added to wake_time, bed_time_plan_aligned, and bed_time variables from the 'date' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOTE: This function can only be ran once as it transforms its own input variable to a format it can no longer process. \n",
    "# Please re-run all previous cells in order to run it without errors.\n",
    "\n",
    "parse_hour_minute([\"wake_time\", \"bed_time\", \"bed_time_plan_aligned\"], \"date\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wake times\n",
      "2017-04-09 09:30:00\n",
      "2017-04-10 07:00:00\n",
      "2017-04-11 07:00:00\n",
      "2017-04-12 07:00:00\n",
      "\n",
      "\n",
      "Planned bed times (bed_time_plan_aligned)\n",
      "NaT\n",
      "2017-04-10 23:00:00\n",
      "2017-04-11 23:30:00\n",
      "2017-04-12 23:00:00\n",
      "\n",
      "\n",
      "Bed times (bed_time)\n",
      "2017-04-09 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-12 00:30:00\n",
      "\n",
      "Type of values\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Wake times\")\n",
    "print_column_vertically(\"wake_time\", daily_data[0:5][0:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Planned bed times (bed_time_plan_aligned)\")\n",
    "print_column_vertically(\"bed_time_plan_aligned\", daily_data[0:5][0:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Bed times (bed_time)\")\n",
    "print_column_vertically(\"bed_time\", daily_data[0:5][0:5])\n",
    "\n",
    "\n",
    "print(\"\\nType of values\")\n",
    "print(type(select_column(\"bed_time\", daily_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These dates (which were just taken from questionnaire_timestamps [i.e., from 'date' column which is calculated with each_timestamp - one_day]), however, should be corrected: <br>\n",
    "For the times past midnight, 1 day should be added to the date (e.g., note the 4th line of the Bed times (bed_time) above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed_time_plan_aligned before change\n",
      "NaT\n",
      "2017-04-10 23:00:00\n",
      "2017-04-11 23:30:00\n",
      "2017-04-12 23:00:00\n",
      "2017-04-13 23:30:00\n",
      "2017-04-14 23:00:00\n",
      "2017-04-15 23:00:00\n",
      "2017-04-16 23:00:00\n",
      "2017-04-17 23:30:00\n",
      "\n",
      "bed_time before change\n",
      "2017-04-09 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-12 00:30:00\n",
      "2017-04-13 00:00:00\n",
      "2017-04-14 01:00:00\n",
      "2017-04-15 23:30:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-17 00:30:00\n",
      "\n",
      "bed_time_plan_aligned after PM-->AM change (notice the changed day values)\n",
      "NaT\n",
      "2017-04-10 23:00:00\n",
      "2017-04-11 23:30:00\n",
      "2017-04-12 23:00:00\n",
      "2017-04-13 23:30:00\n",
      "2017-04-14 23:00:00\n",
      "2017-04-15 23:00:00\n",
      "2017-04-16 23:00:00\n",
      "2017-04-17 23:30:00\n",
      "\n",
      "bed_time after PM-->AM change (notice the changed day values)\n",
      "2017-04-10 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-13 00:30:00\n",
      "2017-04-14 00:00:00\n",
      "2017-04-15 01:00:00\n",
      "2017-04-15 23:30:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-18 00:30:00\n"
     ]
    }
   ],
   "source": [
    "# Printing original values for later comparison\n",
    "print(\"bed_time_plan_aligned before change\")\n",
    "print_column_vertically(\"bed_time_plan_aligned\", daily_data[0:10])\n",
    "\n",
    "# Printing original values for later comparison\n",
    "print(\"\\nbed_time before change\")\n",
    "print_column_vertically(\"bed_time\", daily_data[0:10])\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Extract columns to variables from the dataset\n",
    "bed_time = select_column(\"bed_time\", daily_data)\n",
    "bed_time_plan_aligned = select_column(\"bed_time_plan_aligned\", daily_data)\n",
    "\n",
    "# Store a .timedelta object that coresponds to one day. \n",
    "# This will be used to set the date to one day later in time if it's past 00:00\n",
    "one_day = datetime.timedelta(days=1)\n",
    "\n",
    "# If time is past 00:00, set the date to +1 day\n",
    "for i in range(0, len(bed_time)):  # This is an iteration for both bed_time and bed_time_plan_aligned\n",
    "                                   # Because lengths of both columns are the same, this way works, \n",
    "                                   # but I should have used zip() instead.\n",
    "    if str(type(bed_time[i])) == \"<class 'datetime.datetime'>\": # If the row is a datetime.datetime object (e.g., it is not a 'NA' value)   \n",
    "        bed_hour       = bed_time[i].hour\n",
    "        bed_minute     = bed_time[i].minute\n",
    "        \n",
    "        if  (bed_hour == 0) or (bed_hour > 0 and bed_hour < 12):\n",
    "            bed_time[i] = bed_time[i] + one_day\n",
    "    \n",
    "    if str(type(bed_time_plan_aligned[i])) == \"<class 'datetime.datetime'>\": # If the row is a datetime.datetime object (e.g., it is not a 'NA' value)   \n",
    "        planned_hour   = bed_time_plan_aligned[i].hour\n",
    "        planned_minute = bed_time_plan_aligned[i].minute\n",
    "\n",
    "        if  (planned_hour == 0) or (planned_hour > 0 and planned_hour < 12):\n",
    "            bed_time_plan_aligned[i] = bed_time_plan_aligned[i] + one_day\n",
    "\n",
    "# Write the corrected dates to the columns in the dataset\n",
    "replace_column(bed_time_plan_aligned, \"bed_time_plan_aligned\", daily_data)\n",
    "replace_column(bed_time, \"bed_time\", daily_data)\n",
    "\n",
    "\n",
    "# Print new values for comparison\n",
    "print(\"\\nbed_time_plan_aligned after PM-->AM change (notice the changed day values)\")\n",
    "print_column_vertically(\"bed_time_plan_aligned\", daily_data[0:10])\n",
    "\n",
    "# Print new values for comparison\n",
    "print(\"\\nbed_time after PM-->AM change (notice the changed day values)\")\n",
    "print_column_vertically(\"bed_time\", daily_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wake times\n",
      "2017-04-09 09:30:00\n",
      "2017-04-10 07:00:00\n",
      "2017-04-11 07:00:00\n",
      "2017-04-12 07:00:00\n",
      "2017-04-13 09:00:00\n",
      "\n",
      "NEW Planned bed times (bed_time_plan_aligned)\n",
      "NaT\n",
      "2017-04-10 23:00:00\n",
      "2017-04-11 23:30:00\n",
      "2017-04-12 23:00:00\n",
      "2017-04-13 23:30:00\n",
      "\n",
      "NEW Bed times (bed_time)\n",
      "2017-04-10 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-13 00:30:00\n",
      "2017-04-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Wake times\")\n",
    "print_column_vertically(\"wake_time\", daily_data[:][0:6])\n",
    "print(\"\")\n",
    "\n",
    "print(\"NEW Planned bed times (bed_time_plan_aligned)\")\n",
    "print_column_vertically(\"bed_time_plan_aligned\", daily_data[:][0:6])\n",
    "print(\"\")\n",
    "\n",
    "print(\"NEW Bed times (bed_time)\")\n",
    "print_column_vertically(\"bed_time\", daily_data[:][0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and add a column for day of the week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekdays:\n",
    "- 0: Monday\n",
    "- 6: Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dates    = select_column(\"date\", daily_data)\n",
    "\n",
    "weekdays = []\n",
    "for each_date in dates:\n",
    "    current_weekday = each_date.weekday()\n",
    "    weekdays.append(current_weekday)\n",
    "\n",
    "append_column(weekdays, \"day_of_week\", daily_data)\n",
    "print(\"\") # Supress long output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate bedtime procrastination duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, -90, 60, -10, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, -120, -45, 15, 60, 60, 75, 90, 15, 60, 30, -150, 30, 120, nan, -225, -60, 180, 90, 30, 30, 60, 0, 90, 90, -30, 30, 0, nan, 60, 120, -15, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, -10, 20, -10, -10, 60, 0, -15, 0, 15, 75, 90, -30, -10, 180, 15, 0, nan, -60, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, -30, nan, 0, 15, -15, -45, 90, 50, 0, 30, 60, 0, -75, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, -60, 75, 15, 0, 30, 45, 0, 30, -60, 0, 20, 120, 0, 15, nan, 60, 20, -15, 15, 15, 0, 60, 45, 0, -15, 15, 0, 15, 135, 0, -15, 0, 45]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy\n",
    "procrastination_minutes = []\n",
    "\n",
    "planned_time = select_column(\"bed_time_plan_aligned\", daily_data)\n",
    "bed_time = select_column( \"bed_time\",  daily_data)\n",
    "\n",
    "correction_offset = datetime.timedelta(days=1)\n",
    "for i in range(0, len(planned_time)):  # This iteration runs for both planned_time and bed_time (as lengths are the same)\n",
    "\n",
    "    if str(type(planned_time[i])) == \"<class 'datetime.datetime'>\":  # If row is a datetime.datetime object, process it\n",
    "                                                                     # Otherwise, leave it unchanged\n",
    "\n",
    "        if planned_time[i] < bed_time[i]:  # if the bed time is later than the planned_time time (i.e., procrastinated)\n",
    "            current_duration =  bed_time[i] - planned_time[i] # calculate delay in going to bed\n",
    "            procrastination_minutes.append(int(current_duration.total_seconds()/60)) # and add this delay to list\n",
    "            #print(\"late: \" + str(current_duration))\n",
    "\n",
    "        elif planned_time[i] > bed_time[i]:\n",
    "            current_duration =  planned_time[i] - bed_time[i]\n",
    "            procrastination_minutes.append(int(-current_duration.total_seconds()/60))\n",
    "            #print(\"early: \" + str(current_duration))\n",
    "\n",
    "        elif planned_time[i] == bed_time[i]:\n",
    "            current_duration =  planned_time[i] - bed_time[i]\n",
    "            procrastination_minutes.append(int(current_duration.total_seconds()))\n",
    "            #print(\"on time: \" + str(current_duration))\n",
    "    else:\n",
    "        current_duration = float('NaN')\n",
    "        procrastination_minutes.append(current_duration)\n",
    "\n",
    "append_column(procrastination_minutes, \"procrastination_minutes\", daily_data)\n",
    "print_columns(\"procrastination_minutes\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8038f5208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "bedtime_procrastination = missingval_return_without(\"\", \"procrastination_minutes\", daily_data)\n",
    "plt.hist(bedtime_procrastination, normed=True, bins=\"auto\")\n",
    "plt.xlabel('Bedtime Procrastination Duration');\n",
    "plt.ylabel('Probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat all negative procrastination values as zero procrastination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes_positive is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, 0, 60, 0, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, 0, 0, 15, 60, 60, 75, 90, 15, 60, 30, 0, 30, 120, nan, 0, 0, 180, 90, 30, 30, 60, 0, 90, 90, 0, 30, 0, nan, 60, 120, 0, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, 0, 20, 0, 0, 60, 0, 0, 0, 15, 75, 90, 0, 0, 180, 15, 0, nan, 0, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, 0, nan, 0, 15, 0, 0, 90, 50, 0, 30, 60, 0, 0, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, 0, 75, 15, 0, 30, 45, 0, 30, 0, 0, 20, 120, 0, 15, nan, 60, 20, 0, 15, 15, 0, 60, 45, 0, 0, 15, 0, 15, 135, 0, 0, 0, 45]\n"
     ]
    }
   ],
   "source": [
    "procrastination_minutes = select_column(\"procrastination_minutes\", daily_data)\n",
    "\n",
    "for i, each_duration in enumerate(procrastination_minutes):\n",
    "    if each_duration < 0:\n",
    "        procrastination_minutes[i] = 0\n",
    "append_column(procrastination_minutes, \"procrastination_minutes_positive\", daily_data)\n",
    "print_columns(\"procrastination_minutes_positive\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEKCAYAAAAmfuNnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZXCAcfMzErhgGNmZqVwwDEzs1L8fy5hZIYVQDN+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d80392d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "bedtime_procrastination = missingval_return_without(\"\", \"procrastination_minutes_positive\", daily_data)\n",
    "plt.hist(bedtime_procrastination, normed=True, bins=\"auto\")\n",
    "plt.xlabel('Bedtime Procrastination Duration (Positive Only)');\n",
    "plt.ylabel('Probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide procrastination_minutes_positive to 15-minute bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes_positive_15by15 is: [nan, 3, 1, 6, 2, 8, 2, 2, 4, 4, 6, 0, 4, 0, nan, 3, 0, 1, 0, 7, 1, 4, 3, 2, 0, 8, 1, 1, 4, nan, 0, 0, 1, 4, 4, 5, 6, 1, 4, 2, 0, 2, 8, nan, 0, 0, 12, 6, 2, 2, 4, 0, 6, 6, 0, 2, 0, nan, 4, 8, 0, 8, 5, 4, 10, 12, 8, 7, 4, 0, 11, 16, 2, 8, 10, 4, 10, 9, nan, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 1, 5, 6, 0, 0, 12, 1, 0, nan, 0, 2, 2, 1, 6, 0, 6, 1, 1, 10, 8, 2, 2, 6, 0, nan, 0, 1, 0, 0, 6, 3, 0, 2, 4, 0, 0, 1, 1, 2, 1, 4, 0, 2, nan, 2, 3, 8, 0, 5, 1, 0, 2, 3, 0, 2, 0, 0, 1, 8, 0, 1, nan, 4, 1, 0, 1, 1, 0, 4, 3, 0, 0, 1, 0, 1, 9, 0, 0, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "procrastination_minutes_positive = select_column(\"procrastination_minutes_positive\", daily_data)\n",
    "\n",
    "procrastination_minutes_positive_15by15 = []\n",
    "for each_row in procrastination_minutes_positive:\n",
    "    try:\n",
    "        # Convert each value to a fold of 15, and by doing so, divide the column to groups 15 by 15.  \n",
    "        procrastination_minutes_positive_15by15.append(int(each_row/15))\n",
    "    except:\n",
    "        procrastination_minutes_positive_15by15.append(float(\"NaN\"))\n",
    "    \n",
    "append_column(procrastination_minutes_positive_15by15, \"procrastination_minutes_positive_15by15\", daily_data)\n",
    "print_columns(\"procrastination_minutes_positive_15by15\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide procrastination_minutes_positive to four large bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bins:\n",
    "- 0-15 \n",
    "- 15-30\n",
    "- 30-60\n",
    "- 60+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 1,\n",
       " 0: 50,\n",
       " 1: 25,\n",
       " 2: 20,\n",
       " 3: 8,\n",
       " 4: 18,\n",
       " 5: 4,\n",
       " 6: 11,\n",
       " 7: 2,\n",
       " 8: 10,\n",
       " nan: 1,\n",
       " nan: 1,\n",
       " nan: 1,\n",
       " 9: 2,\n",
       " 10: 4,\n",
       " 11: 1,\n",
       " 12: 3,\n",
       " nan: 1,\n",
       " 16: 1,\n",
       " nan: 1,\n",
       " nan: 1,\n",
       " nan: 1,\n",
       " nan: 1,\n",
       " nan: 1}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_summary(\"procrastination_minutes_positive_15by15\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes_positive_15by15 is: [nan, 3, 1, 6, 2, 8, 2, 2, 4, 4, 6, 0, 4, 0, nan, 3, 0, 1, 0, 7, 1, 4, 3, 2, 0, 8, 1, 1, 4, nan, 0, 0, 1, 4, 4, 5, 6, 1, 4, 2, 0, 2, 8, nan, 0, 0, 12, 6, 2, 2, 4, 0, 6, 6, 0, 2, 0, nan, 4, 8, 0, 8, 5, 4, 10, 12, 8, 7, 4, 0, 11, 16, 2, 8, 10, 4, 10, 9, nan, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 1, 5, 6, 0, 0, 12, 1, 0, nan, 0, 2, 2, 1, 6, 0, 6, 1, 1, 10, 8, 2, 2, 6, 0, nan, 0, 1, 0, 0, 6, 3, 0, 2, 4, 0, 0, 1, 1, 2, 1, 4, 0, 2, nan, 2, 3, 8, 0, 5, 1, 0, 2, 3, 0, 2, 0, 0, 1, 8, 0, 1, nan, 4, 1, 0, 1, 1, 0, 4, 3, 0, 0, 1, 0, 1, 9, 0, 0, 0, 3]\n",
      "\n",
      "\n",
      "procrastination_minutes_positive_four_bins is: [nan, 2, 1, 3, 1, 3, 1, 1, 2, 2, 3, 0, 2, 0, nan, 2, 0, 1, 0, 3, 1, 2, 2, 1, 0, 3, 1, 1, 2, nan, 0, 0, 1, 2, 2, 3, 3, 1, 2, 1, 0, 1, 3, nan, 0, 0, 3, 3, 1, 1, 2, 0, 3, 3, 0, 1, 0, nan, 2, 3, 0, 3, 3, 2, 3, 3, 3, 3, 2, 0, 3, 3, 1, 3, 3, 2, 3, 3, nan, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 3, 3, 0, 0, 3, 1, 0, nan, 0, 1, 1, 1, 3, 0, 3, 1, 1, 3, 3, 1, 1, 3, 0, nan, 0, 1, 0, 0, 3, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 2, 0, 1, nan, 1, 2, 3, 0, 3, 1, 0, 1, 2, 0, 1, 0, 0, 1, 3, 0, 1, nan, 2, 1, 0, 1, 1, 0, 2, 2, 0, 0, 1, 0, 1, 3, 0, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "procrastination_minutes_positive_15by15 = select_column(\"procrastination_minutes_positive_15by15\", daily_data)\n",
    "append_column(procrastination_minutes_positive_15by15, \"procrastination_minutes_positive_four_bins\", daily_data)\n",
    "\n",
    "# IMPORTANT: This function worked for now, but it has a flaw: it owerwrites the vales it converted as it progresses, \n",
    "# if those values are once again referred to down in the line. Because the current data to be converted does not \n",
    "# have this characteristic, it works, but this should be fixed in future.\n",
    "conversions_dictionary = {\n",
    "    0:0, # 0 minutes (bin: 0-15)\n",
    "    1:1, # 15 minutes (bin: 15-30)\n",
    "    2:1, # 30 minutes (bin: 15-30)\n",
    "    3:2, # 45 minutes (bin: 30-60)\n",
    "    4:2, # 60 minutes (bin: 30-60)\n",
    "    5:3, # 75 minutes (bin: 60+)\n",
    "    6:3, # (bin: 60+)     # The rest of this list is populated ungracefully; a more dynamic method should be incorporated.\n",
    "    7:3, # (bin: 60+)     # For this purpose, probably regex (e.g., transform_column_substring() function) should be used.\n",
    "    8:3, # (bin: 60+)\n",
    "    9:3, # (bin: 60+)\n",
    "    10:3, # (bin: 60+)\n",
    "    11:3, # (bin: 60+)\n",
    "    12:3, # (bin: 60+)\n",
    "    13:3, # (bin: 60+)\n",
    "    14:3, # (bin: 60+)\n",
    "    15:3, # (bin: 60+)\n",
    "    16:3, # (bin: 60+)\n",
    "    46:3 # (bin: 60+)\n",
    "}\n",
    "\n",
    "#transform column type to string here \n",
    "#transform substrings with regex\n",
    "#transform_column_substring(\"0:0\", \"procrastination_minutes_positive_four_bins\")\n",
    "#transform column type back to integer # NaN types would probably be problematic\n",
    "\n",
    "print_columns(\"procrastination_minutes_positive_15by15\", daily_data)\n",
    "print(\"\")\n",
    "transform_column_values(conversions_dictionary, \"procrastination_minutes_positive_four_bins\", daily_data)\n",
    "print_columns(\"procrastination_minutes_positive_four_bins\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sleep Durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate sleep durations:\n",
    "- Bed time must be calculated by finding the difference between bed and wake up times.\n",
    "- Then, sleep transition time must be subtracted from bed time, in order to find actual sleep times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how sleep transition times look like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sleep_transition is: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 1, 3, 0, 2, 3, 2, 1, 1, 1, 2, 2, 2, 0, 2, 2, 0, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 3, 1, 0, 0, 0, 0, 1, 0, 0, 2, 3, 3, 2, 1, 0, 1, 1, 0, 3, 1, 3, 1, 2, 1, 1, 1, 1, 0, 1, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print_columns(\"sleep_transition\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep transition times should be converted to minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sleep_transition_minutes_estimated is: [datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900), datetime.timedelta(0, 900)]\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta as td\n",
    "\n",
    "# Select the sleep transitions column and store it in a new column, so it can be transformed afterwards \n",
    "# ... by using transform_column_values function.\n",
    "sleep_transitions = select_column(\"sleep_transition\", daily_data)\n",
    "append_column(sleep_transitions, \"sleep_transition_minutes_estimated\", daily_data)\n",
    "\n",
    "# Transform the values of column according to following scheme:\n",
    "# 0: in 15 minutes\n",
    "# 1: in half an hour\n",
    "# 2: in an hour\n",
    "# 3: in more than an hour\n",
    "transform_column_values({0:td(minutes=15),1:td(minutes=30), 2:td(minutes=60), 3:td(minutes=90)}, \"sleep_transition_minutes_estimated\", daily_data)\n",
    "\n",
    "# Print the new column for checking\n",
    "print_columns(\"sleep_transition_minutes_estimated\", daily_data[:][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the actual sleep time calculation can be made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sleep_minutes is: [435.0, 420.0, 410.0, 375.0, 525.0, 345.0, 435.0, 435.0, 435.0, 345.0, 435.0, 495.0, 405.0, 415.0, 515.0, 480.0, 545.0, 500.0, 510.0, 400.0, 525.0, 495.0, 460.0, 495.0, 505.0, 345.0, 515.0, 510.0, 465.0, 465.0, 555.0, 525.0, 480.0, 540.0, 405.0, 465.0, 375.0, 525.0, 405.0, 465.0, 585.0, 495.0, 390.0, 630.0, 640.0, 495.0, 465.0, 330.0, 435.0, 435.0, 510.0, 390.0, 360.0, 450.0, 510.0, 510.0, 435.0, 360.0, 360.0, 525.0, 525.0, 405.0, 205.0, 585.0, 415.0, 525.0, 135.0, 570.0, 140.0, 690.0, 450.0, 210.0, 585.0, 135.0, 135.0, 645.0, 435.0, 145.0, 555.0, 435.0, 450.0, 440.0, 530.0, 550.0, 625.0, 530.0, 555.0, 570.0, 455.0, 525.0, 420.0, 435.0, 510.0, 550.0, 300.0, 540.0, 570.0, 390.0, 495.0, 390.0, 390.0, 375.0, 315.0, 480.0, 390.0, 495.0, 465.0, 405.0, 270.0, 380.0, 330.0, 390.0, 390.0, 500.0, 480.0, 480.0, 495.0, 540.0, 380.0, 400.0, 520.0, 435.0, 525.0, 420.0, 600.0, 450.0, 510.0, 480.0, 510.0, 540.0, 615.0, 435.0, 405.0, 390.0, 374.0, 480.0, 440.0, 540.0, 450.0, 450.0, 420.0, 360.0, 470.0, 1140.0, 570.0, 450.0, 465.0, 660.0, 600.0, 415.0, 555.0, 420.0, 495.0, 510.0, 525.0, 525.0, 495.0, 450.0, 450.0, 480.0, 525.0, 510.0, 495.0, 495.0, 405.0, 540.0, 510.0, 600.0, 465.0]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Assign relevant columns to variables\n",
    "bed_times    = select_column(\"bed_time\", daily_data)\n",
    "wake_times   = select_column(\"wake_time\", daily_data)\n",
    "sleep_delays = select_column(\"sleep_transition_minutes_estimated\", daily_data)\n",
    "\n",
    "# Calculate times spent in bed\n",
    "bed_durations = []\n",
    "for each_wake_time, each_bed_time in zip(wake_times, bed_times):\n",
    "    delta = each_wake_time - each_bed_time\n",
    "    bed_durations.append(delta)\n",
    "\n",
    "# Calculate times spent actually sleeping (and not just in bed) by subtracting sleep transition times from bed times\n",
    "sleep_durations = []\n",
    "for each_bed_duration, each_sleep_delay in zip(bed_durations, sleep_delays):\n",
    "    actual_sleep_duration = each_bed_duration - each_sleep_delay\n",
    "    sleep_durations.append(actual_sleep_duration)\n",
    "\n",
    "# Transform sleep durations from datetime.timedelta object to minutes\n",
    "sleep_minutes = []\n",
    "for each_duration in sleep_durations:\n",
    "    current_duration_in_minutes = each_duration.seconds/60\n",
    "    sleep_minutes.append(current_duration_in_minutes)\n",
    "\n",
    "# Add these new times as a column to data and print it for checking\n",
    "append_column(sleep_minutes, \"sleep_minutes\", daily_data)\n",
    "print_columns(\"sleep_minutes\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Canceled] Align 'Sun hours' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>CANCELED</font> <br>\n",
    "Just like bed_time, sun_hours also reflects yesterday's values and it should be aligned with the current day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sun_hours_yesterday = select_column(\"sun_hours\", daily_data)\n",
    "#sun_hours_today = sun_hours_yesterday[1:len(sun_hours_yesterday)]\n",
    "#sun_hours_today.append(0)\n",
    "\n",
    "#append_column(sun_hours_today, \"sun_hours_today\", daily_data)\n",
    "\n",
    "#print_columns([\"sun_hours\", \"sun_hours_today\"], daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 1-,2-, and 3-day histories of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 2 values per column.\n",
      "=============================================================\n",
      "\n",
      "questionnaire_timestamp: datetime.datetime(2017 4 10 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 11 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "id: 'AB64' 'AB64'\n",
      "bed_time: datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45)\n",
      "late: 1 1\n",
      "late_reason: 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling' ''\n",
      "wake_time: datetime.datetime(2017 4 9 9 30) datetime.datetime(2017 4 10 7 0)\n",
      "sleep_transition: 0 0\n",
      "sleep_struggle: 0 0\n",
      "night_wake: 0 4\n",
      "wake_earlier: 0 0\n",
      "wake_earlier_problem: 0 0\n",
      "sleep_quality: 2 2\n",
      "physical_activity: 1 1\n",
      "mental_digital_activity: 1 1\n",
      "social_activity: 2 2\n",
      "light: 1 3\n",
      "presleep_description: 'Theaterbezoek autorit (bijrijder)' 'Tv kijken'\n",
      "temptation_smoking: 0 0\n",
      "temptation_eating: 0 0\n",
      "temptation_chat: 2 0\n",
      "temptation_coffee: 0 0\n",
      "temptation_social_media: 2 2\n",
      "temptation_internet: 2 2\n",
      "temptation_tv: 0 0\n",
      "temptation_alcohol: 0 2\n",
      "temptation_soft_drink: 0 0\n",
      "temptation_cleaning: 0 0\n",
      "temptation_shopping: 0 0\n",
      "temptation_other: 0 0\n",
      "bed_time_plan_aligned: NaT datetime.datetime(2017 4 10 23 0)\n",
      "steps: 5845.0 7649.0\n",
      "active_minutes: 5.0 0.0\n",
      "sun_hours: 12.3 8.8\n",
      "temptation_score: 6.0 6.0\n",
      "ego_depletion: 0 0\n",
      "date: datetime.datetime(2017 4 9 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 10 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "day_of_week: 6 0\n",
      "procrastination_minutes: nan 45\n",
      "procrastination_minutes_positive: nan 45\n",
      "procrastination_minutes_positive_15by15: nan 3\n",
      "procrastination_minutes_positive_four_bins: nan 2\n",
      "sleep_transition_minutes_estimated: datetime.timedelta(0 900) datetime.timedelta(0 900)\n",
      "sleep_minutes: 435.0 420.0\n"
     ]
    }
   ],
   "source": [
    "preview_data(daily_data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes_positive is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, 0, 60, 0, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, 0, 0, 15, 60, 60, 75, 90, 15, 60, 30, 0, 30, 120, nan, 0, 0, 180, 90, 30, 30, 60, 0, 90, 90, 0, 30, 0, nan, 60, 120, 0, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, 0, 20, 0, 0, 60, 0, 0, 0, 15, 75, 90, 0, 0, 180, 15, 0, nan, 0, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, 0, nan, 0, 15, 0, 0, 90, 50, 0, 30, 60, 0, 0, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, 0, 75, 15, 0, 30, 45, 0, 30, 0, 0, 20, 120, 0, 15, nan, 60, 20, 0, 15, 15, 0, 60, 45, 0, 0, 15, 0, 15, 135, 0, 0, 0, 45]\n",
      " \n",
      "\n",
      "procrastination_minutes is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, -90, 60, -10, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, -120, -45, 15, 60, 60, 75, 90, 15, 60, 30, -150, 30, 120, nan, -225, -60, 180, 90, 30, 30, 60, 0, 90, 90, -30, 30, 0, nan, 60, 120, -15, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, -10, 20, -10, -10, 60, 0, -15, 0, 15, 75, 90, -30, -10, 180, 15, 0, nan, -60, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, -30, nan, 0, 15, -15, -45, 90, 50, 0, 30, 60, 0, -75, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, -60, 75, 15, 0, 30, 45, 0, 30, -60, 0, 20, 120, 0, 15, nan, 60, 20, -15, 15, 15, 0, 60, 45, 0, -15, 15, 0, 15, 135, 0, -15, 0, 45]\n"
     ]
    }
   ],
   "source": [
    "print_columns(\"procrastination_minutes_positive\", daily_data)\n",
    "print(\" \")\n",
    "print_columns(\"procrastination_minutes\", daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cumulative_history_variables = [\n",
    "    [\"procrastination_minutes\", 4, \"four\"],\n",
    "    [\"procrastination_minutes\", 3, \"three\"],\n",
    "    [\"procrastination_minutes\", 2, \"two\"],\n",
    "    \n",
    "    [\"procrastination_minutes_positive\", 4, \"four\"],\n",
    "    [\"procrastination_minutes_positive\", 3, \"three\"],\n",
    "    [\"procrastination_minutes_positive\", 2, \"two\"],\n",
    "    \n",
    "    [\"sleep_minutes\", 4, \"four\"],\n",
    "    [\"sleep_minutes\", 3, \"three\"],\n",
    "    [\"sleep_minutes\", 2, \"two\"],\n",
    "\n",
    "    #[\"sleep_deficit\", 4, \"four\"],\n",
    "    #[\"sleep_deficit\", 3, \"three\"],\n",
    "    #[\"sleep_deficit\", 2, \"two\"],    \n",
    "    \n",
    "    [\"sleep_struggle\", 4, \"four\"],\n",
    "    [\"sleep_struggle\", 3, \"three\"],\n",
    "    [\"sleep_struggle\", 2, \"two\"],\n",
    "    \n",
    "   [\"night_wake\", 4, \"four\"],\n",
    "   [\"night_wake\", 3, \"three\"],\n",
    "   [\"night_wake\", 2, \"two\"],\n",
    "   \n",
    "   \n",
    "   [\"sleep_quality\", 4, \"four\"],\n",
    "   [\"sleep_quality\", 3, \"three\"],\n",
    "   [\"sleep_quality\", 2, \"two\"],\n",
    "   \n",
    "   [\"social_activity\", 4, \"four\"],\n",
    "   [\"social_activity\", 3, \"three\"],\n",
    "   [\"social_activity\", 2, \"two\"],\n",
    "   \n",
    "   [\"light\", 4, \"four\"],\n",
    "   [\"light\", 3, \"three\"],\n",
    "   [\"light\", 2, \"two\"],\n",
    "   \n",
    "   [\"temptation_eating\", 4, \"four\"],\n",
    "   [\"temptation_eating\", 3, \"three\"],\n",
    "   [\"temptation_eating\", 2, \"two\"],\n",
    "   \n",
    "   [\"temptation_coffee\", 4, \"four\"],\n",
    "   [\"temptation_coffee\", 3, \"three\"],\n",
    "   [\"temptation_coffee\", 2, \"two\"],\n",
    "   \n",
    "   [\"temptation_score\", 4, \"four\"],\n",
    "   [\"temptation_score\", 3, \"three\"],\n",
    "   [\"temptation_score\", 2, \"two\"]\n",
    "]\n",
    "\n",
    "for each_entity in cumulative_history_variables:\n",
    "    new_column = history_cumulative(each_entity[0], each_entity[1], daily_data, \"id\")\n",
    "    new_column_name = (each_entity[0] + \"_\" + each_entity[2] + \"_day_cumulative_history\")\n",
    "    append_column(new_column, new_column_name, daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes_positive is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, 0, 60, 0, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, 0, 0, 15, 60, 60, 75, 90, 15, 60, 30, 0, 30, 120, nan, 0, 0, 180, 90, 30, 30, 60, 0, 90, 90, 0, 30, 0, nan, 60, 120, 0, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, 0, 20, 0, 0, 60, 0, 0, 0, 15, 75, 90, 0, 0, 180, 15, 0, nan, 0, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, 0, nan, 0, 15, 0, 0, 90, 50, 0, 30, 60, 0, 0, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, 0, 75, 15, 0, 30, 45, 0, 30, 0, 0, 20, 120, 0, 15, nan, 60, 20, 0, 15, 15, 0, 60, 45, 0, 0, 15, 0, 15, 135, 0, 0, 0, 45]\n",
      "\n",
      "procrastination_minutes_positive_three_day_cumulative_history is: [nan, nan, nan, 160, 145, 240, 180, 180, 120, 150, 210, 150, 150, 60, nan, nan, nan, 70, 25, 120, 120, 180, 120, 135, 75, 150, 135, 150, 90, nan, nan, nan, 15, 75, 135, 195, 225, 180, 165, 105, 90, 60, 150, nan, nan, nan, 180, 270, 300, 150, 120, 90, 150, 180, 180, 120, 30, nan, nan, nan, 180, 240, 195, 255, 285, 390, 450, 405, 295, 175, 235, 405, 435, 390, 300, 330, 360, 345, nan, nan, nan, 10, 25, 20, 20, 60, 60, 60, 0, 15, 90, 180, 165, 90, 180, 195, 195, nan, nan, nan, 60, 75, 135, 105, 180, 105, 120, 180, 285, 300, 180, 150, 120, nan, nan, nan, 15, 15, 90, 140, 140, 80, 90, 90, 60, 15, 30, 60, 60, 105, 75, 90, nan, nan, nan, 196, 166, 195, 90, 90, 45, 75, 75, 75, 30, 30, 20, 140, 140, 135, nan, nan, nan, 80, 35, 30, 30, 75, 105, 105, 45, 15, 15, 30, 150, 150, 135, 0, 45]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"procrastination_minutes_positive\",\n",
    "               \"procrastination_minutes_positive_three_day_cumulative_history\",\n",
    "              ], \n",
    "              daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temptation_score_one_days_ago is: [nan, 6.0, 6.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 1.0, 4.0, 0.0, 4.0, nan, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 6.0, 2.0, 2.0, 6.0, 2.0, 6.0, 2.0, nan, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 0.0, 2.0, nan, 6.0, 6.0, 6.0, 10.0, 6.0, 7.0, 10.0, 6.0, 6.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 8.0, 8.0, 4.0, nan, 4.0, 2.0, 10.0, 3.0, 2.0, 4.0, 8.0, 4.0, 6.0, 6.0, 2.0, 2.0, 4.0, 0.0, 2.0, nan, 5.0, 2.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 0.0, 4.0, 6.0, 4.0, 2.0, 4.0, 6.0, nan, 4.0, 4.0, 6.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 7.0, 5.0, 6.0, 4.0, nan, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "temptation_score_two_days_ago is: [nan, nan, 6.0, 6.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 1.0, 4.0, 0.0, nan, nan, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, nan, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 6.0, 2.0, 2.0, 6.0, 2.0, 6.0, nan, nan, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, nan, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 0.0, nan, nan, 6.0, 6.0, 6.0, 10.0, 6.0, 7.0, 10.0, 6.0, 6.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 8.0, 8.0, nan, nan, 4.0, 2.0, 10.0, 3.0, 2.0, 4.0, 8.0, 4.0, 6.0, 6.0, 2.0, 2.0, 4.0, 0.0, nan, nan, 5.0, 2.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 0.0, 4.0, 6.0, 4.0, 2.0, 4.0, nan, nan, 4.0, 4.0, 6.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 7.0, 5.0, 6.0, nan, nan, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "temptation_score_three_days_ago is: [nan, nan, nan, 6.0, 6.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 1.0, 4.0, nan, nan, nan, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, nan, nan, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 6.0, 2.0, 2.0, 6.0, 2.0, nan, nan, nan, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, nan, nan, nan, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, nan, nan, nan, 6.0, 6.0, 6.0, 10.0, 6.0, 7.0, 10.0, 6.0, 6.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 8.0, nan, nan, nan, 4.0, 2.0, 10.0, 3.0, 2.0, 4.0, 8.0, 4.0, 6.0, 6.0, 2.0, 2.0, 4.0, nan, nan, nan, 5.0, 2.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 0.0, 4.0, 6.0, 4.0, 2.0, nan, nan, nan, 4.0, 4.0, 6.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 7.0, 5.0, nan, nan, nan, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "bed_time_three_days_ago:\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-10 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-13 00:30:00\n",
      "2017-04-14 00:00:00\n",
      "2017-04-15 01:00:00\n",
      "2017-04-15 23:30:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-18 00:30:00\n",
      "2017-04-19 01:00:00\n",
      "2017-04-20 00:30:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 21:30:00\n",
      "2017-04-10 22:15:00\n"
     ]
    }
   ],
   "source": [
    "xdays_ago_variables = [\n",
    "    [\"procrastination_minutes\", 3, \"three\"],\n",
    "    [\"procrastination_minutes\", 2, \"two\"],\n",
    "    [\"procrastination_minutes\", 1, \"one\"],\n",
    "    [\"temptation_score\", 3, \"three\"],\n",
    "    [\"temptation_score\", 2, \"two\"],\n",
    "    [\"temptation_score\", 1, \"one\"],\n",
    "    [\"bed_time\", 3, \"three\"],\n",
    "    [\"bed_time\", 2, \"two\"],\n",
    "    [\"bed_time\", 1, \"one\"],\n",
    "    [\"sleep_minutes\", 3, \"three\"],\n",
    "    [\"sleep_minutes\", 2, \"two\"],\n",
    "    [\"sleep_minutes\", 1, \"one\"]\n",
    "]\n",
    "\n",
    "for each_entity in xdays_ago_variables:\n",
    "    new_column      = history_nback(each_entity[0], each_entity[1], \"column\", daily_data, row_grouping_criteria_header=\"id\")\n",
    "    new_column_name = (each_entity[0] + \"_\" + each_entity[2] + \"_days_ago\") \n",
    "    append_column(new_column, new_column_name, daily_data)\n",
    "\n",
    "    \n",
    "print_columns([\"temptation_score_one_days_ago\",\n",
    "               \"temptation_score_two_days_ago\",\n",
    "               \"temptation_score_three_days_ago\",\n",
    "              ],\n",
    "              daily_data)\n",
    "print(\"\\nbed_time_three_days_ago:\")\n",
    "print_column_vertically(\"bed_time_three_days_ago\", daily_data[:][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sleep Deficit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sleep deficit change for the current row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sleep_deficit_change is: [45.0, 60.0, 70.0, 105.0, -45.0, 135.0, 45.0, 45.0, 45.0, 135.0, 45.0, -15.0, 75.0, 65.0, -35.0, 0.0, -65.0, -20.0, -30.0, 80.0, -45.0, -15.0, 20.0, -15.0, -25.0, 135.0, -35.0, -30.0, 15.0, 15.0, -75.0, -45.0, 0.0, -60.0, 75.0, 15.0, 105.0, -45.0, 75.0, 15.0, -105.0, -15.0, 90.0, -150.0, -160.0, -15.0, 15.0, 150.0, 45.0, 45.0, -30.0, 90.0, 120.0, 30.0, -30.0, -30.0, 45.0, 120.0, 120.0, -45.0, -45.0, 75.0, 275.0, -105.0, 65.0, -45.0, 345.0, -90.0, 340.0, -210.0, 30.0, 270.0, -105.0, 345.0, 345.0, -165.0, 45.0, 335.0, -75.0, 45.0, 30.0, 40.0, -50.0, -70.0, -145.0, -50.0, -75.0, -90.0, 25.0, -45.0, 60.0, 45.0, -30.0, -70.0, 180.0, -60.0, -90.0, 90.0, -15.0, 90.0, 90.0, 105.0, 165.0, 0.0, 90.0, -15.0, 15.0, 75.0, 210.0, 100.0, 150.0, 90.0, 90.0, -20.0, 0.0, 0.0, -15.0, -60.0, 100.0, 80.0, -40.0, 45.0, -45.0, 60.0, -120.0, 30.0, -30.0, 0.0, -30.0, -60.0, -135.0, 45.0, 75.0, 90.0, 106.0, 0.0, 40.0, -60.0, 30.0, 30.0, 60.0, 120.0, 10.0, -660.0, -90.0, 30.0, 15.0, -180.0, -120.0, 65.0, -75.0, 60.0, -15.0, -30.0, -45.0, -45.0, -15.0, 30.0, 30.0, 0.0, -45.0, -30.0, -15.0, -15.0, 75.0, -60.0, -30.0, -120.0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "sleep_minutes = select_column(\"sleep_minutes\", daily_data)\n",
    "\n",
    "sleep_deficit_changes = []\n",
    "for each_sleep_duration in sleep_minutes:\n",
    "    current_deficit = 480 - each_sleep_duration\n",
    "    sleep_deficit_changes.append(current_deficit)\n",
    "\n",
    "append_column(sleep_deficit_changes, \"sleep_deficit_change\", daily_data)    \n",
    "print_columns(\"sleep_deficit_change\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cumulative sleep deficit (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sleep_deficit_change is: [45.0, 60.0, 70.0, 105.0, -45.0, 135.0, 45.0, 45.0, 45.0, 135.0, 45.0, -15.0, 75.0, 65.0, -35.0, 0.0, -65.0, -20.0, -30.0, 80.0, -45.0, -15.0, 20.0, -15.0, -25.0, 135.0, -35.0, -30.0, 15.0, 15.0, -75.0, -45.0, 0.0, -60.0, 75.0, 15.0, 105.0, -45.0, 75.0, 15.0, -105.0, -15.0, 90.0, -150.0, -160.0, -15.0, 15.0, 150.0, 45.0, 45.0, -30.0, 90.0, 120.0, 30.0, -30.0, -30.0, 45.0, 120.0, 120.0, -45.0, -45.0, 75.0, 275.0, -105.0, 65.0, -45.0, 345.0, -90.0, 340.0, -210.0, 30.0, 270.0, -105.0, 345.0, 345.0, -165.0, 45.0, 335.0, -75.0, 45.0, 30.0, 40.0, -50.0, -70.0, -145.0, -50.0, -75.0, -90.0, 25.0, -45.0, 60.0, 45.0, -30.0, -70.0, 180.0, -60.0, -90.0, 90.0, -15.0, 90.0, 90.0, 105.0, 165.0, 0.0, 90.0, -15.0, 15.0, 75.0, 210.0, 100.0, 150.0, 90.0, 90.0, -20.0, 0.0, 0.0, -15.0, -60.0, 100.0, 80.0, -40.0, 45.0, -45.0, 60.0, -120.0, 30.0, -30.0, 0.0, -30.0, -60.0, -135.0, 45.0, 75.0, 90.0, 106.0, 0.0, 40.0, -60.0, 30.0, 30.0, 60.0, 120.0, 10.0, -660.0, -90.0, 30.0, 15.0, -180.0, -120.0, 65.0, -75.0, 60.0, -15.0, -30.0, -45.0, -45.0, -15.0, 30.0, 30.0, 0.0, -45.0, -30.0, -15.0, -15.0, 75.0, -60.0, -30.0, -120.0, 15.0]\n",
      "\n",
      "sleep_deficit_minutes_simple is: [nan, nan, nan, 280.0, 190.0, 265.0, 240.0, 180.0, 270.0, 270.0, 270.0, 210.0, 240.0, 170.0, nan, nan, nan, 0, 0, 80.0, 35.0, 0, 40.0, 5.0, 0, 135.0, 100.0, 45.0, 85.0, nan, nan, nan, 0.0, 0, 75.0, 90.0, 135.0, 150.0, 150.0, 150.0, 0, 0, 90.0, nan, nan, nan, 15.0, 165.0, 195.0, 255.0, 210.0, 150.0, 225.0, 210.0, 210.0, 90.0, 45.0, nan, nan, nan, 150.0, 105.0, 350.0, 200.0, 310.0, 190.0, 345.0, 275.0, 550.0, 385.0, 70.0, 430.0, 165.0, 540.0, 855.0, 420.0, 570.0, 560.0, nan, nan, nan, 70.0, 65.0, 0, 0, 0, 0, 0, 25.0, 0, 60.0, 105.0, 30.0, 5.0, 180.0, 120.0, 0, nan, nan, nan, 255.0, 270.0, 450.0, 360.0, 360.0, 240.0, 90.0, 165.0, 285.0, 400.0, 535.0, 550.0, 430.0, nan, nan, nan, 0, 0, 100.0, 180.0, 80.0, 185.0, 40.0, 60.0, 0, 30.0, 0.0, 0.0, 0, 0, 0, 45.0, nan, nan, nan, 271.0, 236.0, 86.0, 30.0, 60.0, 90.0, 240.0, 220.0, 0, 0, 30.0, 45.0, 0, 0, 65.0, nan, nan, nan, 0, 0, 0, 0, 30.0, 60.0, 45.0, 15.0, 0, 0, 0, 75.0, 15.0, 0, 0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "sleep_deficit_changes = select_column(\"sleep_deficit_change\", daily_data)\n",
    "sleep_deficits = history_cumulative(\"sleep_deficit_change\", 4, daily_data, \"id\", zero_floored_summation=1)\n",
    "append_column(sleep_deficits, \"sleep_deficit_minutes_simple\", daily_data)\n",
    "\n",
    "print_columns(\"sleep_deficit_change\", daily_data)\n",
    "print_columns(\"sleep_deficit_minutes_simple\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Three-day Weighted Cumulative History (Special formula on p.13 of Erik van den Boogaard's thesis)\n",
    "***Former name of variable: 'Cumulative Sleep Deficit'***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is calculated as follows: <br>\n",
    "CBT = BTP-0 + (BTP-1)*0.5 + (BTP-2)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "procrastination_minutes is: [nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, -90, 60, -10, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, 60, nan, -120, -45, 15, 60, 60, 75, 90, 15, 60, 30, -150, 30, 120, nan, -225, -60, 180, 90, 30, 30, 60, 0, 90, 90, -30, 30, 0, nan, 60, 120, -15, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, 135, nan, 5, 5, -10, 20, -10, -10, 60, 0, -15, 0, 15, 75, 90, -30, -10, 180, 15, 0, nan, -60, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, -30, nan, 0, 15, -15, -45, 90, 50, 0, 30, 60, 0, -75, 15, 15, 30, 15, 60, 0, 30, nan, 30, 46, 120, -60, 75, 15, 0, 30, 45, 0, 30, -60, 0, 20, 120, 0, 15, nan, 60, 20, -15, 15, 15, 0, 60, 45, 0, -15, 15, 0, 15, 135, 0, -15, 0, 45]\n",
      "\n",
      "procrastination_minutes_one_days_ago is: [nan, nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, -90, 60, nan, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, 15, nan, nan, -120, -45, 15, 60, 60, 75, 90, 15, 60, 30, -150, 30, nan, nan, -225, -60, 180, 90, 30, 30, 60, 0, 90, 90, -30, 30, nan, nan, 60, 120, -15, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, 150, nan, nan, 5, 5, -10, 20, -10, -10, 60, 0, -15, 0, 15, 75, 90, -30, -10, 180, 15, nan, nan, -60, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, 90, nan, nan, 0, 15, -15, -45, 90, 50, 0, 30, 60, 0, -75, 15, 15, 30, 15, 60, 0, nan, nan, 30, 46, 120, -60, 75, 15, 0, 30, 45, 0, 30, -60, 0, 20, 120, 0, nan, nan, 60, 20, -15, 15, 15, 0, 60, 45, 0, -15, 15, 0, 15, 135, 0, -15, 0]\n",
      "\n",
      "procrastination_minutes_two_days_ago is: [nan, nan, nan, 45, 25, 90, 30, 120, 30, 30, 60, 60, 90, -90, nan, nan, nan, 45, 10, 15, 0, 105, 15, 60, 45, 30, 0, 120, 15, nan, nan, nan, -120, -45, 15, 60, 60, 75, 90, 15, 60, 30, -150, nan, nan, nan, -225, -60, 180, 90, 30, 30, 60, 0, 90, 90, -30, nan, nan, nan, 60, 120, -15, 120, 75, 60, 150, 180, 120, 105, 70, 0, 165, 240, 30, 120, 150, 60, nan, nan, nan, 5, 5, -10, 20, -10, -10, 60, 0, -15, 0, 15, 75, 90, -30, -10, 180, nan, nan, nan, -60, 30, 30, 15, 90, 0, 90, 15, 15, 150, 120, 30, 30, nan, nan, nan, 0, 15, -15, -45, 90, 50, 0, 30, 60, 0, -75, 15, 15, 30, 15, 60, nan, nan, nan, 30, 46, 120, -60, 75, 15, 0, 30, 45, 0, 30, -60, 0, 20, 120, nan, nan, nan, 60, 20, -15, 15, 15, 0, 60, 45, 0, -15, 15, 0, 15, 135, 0, -15]\n",
      "\n",
      "procrastination_minutes_three_day_weighted_cumulative_history is: [nan, nan, nan, 111.5, 80.0, 153.0, 96.0, 69.0, 81.0, 96.0, 132.0, 0, 33.0, 2.0, nan, nan, nan, 29.0, 9.5, 108.0, 67.5, 88.5, 78.0, 64.5, 24.0, 126.0, 75.0, 46.5, 70.5, nan, nan, nan, 0, 58.5, 93.0, 117.0, 139.5, 75.0, 85.5, 63.0, 0, 0, 105.0, nan, nan, nan, 105.0, 168.0, 111.0, 63.0, 81.0, 36.0, 102.0, 135.0, 33.0, 33.0, 9.0, nan, nan, nan, 57.0, 136.5, 132.0, 121.5, 195.0, 267.0, 240.0, 201.0, 146.5, 56.0, 179.0, 322.5, 183.0, 183.0, 216.0, 159.0, 210.0, 222.0, nan, nan, nan, 0, 16.0, 0, 0, 53.0, 28.0, 0, 0, 12.0, 82.5, 130.5, 30.0, 0, 169.0, 103.0, 43.5, nan, nan, nan, 33.0, 36.0, 103.5, 48.0, 108.0, 60.0, 40.5, 160.5, 198.0, 120.0, 69.0, 111.0, 21.0, nan, nan, nan, 0, 0, 64.5, 86.0, 43.0, 40.0, 75.0, 36.0, 0, 0, 7.5, 40.5, 33.0, 73.5, 33.0, 42.0, nan, nan, nan, 149.0, 9.200000000000001, 69.0, 40.5, 22.5, 33.0, 60.0, 28.5, 39.0, 0, 0, 8.0, 130.0, 64.0, 39.0, nan, nan, nan, 7.0, 11.5, 19.5, 10.5, 63.0, 75.0, 34.5, 0, 7.5, 4.5, 18.0, 142.5, 70.5, 12.0, 0, 42.0]\n"
     ]
    }
   ],
   "source": [
    "procrastination_minutes_current_day  = select_column(\"procrastination_minutes\", daily_data)\n",
    "procrastination_minutes_one_days_ago = select_column(\"procrastination_minutes_one_days_ago\", daily_data)\n",
    "procrastination_minutes_two_days_ago = select_column(\"procrastination_minutes_two_days_ago\", daily_data)\n",
    "\n",
    "procrastination_minutes_three_day_weighted_cumulative_history = []\n",
    "for each_row_current_day, each_row_one_days_ago, each_row_two_days_ago in zip(procrastination_minutes_current_day, procrastination_minutes_one_days_ago, procrastination_minutes_two_days_ago):\n",
    "    procrastination_minutes_three_day_weighted_cumulative_history.append(each_row_current_day + each_row_one_days_ago*0.5 + each_row_two_days_ago*0.2)\n",
    "\n",
    "procrastination_minutes_three_day_weighted_cumulative_history_positive_only =  []\n",
    "current_value = 0\n",
    "for i, each_row in enumerate(procrastination_minutes_three_day_weighted_cumulative_history):\n",
    "    if each_row == each_row: # If the value is not NaN\n",
    "        if each_row >= 0:    # Keep all values as they are if they are positive\n",
    "            current_value = each_row\n",
    "        elif each_row < 0:   # Make all values 0 if they are negative (as negative procrastination is not possible in this study)\n",
    "            current_value = 0\n",
    "    else:                   # If value is NaN\n",
    "        current_value = each_row\n",
    "\n",
    "    procrastination_minutes_three_day_weighted_cumulative_history_positive_only.append(current_value)\n",
    "    \n",
    "append_column(procrastination_minutes_three_day_weighted_cumulative_history_positive_only, \"procrastination_minutes_three_day_weighted_cumulative_history\", daily_data)\n",
    "print_columns([\"procrastination_minutes\", \"procrastination_minutes_one_days_ago\", \"procrastination_minutes_two_days_ago\", \"procrastination_minutes_three_day_weighted_cumulative_history\"], daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all integers to float (So that all values in the dataset would be compatible with NaN values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers_list = daily_data[0]\n",
    "\n",
    "for each_header in headers_list:\n",
    "    selected_column = select_column(each_header, daily_data)\n",
    "    for i, each_row in enumerate(selected_column):\n",
    "        if type(each_row) is int:\n",
    "            selected_column[i] = float(each_row)\n",
    "    replace_column(selected_column, each_header, daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reader is advised to skip this section.\n",
    "\n",
    "The features in this section are added upon request of Erik van den Boogaard in July 2017, a few months after the completion of project. This section is not commented, short variable names were used instead of the verbose names that were used in the rest of this document. This was done and for compatibility with formulas provided, however, this is likely to reduce readibility of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- if there is a NaN value in a row of one of the columns, the output of sp will also be a NaN for that row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Name Changes and Small Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EL | DLQ | DPAL | EPAL | EMAL | TSC | ATS | ATBR | PDSQ | TBTP | CT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Intake data\n",
    "append_column(select_column(\"sc_score\", intake_data), \"TSC\", intake_data)\n",
    "append_column(select_column(\"ats_score\", intake_data), \"ATS\", intake_data)\n",
    "append_column(select_column(\"atbr_score\", intake_data), \"ATBR\", intake_data)\n",
    "append_column(select_column(\"bptrt_score\", intake_data), \"TBTP\", intake_data)\n",
    "append_column(select_column(\"chron_score\", intake_data), \"CT\", intake_data)\n",
    "\n",
    "# Daily data\n",
    "append_column(select_column(\"light\", daily_data), \"ELQ\", daily_data)\n",
    "append_column(select_column(\"sun_hours\", daily_data), \"DLQ\", daily_data)\n",
    "append_column(select_column(\"steps\", daily_data), \"DPAL\", daily_data)\n",
    "append_column(select_column(\"physical_activity\", daily_data), \"EPAL\", daily_data)\n",
    "append_column(select_column(\"mental_digital_activity\", daily_data), \"EMAL\", daily_data)\n",
    "append_column(select_column(\"sleep_quality\", daily_data), \"PDSQ\", daily_data)\n",
    "\n",
    "print(\"\") #supress output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BTP | CSD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_btp_with_nans = select_column(\"procrastination_minutes_positive\", daily_data)\n",
    "column_csd_with_nans = select_column(\"procrastination_minutes_three_day_weighted_cumulative_history\", daily_data)\n",
    "\n",
    "\n",
    "column_btp = []\n",
    "for each_row in column_btp_with_nans:\n",
    "    if each_row != each_row:\n",
    "        column_btp.append(0)\n",
    "    else:\n",
    "        column_btp.append(each_row)\n",
    "\n",
    "column_csd = []\n",
    "for each_row in column_csd_with_nans:\n",
    "    if each_row != each_row:\n",
    "        column_csd.append(0)\n",
    "    else:\n",
    "        column_csd.append(each_row)\n",
    "        \n",
    "append_column(column_btp, \"BTP\", daily_data)\n",
    "append_column(column_csd, \"CSD\", daily_data)\n",
    "print(\"\") #supress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 45.0, 25.0, 90.0, 30.0]\n",
      "['BTP', 0, 45.0, 25.0, 90.0]\n",
      "[nan, nan, nan, 111.5, 80.0]\n",
      "['CSD', 0, 0, 0, 111.5]\n"
     ]
    }
   ],
   "source": [
    "print(column_btp_with_nans[:5])\n",
    "print(column_btp[:5])\n",
    "        \n",
    "print(column_csd_with_nans[:5])\n",
    "print(column_csd[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BTP is: [0, 45.0, 25.0, 90.0, 30.0, 120.0, 30.0, 30.0, 60.0, 60.0, 90.0, 0.0, 60.0, 0.0, 0, 45.0, 10.0, 15.0, 0.0, 105.0, 15.0, 60.0, 45.0, 30.0, 0.0, 120.0, 15.0, 15.0, 60.0, 0, 0.0, 0.0, 15.0, 60.0, 60.0, 75.0, 90.0, 15.0, 60.0, 30.0, 0.0, 30.0, 120.0, 0, 0.0, 0.0, 180.0, 90.0, 30.0, 30.0, 60.0, 0.0, 90.0, 90.0, 0.0, 30.0, 0.0, 0, 60.0, 120.0, 0.0, 120.0, 75.0, 60.0, 150.0, 180.0, 120.0, 105.0, 70.0, 0.0, 165.0, 240.0, 30.0, 120.0, 150.0, 60.0, 150.0, 135.0, 0, 5.0, 5.0, 0.0, 20.0, 0.0, 0.0, 60.0, 0.0, 0.0, 0.0, 15.0, 75.0, 90.0, 0.0, 0.0, 180.0, 15.0, 0.0, 0, 0.0, 30.0, 30.0, 15.0, 90.0, 0.0, 90.0, 15.0, 15.0, 150.0, 120.0, 30.0, 30.0, 90.0, 0.0, 0, 0.0, 15.0, 0.0, 0.0, 90.0, 50.0, 0.0, 30.0, 60.0, 0.0, 0.0, 15.0, 15.0, 30.0, 15.0, 60.0, 0.0, 30.0, 0, 30.0, 46.0, 120.0, 0.0, 75.0, 15.0, 0.0, 30.0, 45.0, 0.0, 30.0, 0.0, 0.0, 20.0, 120.0, 0.0, 15.0, 0, 60.0, 20.0, 0.0, 15.0, 15.0, 0.0, 60.0, 45.0, 0.0, 0.0, 15.0, 0.0, 15.0, 135.0, 0.0, 0.0, 0.0, 45.0]\n",
      "\n",
      "CSD is: [0, 0, 0, 111.5, 80.0, 153.0, 96.0, 69.0, 81.0, 96.0, 132.0, 0.0, 33.0, 2.0, 0, 0, 0, 29.0, 9.5, 108.0, 67.5, 88.5, 78.0, 64.5, 24.0, 126.0, 75.0, 46.5, 70.5, 0, 0, 0, 0.0, 58.5, 93.0, 117.0, 139.5, 75.0, 85.5, 63.0, 0.0, 0.0, 105.0, 0, 0, 0, 105.0, 168.0, 111.0, 63.0, 81.0, 36.0, 102.0, 135.0, 33.0, 33.0, 9.0, 0, 0, 0, 57.0, 136.5, 132.0, 121.5, 195.0, 267.0, 240.0, 201.0, 146.5, 56.0, 179.0, 322.5, 183.0, 183.0, 216.0, 159.0, 210.0, 222.0, 0, 0, 0, 0.0, 16.0, 0.0, 0.0, 53.0, 28.0, 0.0, 0.0, 12.0, 82.5, 130.5, 30.0, 0.0, 169.0, 103.0, 43.5, 0, 0, 0, 33.0, 36.0, 103.5, 48.0, 108.0, 60.0, 40.5, 160.5, 198.0, 120.0, 69.0, 111.0, 21.0, 0, 0, 0, 0.0, 0.0, 64.5, 86.0, 43.0, 40.0, 75.0, 36.0, 0.0, 0.0, 7.5, 40.5, 33.0, 73.5, 33.0, 42.0, 0, 0, 0, 149.0, 9.200000000000001, 69.0, 40.5, 22.5, 33.0, 60.0, 28.5, 39.0, 0.0, 0.0, 8.0, 130.0, 64.0, 39.0, 0, 0, 0, 7.0, 11.5, 19.5, 10.5, 63.0, 75.0, 34.5, 0.0, 7.5, 4.5, 18.0, 142.5, 70.5, 12.0, 0.0, 42.0]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"BTP\",\"CSD\"], daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML (Daily data feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML=DLQ*(1-ELQ) (delayed effect or prolonged effect?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_elq = select_column(\"ELQ\", daily_data)\n",
    "column_dlq = select_column(\"DLQ\", daily_data)\n",
    "\n",
    "column_ml  = []\n",
    "for elq, dlq in zip(column_elq, column_dlq):\n",
    "    column_ml.append(dlq * (1-elq))\n",
    "\n",
    "append_column(column_ml, \"ML\", daily_data)\n",
    "print(\"\") #supress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ELQ is: [1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0]\n",
      "\n",
      "DLQ is: [12.3, 8.8, 10.7, 1.3, 7.2, 4.4, 5.8]\n",
      "\n",
      "ML is: [0.0, -17.6, -21.4, -2.6, -14.4, -8.8, -5.8]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"ELQ\", \"DLQ\", \"ML\"], daily_data[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EA (Daily data feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_epal = select_column(\"EPAL\", daily_data)\n",
    "column_emal = select_column(\"EMAL\", daily_data)\n",
    "\n",
    "column_ea   = [] \n",
    "for epal, emal in zip(column_epal, column_emal):\n",
    "    column_ea.append(epal+emal)\n",
    "append_column(column_ea, \"EA\", daily_data)\n",
    "print(\"\") #supress output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPAL is: [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "EMAL is: [1.0, 1.0, 0.0, 3.0, 1.0, 2.0, 1.0]\n",
      "\n",
      "EA is: [2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"EPAL\", \"EMAL\", \"EA\"], daily_data[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP (Daily data feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SP = CSD*x1 - PDSQ*x2 + ML*x3 +  DPAL*x4 - EA*x5\n",
    "For this study, all coefficients are taken as equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_csd = select_column(\"CSD\", daily_data)\n",
    "column_pdsq = select_column(\"PDSQ\", daily_data)\n",
    "column_ml = select_column(\"ML\", daily_data)\n",
    "column_dpal = select_column(\"DPAL\", daily_data)\n",
    "column_ea = select_column(\"EA\", daily_data)\n",
    "\n",
    "column_sp = []\n",
    "for csd, pdsq, ml, dpal, ea in zip(column_csd, column_pdsq, column_ml, column_dpal, column_ea):\n",
    "    column_sp.append(1*csd - 1*pdsq + 1*ml + 1*dpal - 1*ea)\n",
    "append_column(column_sp, \"SP\", daily_data)\n",
    "print(\"\") #supress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSD is: [0, 0, 0, 111.5, 80.0, 153.0, 96.0]\n",
      "\n",
      "PDSQ is: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "ML is: [0.0, -17.6, -21.4, -2.6, -14.4, -8.8, -5.8]\n",
      "\n",
      "DPAL is: [5845.0, 7649.0, 5012.0, 2467.0, 2114.0, 2943.0, 2288.0]\n",
      "\n",
      "EA is: [2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0]\n",
      "\n",
      "SP is: [5841.0, 7627.4, 4989.6, 2570.9, 2176.6, 3083.2, 2375.2]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"CSD\", \"PDSQ\", \"ML\", \"DPAL\", \"EA\", \"SP\"], daily_data[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TA (Intake data feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TA = ((ATS + ATBR + 8)/24) * (1-TSC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "column_tsc = select_column(\"TSC\", intake_data)\n",
    "column_ats = select_column(\"ATS\", intake_data)\n",
    "column_atbr = select_column(\"ATBR\", intake_data)\n",
    "\n",
    "column_ta = []\n",
    "for tsc, ats, atbr in zip(column_tsc, column_ats, column_atbr):\n",
    "    column_ta.append(((ats + atbr + 8)/24) * (1-tsc))\n",
    "append_column(column_ta, \"TA\", intake_data)\n",
    "print(\"\") #supress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSC is: [-2.0, -8.0, -16.0, -8.0, -2.0, -18.0, -15.0, -21.0, -3.0, 2.0, -11.0]\n",
      "\n",
      "ATS is: [-7.0, -3.0, -4.0, -1.0, -5.0, -4.0, -3.0, -2.0, -2.0, -3.0, -3.0]\n",
      "\n",
      "ATBR is: [0.0, 4.0, 1.0, 3.0, 3.0, 8.0, 3.0, 11.0, 1.0, 0.0, 7.0]\n",
      "\n",
      "TA is: [0.125, 3.375, 3.541666666666667, 3.75, 0.75, 9.5, 5.333333333333333, 15.583333333333334, 1.1666666666666667, -0.20833333333333334, 6.0]\n"
     ]
    }
   ],
   "source": [
    "print_columns([\"TSC\", \"ATS\", \"ATBR\", \"TA\"], intake_data)\n",
    "# sc_score is the same with tsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data after parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 3 values per column.\n",
      "=============================================================\n",
      "\n",
      "questionnaire_timestamp: datetime.datetime(2017 4 10 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 11 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 12 7 42 47 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "id: 'AB64' 'AB64' 'AB64'\n",
      "bed_time: datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45) datetime.datetime(2017 4 11 23 55)\n",
      "late: 1.0 1.0 1.0\n",
      "late_reason: 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling' '' 'Man kwam thuis en daar wilde ik nog even mee praten'\n",
      "wake_time: datetime.datetime(2017 4 9 9 30) datetime.datetime(2017 4 10 7 0) datetime.datetime(2017 4 11 7 0)\n",
      "sleep_transition: 0.0 0.0 0.0\n",
      "sleep_struggle: 0.0 0.0 0.0\n",
      "night_wake: 0.0 4.0 2.0\n",
      "wake_earlier: 0.0 0.0 0.0\n",
      "wake_earlier_problem: 0.0 0.0 0.0\n",
      "sleep_quality: 2.0 2.0 1.0\n",
      "physical_activity: 1.0 1.0 0.0\n",
      "mental_digital_activity: 1.0 1.0 0.0\n",
      "social_activity: 2.0 2.0 3.0\n",
      "light: 1.0 3.0 3.0\n",
      "presleep_description: 'Theaterbezoek autorit (bijrijder)' 'Tv kijken' 'Poging om Netflix te kijken maar was te moe praten met huisgenoten '\n",
      "temptation_smoking: 0.0 0.0 0.0\n",
      "temptation_eating: 0.0 0.0 0.0\n",
      "temptation_chat: 2.0 0.0 0.0\n",
      "temptation_coffee: 0.0 0.0 0.0\n",
      "temptation_social_media: 2.0 2.0 0.0\n",
      "temptation_internet: 2.0 2.0 0.0\n",
      "temptation_tv: 0.0 0.0 0.0\n",
      "temptation_alcohol: 0.0 2.0 2.0\n",
      "temptation_soft_drink: 0.0 0.0 0.0\n",
      "temptation_cleaning: 0.0 0.0 0.0\n",
      "temptation_shopping: 0.0 0.0 0.0\n",
      "temptation_other: 0.0 0.0 0.0\n",
      "bed_time_plan_aligned: NaT datetime.datetime(2017 4 10 23 0) datetime.datetime(2017 4 11 23 30)\n",
      "steps: 5845.0 7649.0 5012.0\n",
      "active_minutes: 5.0 0.0 3.0\n",
      "sun_hours: 12.3 8.8 10.7\n",
      "temptation_score: 6.0 6.0 2.0\n",
      "ego_depletion: 0.0 0.0 0.0\n",
      "date: datetime.datetime(2017 4 9 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 10 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 11 7 42 47 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "day_of_week: 6.0 0.0 1.0\n",
      "procrastination_minutes: nan 45.0 25.0\n",
      "procrastination_minutes_positive: nan 45.0 25.0\n",
      "procrastination_minutes_positive_15by15: nan 3.0 1.0\n",
      "procrastination_minutes_positive_four_bins: nan 2.0 1.0\n",
      "sleep_transition_minutes_estimated: datetime.timedelta(0 900) datetime.timedelta(0 900) datetime.timedelta(0 900)\n",
      "sleep_minutes: 435.0 420.0 410.0\n",
      "procrastination_minutes_four_day_cumulative_history: nan nan nan\n",
      "procrastination_minutes_three_day_cumulative_history: nan nan nan\n",
      "procrastination_minutes_two_day_cumulative_history: nan nan 70.0\n",
      "procrastination_minutes_positive_four_day_cumulative_history: nan nan nan\n",
      "procrastination_minutes_positive_three_day_cumulative_history: nan nan nan\n",
      "procrastination_minutes_positive_two_day_cumulative_history: nan nan 70.0\n",
      "sleep_minutes_four_day_cumulative_history: nan nan nan\n",
      "sleep_minutes_three_day_cumulative_history: nan nan 1265.0\n",
      "sleep_minutes_two_day_cumulative_history: nan 855.0 830.0\n",
      "sleep_struggle_four_day_cumulative_history: nan nan nan\n",
      "sleep_struggle_three_day_cumulative_history: nan nan 0.0\n",
      "sleep_struggle_two_day_cumulative_history: nan 0.0 0.0\n",
      "night_wake_four_day_cumulative_history: nan nan nan\n",
      "night_wake_three_day_cumulative_history: nan nan 6.0\n",
      "night_wake_two_day_cumulative_history: nan 4.0 6.0\n",
      "sleep_quality_four_day_cumulative_history: nan nan nan\n",
      "sleep_quality_three_day_cumulative_history: nan nan 5.0\n",
      "sleep_quality_two_day_cumulative_history: nan 4.0 3.0\n",
      "social_activity_four_day_cumulative_history: nan nan nan\n",
      "social_activity_three_day_cumulative_history: nan nan 7.0\n",
      "social_activity_two_day_cumulative_history: nan 4.0 5.0\n",
      "light_four_day_cumulative_history: nan nan nan\n",
      "light_three_day_cumulative_history: nan nan 7.0\n",
      "light_two_day_cumulative_history: nan 4.0 6.0\n",
      "temptation_eating_four_day_cumulative_history: nan nan nan\n",
      "temptation_eating_three_day_cumulative_history: nan nan 0.0\n",
      "temptation_eating_two_day_cumulative_history: nan 0.0 0.0\n",
      "temptation_coffee_four_day_cumulative_history: nan nan nan\n",
      "temptation_coffee_three_day_cumulative_history: nan nan 0.0\n",
      "temptation_coffee_two_day_cumulative_history: nan 0.0 0.0\n",
      "temptation_score_four_day_cumulative_history: nan nan nan\n",
      "temptation_score_three_day_cumulative_history: nan nan 14.0\n",
      "temptation_score_two_day_cumulative_history: nan 12.0 8.0\n",
      "procrastination_minutes_three_days_ago: nan nan nan\n",
      "procrastination_minutes_two_days_ago: nan nan nan\n",
      "procrastination_minutes_one_days_ago: nan nan 45.0\n",
      "temptation_score_three_days_ago: nan nan nan\n",
      "temptation_score_two_days_ago: nan nan 6.0\n",
      "temptation_score_one_days_ago: nan 6.0 6.0\n",
      "bed_time_three_days_ago: nan nan nan\n",
      "bed_time_two_days_ago: nan nan datetime.datetime(2017 4 10 2 0)\n",
      "bed_time_one_days_ago: nan datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45)\n",
      "sleep_minutes_three_days_ago: nan nan nan\n",
      "sleep_minutes_two_days_ago: nan nan 435.0\n",
      "sleep_minutes_one_days_ago: nan 435.0 420.0\n",
      "sleep_deficit_change: 45.0 60.0 70.0\n",
      "sleep_deficit_minutes_simple: nan nan nan\n",
      "procrastination_minutes_three_day_weighted_cumulative_history: nan nan nan\n",
      "ELQ: 1.0 3.0 3.0\n",
      "DLQ: 12.3 8.8 10.7\n",
      "DPAL: 5845.0 7649.0 5012.0\n",
      "EPAL: 1.0 1.0 0.0\n",
      "EMAL: 1.0 1.0 0.0\n",
      "PDSQ: 2.0 2.0 1.0\n",
      "BTP: 0 45.0 25.0\n",
      "CSD: 0 0 0\n",
      "ML: 0.0 -17.6 -21.4\n",
      "EA: 2.0 2.0 0.0\n",
      "SP: 5841.0 7627.4 4989.6\n"
     ]
    }
   ],
   "source": [
    "preview_data(daily_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make a class from the dataset to enable easy access to variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Canceled</font> <br>\n",
    "This is intended to enable easy manipulation of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Daily ():\n",
    "#     def __init__(self):\n",
    "#         self.date                      = select_column(\"date\", daily_data)\n",
    "#         self.id                        = select_column(\"id\", daily_data)\n",
    "#         self.bed_time                  = select_column(\"bed_time\", daily_data)\n",
    "#         self.late                      = select_column(\"late\", daily_data)\n",
    "#         self.late_reason               = select_column(\"late_reason\", daily_data)\n",
    "#         self.wake_time                 = select_column(\"wake_time\", daily_data)\n",
    "#         self.sleep_transition          = select_column(\"sleep_transition\", daily_data)\n",
    "#         self.sleep_struggle            = select_column(\"sleep_struggle\", daily_data)\n",
    "#         self.night_wake                = select_column(\"night_wake\", daily_data)\n",
    "#         self.wake_earlier              = select_column(\"wake_earlier\", daily_data)\n",
    "#         self.wake_earlier_problem      = select_column(\"wake_earlier_problem\", daily_data)\n",
    "#         self.sleep_quality             = select_column(\"sleep_quality\", daily_data)\n",
    "#         self.physical_activity         = select_column(\"physical_activity\", daily_data)\n",
    "#         self.mental_digital_activity   = select_column(\"mental_digital_activity\", daily_data)\n",
    "#         self.social_activity           = select_column(\"social_activity\", daily_data)\n",
    "#         self.light                     = select_column(\"light\", daily_data)\n",
    "#         self.presleep_description      = select_column(\"presleep_description\", daily_data)\n",
    "#         self.temptation_smoking        = select_column(\"temptation_smoking\", daily_data)\n",
    "#         self.temptation_eating         = select_column(\"temptation_eating\", daily_data)\n",
    "#         self.temptation_chat           = select_column(\"temptation_chat\", daily_data)\n",
    "#         self.temptation_coffee         = select_column(\"temptation_coffee\", daily_data)\n",
    "#         self.temptation_social_media   = select_column(\"temptation_social_media\", daily_data)\n",
    "#         self.temptation_internet       = select_column(\"temptation_internet\", daily_data)\n",
    "#         self.temptation_tv             = select_column(\"temptation_tv\", daily_data)\n",
    "#         self.temptation_alcohol        = select_column(\"temptation_alcohol\", daily_data)\n",
    "#         self.temptation_soft_drink     = select_column(\"temptation_soft_drink\", daily_data)\n",
    "#         self.temptation_cleaning       = select_column(\"temptation_cleaning\", daily_data)\n",
    "#         self.temptation_shopping       = select_column(\"temptation_shopping\", daily_data)\n",
    "#         self.temptation_other          = select_column(\"temptation_other\", daily_data)\n",
    "#         self.temptation_score          = select_column(\"temptation_score\", daily_data)\n",
    "#         self.procrastination_minutes   = select_column(\"procrastination_minutes\", daily_data),\n",
    "#         self.bed_time_plan             = select_column(\"bed_time_plan\", daily_data)\n",
    "#\n",
    "# daily = Daily()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example uses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print (daily.sleep_quality)\n",
    "# print (daily.light[0:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(daily.bed_time_plan[0])\n",
    "# print(daily.bed_time_plan[0].hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"fitbit-data\"></a>\n",
    "# FITBIT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data, tokenize it, and read it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffActivities', '', '', '', '', '', '', '', '', '']\n",
      "['Date', 'Calories Burned', 'Steps', 'Distance', 'Floors', 'Minutes Sedentary', 'Minutes Lightly Active', 'Minutes Fairly Active', 'Minutes Very Active', 'Activity Calories']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "fitbit_data = list(csv.reader(open(\"data//original_data//fitbit-data.csv\", encoding=\"utf8\")))\n",
    "\n",
    "print(fitbit_data[0])                           # The first row is not a headers row.\n",
    "fitbit_data = fitbit_data[1:len(fitbit_data)]   # It is now a headers row.\n",
    "print(fitbit_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Date', 'Calories Burned', 'Steps', 'Distance', 'Floors', 'Minutes Sedentary', 'Minutes Lightly Active', 'Minutes Fairly Active', 'Minutes Very Active', 'Activity Calories'], ['01/02/2017', '1.716', '0', '0', '0', '1.44', '0', '0', '0', '0'], ['02/02/2017', '1.716', '0', '0', '0', '1.44', '0', '0', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "print(fitbit_data[0:3]) # <-- Print row 2 and 3 of daily dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['date', 'calories_burned', 'steps', 'distance', 'floors', 'minutes_sedentary', 'minutes_lightly_active', 'minutes_fairly_active', 'minutes_very_active', 'activity_calories'], ['01/02/2017', '1.716', '0', '0', '0', '1.44', '0', '0', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "headers_list = [\n",
    "    \"date\", \"calories_burned\", \"steps\", \"distance\", \"floors\", \n",
    "    \"minutes_sedentary\", \"minutes_lightly_active\", \"minutes_fairly_active\", \"minutes_very_active\", \n",
    "    \"activity_calories\"\n",
    "]\n",
    "\n",
    "replace_headers(headers_list, fitbit_data)\n",
    "\n",
    "print(fitbit_data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 8 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: '01/02/2017' '02/02/2017' '03/02/2017' '04/02/2017' '05/02/2017' '06/02/2017' '07/02/2017' '08/02/2017'\n",
      "calories_burned: '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716'\n",
      "steps: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "distance: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "floors: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "minutes_sedentary: '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44'\n",
      "minutes_lightly_active: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "minutes_fairly_active: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "minutes_very_active: '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "activity_calories: '0' '0' '0' '0' '0' '0' '0' '0'\n"
     ]
    }
   ],
   "source": [
    "preview_data(fitbit_data,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "datetime.datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the \"date\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/02/2017\n",
      "02/02/2017\n",
      "03/02/2017\n",
      "04/02/2017\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print_column_vertically(\"date\", fitbit_data[0:5][0:5])\n",
    "print(type(select_column(\"date\", fitbit_data)[0])) # print the type of a date value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-01 00:00:00\n",
      "2017-02-02 00:00:00\n",
      "2017-02-03 00:00:00\n",
      "2017-02-04 00:00:00\n",
      "\n",
      " Type of time is now:\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This function can only be ran once. Once the new values are in the memory, using them as an input will cause an error.\n",
    "# Please re-reun all the previous cells from \"Menu -> Cell -> Run all above to reset the value of the input variable.\n",
    "\n",
    "import datetime\n",
    "\n",
    "date_column = select_column(\"date\", fitbit_data)\n",
    "\n",
    "for i, date in enumerate(date_column): \n",
    "    date_column[i] = datetime.datetime.strptime(date_column[i], \"%d/%m/%Y\")    \n",
    "\n",
    "replace_column(date_column, \"date\", fitbit_data)\n",
    "print_column_vertically(\"date\", fitbit_data[0:5][0:5])\n",
    "\n",
    "print(\"\\n Type of time is now:\")\n",
    "print(type(select_column(\"date\", fitbit_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"date\" column is now parsed/converted into a datetime object from a string. \n",
    "\n",
    "Datetime objecs can be used in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_column[0].day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Values from Strings to Integers and Floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a preview of the data in its current form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 29 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: datetime.datetime(2017 2 1 0 0) datetime.datetime(2017 2 2 0 0) datetime.datetime(2017 2 3 0 0) datetime.datetime(2017 2 4 0 0) datetime.datetime(2017 2 5 0 0) datetime.datetime(2017 2 6 0 0) datetime.datetime(2017 2 7 0 0) datetime.datetime(2017 2 8 0 0) datetime.datetime(2017 2 9 0 0) datetime.datetime(2017 2 10 0 0) datetime.datetime(2017 2 11 0 0) datetime.datetime(2017 2 12 0 0) datetime.datetime(2017 2 13 0 0) datetime.datetime(2017 2 14 0 0) datetime.datetime(2017 2 15 0 0) datetime.datetime(2017 2 16 0 0) datetime.datetime(2017 2 17 0 0) datetime.datetime(2017 2 18 0 0) datetime.datetime(2017 2 19 0 0) datetime.datetime(2017 2 20 0 0) datetime.datetime(2017 2 21 0 0) datetime.datetime(2017 2 22 0 0) datetime.datetime(2017 2 23 0 0) datetime.datetime(2017 2 24 0 0) datetime.datetime(2017 2 25 0 0) datetime.datetime(2017 2 26 0 0) datetime.datetime(2017 2 27 0 0) datetime.datetime(2017 2 28 0 0)\n",
      "calories_burned: '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '1.716' '2.743' '2.406' '2.08' '2.062' '3.52' '2.348' '2.366' '2.524' '2.194' '2.529' '2.595' '1.732' '1.716' '1.716'\n",
      "steps: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '17.507' '9.291' '3.25' '3.25' '19.386' '7.243' '8.618' '10.702' '5.564' '10.293' '11.591' '30' '0' '0'\n",
      "distance: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '8.26' '4.38' '1.53' '1.53' '9.59' '3.42' '4.06' '5.05' '2.62' '4.85' '5.47' '0.01' '0' '0'\n",
      "floors: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '20' '7' '0' '32' '52' '34' '15' '8' '40' '35' '54' '0' '0' '0'\n",
      "minutes_sedentary: '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.44' '1.409' '507' '1.212' '612' '990' '984' '790' '757' '1.199' '1.251' '1.157' '1.11' '1.434' '1.44' '1.44'\n",
      "minutes_lightly_active: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '97' '182' '137' '171' '273' '129' '154' '173' '168' '222' '258' '6' '0' '0'\n",
      "minutes_fairly_active: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '98' '41' '6' '0' '107' '37' '15' '40' '19' '46' '71' '0' '0' '0'\n",
      "minutes_very_active: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '40' '5' '3' '0' '76' '20' '17' '28' '2' '15' '1' '0' '0' '0'\n",
      "activity_calories: '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1.306' '961' '538' '550' '2.347' '854' '872' '1.093' '703' '1.15' '1.273' '22' '0' '0'\n"
     ]
    }
   ],
   "source": [
    "preview_data(fitbit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the data above, some values don't make sense, such as '1.716' as calories_burned 1.7 is too small for a calory burn record, and it is likely to be 1716.\n",
    "- This is also the case for minutes sedentary: 144 instead of 1.44.\n",
    "- This likely means that dots are placed to help reading, but not as decimal indicators. Therefore, dots should be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calories_burned is: ['1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '1716', '2743', '2406', '208', '2062', '352', '2348', '2366', '2524', '2194', '2529', '2595', '1732', '1716', '1716']\n",
      "\n",
      "steps is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '17507', '9291', '325', '325', '19386', '7243', '8618', '10702', '5564', '10293', '11591', '30', '0', '0']\n",
      "\n",
      "distance is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '826', '438', '153', '153', '959', '342', '406', '505', '262', '485', '547', '001', '0', '0']\n",
      "\n",
      "floors is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '20', '7', '0', '32', '52', '34', '15', '8', '40', '35', '54', '0', '0', '0']\n",
      "\n",
      "minutes_sedentary is: ['144', '144', '144', '144', '144', '144', '144', '144', '144', '144', '144', '144', '144', '1409', '507', '1212', '612', '990', '984', '790', '757', '1199', '1251', '1157', '111', '1434', '144', '144']\n",
      "\n",
      "minutes_lightly_active is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '97', '182', '137', '171', '273', '129', '154', '173', '168', '222', '258', '6', '0', '0']\n",
      "\n",
      "minutes_fairly_active is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '98', '41', '6', '0', '107', '37', '15', '40', '19', '46', '71', '0', '0', '0']\n",
      "\n",
      "minutes_very_active is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '40', '5', '3', '0', '76', '20', '17', '28', '2', '15', '1', '0', '0', '0']\n",
      "\n",
      "activity_calories is: ['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1306', '961', '538', '550', '2347', '854', '872', '1093', '703', '115', '1273', '22', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "dot_removal_columns = [\n",
    "    \"calories_burned\", \"steps\", \"distance\", \"floors\",\n",
    "    \"minutes_sedentary\", \"minutes_lightly_active\", \"minutes_fairly_active\", \"minutes_very_active\", \n",
    "    \"activity_calories\"\n",
    "]\n",
    "\n",
    "transform_column_substring(\"\\.\", \"\", dot_removal_columns, fitbit_data)\n",
    "print_columns(dot_removal_columns, fitbit_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dots are out of the way, values can be converted from strings to integers and floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 8 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: datetime.datetime(2017 2 1 0 0) datetime.datetime(2017 2 2 0 0) datetime.datetime(2017 2 3 0 0) datetime.datetime(2017 2 4 0 0) datetime.datetime(2017 2 5 0 0) datetime.datetime(2017 2 6 0 0) datetime.datetime(2017 2 7 0 0) datetime.datetime(2017 2 8 0 0)\n",
      "calories_burned: 1716 1716 1716 1716 1716 1716 1716 1716\n",
      "steps: 0 0 0 0 0 0 0 0\n",
      "distance: 0 0 0 0 0 0 0 0\n",
      "floors: 0 0 0 0 0 0 0 0\n",
      "minutes_sedentary: 144 144 144 144 144 144 144 144\n",
      "minutes_lightly_active: 0 0 0 0 0 0 0 0\n",
      "minutes_fairly_active: 0 0 0 0 0 0 0 0\n",
      "minutes_very_active: 0 0 0 0 0 0 0 0\n",
      "activity_calories: 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "integer_columns = [\n",
    "    \"steps\", \"floors\",\n",
    "    \"minutes_sedentary\", \"minutes_lightly_active\", \"minutes_fairly_active\", \"minutes_very_active\",\n",
    "    \"distance\", \"calories_burned\", \"activity_calories\"\n",
    "    ]\n",
    "\n",
    "transform_column_type(integer_columns, \"int\", fitbit_data) # Transform all strings in these columns to integers\n",
    "preview_data(fitbit_data, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data after parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 3 values per column.\n",
      "=============================================================\n",
      "\n",
      "date: datetime.datetime(2017 2 1 0 0) datetime.datetime(2017 2 2 0 0) datetime.datetime(2017 2 3 0 0)\n",
      "calories_burned: 1716 1716 1716\n",
      "steps: 0 0 0\n",
      "distance: 0 0 0\n",
      "floors: 0 0 0\n",
      "minutes_sedentary: 144 144 144\n",
      "minutes_lightly_active: 0 0 0\n",
      "minutes_fairly_active: 0 0 0\n",
      "minutes_very_active: 0 0 0\n",
      "activity_calories: 0 0 0\n"
     ]
    }
   ],
   "source": [
    "preview_data(fitbit_data,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make a class from the dataset to enable easy access to variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is intended to enable easy manipulation of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Fitbit ():\n",
    "#     def __init__(self):\n",
    "#         self.date                     = select_column(\"date\", fitbit_data)\n",
    "#         self.calories_burned          = select_column(\"calories_burned\", fitbit_data)\n",
    "#         self.steps                    = select_column(\"steps\", fitbit_data)\n",
    "#         self.distance                 = select_column(\"distance\", fitbit_data)\n",
    "#         self.floors                   = select_column(\"floors\", fitbit_data)\n",
    "#         self.minutes_sedentary        = select_column(\"minutes_sedentary\", fitbit_data)\n",
    "#         self.minutes_lightly_active   = select_column(\"minutes_lightly_active\", fitbit_data)\n",
    "#         self.minutes_fairly_active    = select_column(\"minutes_fairly_active\", fitbit_data)\n",
    "#         self.minutes_very_active      = select_column(\"minutes_very_active\", fitbit_data)\n",
    "#         self.activity_calories        = select_column(\"activity_calories\", fitbit_data)        \n",
    "# fitbit = Fitbit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example uses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print (fitbit.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print (fitbit.date[11])\n",
    "# print (fitbit.date[11].day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(fitbit.minutes_fairly_active[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"final-steps\"></a>\n",
    "# IV. Final Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the prepared datasets to CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write intake_data to .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('data//intake_prepared_v2.0b.csv', 'w', newline='')\n",
    "writer = csv.writer(file, delimiter=';', quoting=csv.QUOTE_NONNUMERIC)\n",
    "for row in intake_data:\n",
    "    writer.writerow(row)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the written dataset is the same with the one in the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "test_intake = list(csv.reader(open(\"data//intake_prepared_v2.0b.csv\", encoding=\"utf8\"), delimiter=\";\"))\n",
    "\n",
    "print(len(intake_data) == len(test_intake))\n",
    "print(select_column(\"id\", intake_data) == select_column(\"id\", test_intake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write daily_data to .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = \"data//daily_prepared_v2.0b.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(output_file, 'w', newline='')\n",
    "writer = csv.writer(file, delimiter=';', quoting=csv.QUOTE_NONNUMERIC)\n",
    "for row in daily_data:\n",
    "    writer.writerow(row)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the written dataset is the same with the one in the memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "test_daily = list(csv.reader(open(output_file, encoding=\"utf8\"), delimiter=\";\"))\n",
    "\n",
    "print(len(daily_data) == len(test_daily))\n",
    "print(select_column(\"id\", daily_data) == select_column(\"id\", test_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed Table (Columns in original data => Rows in output)\n",
      "Displaying up to 4 values per column.\n",
      "=============================================================\n",
      "\n",
      "questionnaire_timestamp: datetime.datetime(2017 4 10 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 11 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 12 7 42 47 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 13 8 26 21 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "id: 'AB64' 'AB64' 'AB64' 'AB64'\n",
      "bed_time: datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45) datetime.datetime(2017 4 11 23 55) datetime.datetime(2017 4 13 0 30)\n",
      "late: 1.0 1.0 1.0 1.0\n",
      "late_reason: 'We zijn vanuit het noorden van het land teruggereden naar huis na een theatervoorstelling' '' 'Man kwam thuis en daar wilde ik nog even mee praten' 'Tot laat doorgewerkt.'\n",
      "wake_time: datetime.datetime(2017 4 9 9 30) datetime.datetime(2017 4 10 7 0) datetime.datetime(2017 4 11 7 0) datetime.datetime(2017 4 12 7 0)\n",
      "sleep_transition: 0.0 0.0 0.0 0.0\n",
      "sleep_struggle: 0.0 0.0 0.0 0.0\n",
      "night_wake: 0.0 4.0 2.0 2.0\n",
      "wake_earlier: 0.0 0.0 0.0 0.0\n",
      "wake_earlier_problem: 0.0 0.0 0.0 0.0\n",
      "sleep_quality: 2.0 2.0 1.0 2.0\n",
      "physical_activity: 1.0 1.0 0.0 0.0\n",
      "mental_digital_activity: 1.0 1.0 0.0 3.0\n",
      "social_activity: 2.0 2.0 3.0 1.0\n",
      "light: 1.0 3.0 3.0 3.0\n",
      "presleep_description: 'Theaterbezoek autorit (bijrijder)' 'Tv kijken' 'Poging om Netflix te kijken maar was te moe praten met huisgenoten ' 'Gewerkt achter de pc'\n",
      "temptation_smoking: 0.0 0.0 0.0 0.0\n",
      "temptation_eating: 0.0 0.0 0.0 0.0\n",
      "temptation_chat: 2.0 0.0 0.0 0.0\n",
      "temptation_coffee: 0.0 0.0 0.0 0.0\n",
      "temptation_social_media: 2.0 2.0 0.0 0.0\n",
      "temptation_internet: 2.0 2.0 0.0 0.0\n",
      "temptation_tv: 0.0 0.0 0.0 1.0\n",
      "temptation_alcohol: 0.0 2.0 2.0 1.0\n",
      "temptation_soft_drink: 0.0 0.0 0.0 0.0\n",
      "temptation_cleaning: 0.0 0.0 0.0 0.0\n",
      "temptation_shopping: 0.0 0.0 0.0 0.0\n",
      "temptation_other: 0.0 0.0 0.0 0.0\n",
      "bed_time_plan_aligned: NaT datetime.datetime(2017 4 10 23 0) datetime.datetime(2017 4 11 23 30) datetime.datetime(2017 4 12 23 0)\n",
      "steps: 5845.0 7649.0 5012.0 2467.0\n",
      "active_minutes: 5.0 0.0 3.0 1.0\n",
      "sun_hours: 12.3 8.8 10.7 1.3\n",
      "temptation_score: 6.0 6.0 2.0 2.0\n",
      "ego_depletion: 0.0 0.0 0.0 2.0\n",
      "date: datetime.datetime(2017 4 9 9 57 26 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 10 23 25 39 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 11 7 42 47 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC')) datetime.datetime(2017 4 12 8 26 21 tzinfo=datetime.timezone(datetime.timedelta(0 7200) 'UTC'))\n",
      "day_of_week: 6.0 0.0 1.0 2.0\n",
      "procrastination_minutes: nan 45.0 25.0 90.0\n",
      "procrastination_minutes_positive: nan 45.0 25.0 90.0\n",
      "procrastination_minutes_positive_15by15: nan 3.0 1.0 6.0\n",
      "procrastination_minutes_positive_four_bins: nan 2.0 1.0 3.0\n",
      "sleep_transition_minutes_estimated: datetime.timedelta(0 900) datetime.timedelta(0 900) datetime.timedelta(0 900) datetime.timedelta(0 900)\n",
      "sleep_minutes: 435.0 420.0 410.0 375.0\n",
      "procrastination_minutes_four_day_cumulative_history: nan nan nan nan\n",
      "procrastination_minutes_three_day_cumulative_history: nan nan nan 160.0\n",
      "procrastination_minutes_two_day_cumulative_history: nan nan 70.0 115.0\n",
      "procrastination_minutes_positive_four_day_cumulative_history: nan nan nan nan\n",
      "procrastination_minutes_positive_three_day_cumulative_history: nan nan nan 160.0\n",
      "procrastination_minutes_positive_two_day_cumulative_history: nan nan 70.0 115.0\n",
      "sleep_minutes_four_day_cumulative_history: nan nan nan 1640.0\n",
      "sleep_minutes_three_day_cumulative_history: nan nan 1265.0 1205.0\n",
      "sleep_minutes_two_day_cumulative_history: nan 855.0 830.0 785.0\n",
      "sleep_struggle_four_day_cumulative_history: nan nan nan 0.0\n",
      "sleep_struggle_three_day_cumulative_history: nan nan 0.0 0.0\n",
      "sleep_struggle_two_day_cumulative_history: nan 0.0 0.0 0.0\n",
      "night_wake_four_day_cumulative_history: nan nan nan 8.0\n",
      "night_wake_three_day_cumulative_history: nan nan 6.0 8.0\n",
      "night_wake_two_day_cumulative_history: nan 4.0 6.0 4.0\n",
      "sleep_quality_four_day_cumulative_history: nan nan nan 7.0\n",
      "sleep_quality_three_day_cumulative_history: nan nan 5.0 5.0\n",
      "sleep_quality_two_day_cumulative_history: nan 4.0 3.0 3.0\n",
      "social_activity_four_day_cumulative_history: nan nan nan 8.0\n",
      "social_activity_three_day_cumulative_history: nan nan 7.0 6.0\n",
      "social_activity_two_day_cumulative_history: nan 4.0 5.0 4.0\n",
      "light_four_day_cumulative_history: nan nan nan 10.0\n",
      "light_three_day_cumulative_history: nan nan 7.0 9.0\n",
      "light_two_day_cumulative_history: nan 4.0 6.0 6.0\n",
      "temptation_eating_four_day_cumulative_history: nan nan nan 0.0\n",
      "temptation_eating_three_day_cumulative_history: nan nan 0.0 0.0\n",
      "temptation_eating_two_day_cumulative_history: nan 0.0 0.0 0.0\n",
      "temptation_coffee_four_day_cumulative_history: nan nan nan 0.0\n",
      "temptation_coffee_three_day_cumulative_history: nan nan 0.0 0.0\n",
      "temptation_coffee_two_day_cumulative_history: nan 0.0 0.0 0.0\n",
      "temptation_score_four_day_cumulative_history: nan nan nan 16.0\n",
      "temptation_score_three_day_cumulative_history: nan nan 14.0 10.0\n",
      "temptation_score_two_day_cumulative_history: nan 12.0 8.0 4.0\n",
      "procrastination_minutes_three_days_ago: nan nan nan nan\n",
      "procrastination_minutes_two_days_ago: nan nan nan 45.0\n",
      "procrastination_minutes_one_days_ago: nan nan 45.0 25.0\n",
      "temptation_score_three_days_ago: nan nan nan 6.0\n",
      "temptation_score_two_days_ago: nan nan 6.0 6.0\n",
      "temptation_score_one_days_ago: nan 6.0 6.0 2.0\n",
      "bed_time_three_days_ago: nan nan nan datetime.datetime(2017 4 10 2 0)\n",
      "bed_time_two_days_ago: nan nan datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45)\n",
      "bed_time_one_days_ago: nan datetime.datetime(2017 4 10 2 0) datetime.datetime(2017 4 10 23 45) datetime.datetime(2017 4 11 23 55)\n",
      "sleep_minutes_three_days_ago: nan nan nan 435.0\n",
      "sleep_minutes_two_days_ago: nan nan 435.0 420.0\n",
      "sleep_minutes_one_days_ago: nan 435.0 420.0 410.0\n",
      "sleep_deficit_change: 45.0 60.0 70.0 105.0\n",
      "sleep_deficit_minutes_simple: nan nan nan 280.0\n",
      "procrastination_minutes_three_day_weighted_cumulative_history: nan nan nan 111.5\n",
      "ELQ: 1.0 3.0 3.0 3.0\n",
      "DLQ: 12.3 8.8 10.7 1.3\n",
      "DPAL: 5845.0 7649.0 5012.0 2467.0\n",
      "EPAL: 1.0 1.0 0.0 0.0\n",
      "EMAL: 1.0 1.0 0.0 3.0\n",
      "PDSQ: 2.0 2.0 1.0 2.0\n",
      "BTP: 0 45.0 25.0 90.0\n",
      "CSD: 0 0 0 111.5\n",
      "ML: 0.0 -17.6 -21.4 -2.6\n",
      "EA: 2.0 2.0 0.0 3.0\n",
      "SP: 5841.0 7627.4 4989.6 2570.9\n"
     ]
    }
   ],
   "source": [
    "preview_data(daily_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-10 02:00:00\n",
      "2017-04-10 23:45:00\n",
      "2017-04-11 23:55:00\n",
      "2017-04-13 00:30:00\n",
      "2017-04-14 00:00:00\n",
      "2017-04-15 01:00:00\n",
      "2017-04-15 23:30:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-18 00:30:00\n",
      "2017-04-19 01:00:00\n",
      "2017-04-20 00:30:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 21:30:00\n",
      "2017-04-10 22:15:00\n",
      "2017-04-11 21:40:00\n",
      "2017-04-12 21:15:00\n",
      "2017-04-13 22:00:00\n",
      "2017-04-14 23:15:00\n",
      "2017-04-15 21:15:00\n",
      "2017-04-16 22:00:00\n",
      "2017-04-17 22:15:00\n",
      "2017-04-18 22:00:00\n",
      "2017-04-19 21:30:00\n",
      "2017-04-21 01:00:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 23:15:00\n",
      "2017-04-10 22:00:00\n",
      "2017-04-11 22:15:00\n",
      "2017-04-12 22:15:00\n",
      "2017-04-14 00:00:00\n",
      "2017-04-15 00:00:00\n",
      "2017-04-16 00:15:00\n",
      "2017-04-17 01:30:00\n",
      "2017-04-17 23:15:00\n",
      "2017-04-19 00:00:00\n",
      "2017-04-20 00:00:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-10 03:00:00\n",
      "2017-04-11 01:15:00\n",
      "2017-04-12 02:30:00\n",
      "2017-04-13 05:00:00\n",
      "2017-04-14 04:30:00\n",
      "2017-04-15 03:30:00\n",
      "2017-04-16 03:30:00\n",
      "2017-04-17 04:00:00\n",
      "2017-04-18 01:00:00\n",
      "2017-04-19 04:30:00\n",
      "2017-04-20 04:30:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-10 03:00:00\n",
      "2017-04-11 03:00:00\n",
      "2017-04-12 04:00:00\n",
      "2017-04-13 02:45:00\n",
      "2017-04-14 07:00:00\n",
      "2017-04-15 01:15:00\n",
      "2017-04-16 03:00:00\n",
      "2017-04-17 05:30:00\n",
      "2017-04-18 05:00:00\n",
      "2017-04-19 02:00:00\n",
      "2017-04-20 03:45:00\n",
      "2017-04-21 02:10:00\n",
      "2017-04-22 01:00:00\n",
      "2017-04-23 05:45:00\n",
      "2017-04-24 05:00:00\n",
      "2017-04-25 03:30:00\n",
      "2017-04-26 02:00:00\n",
      "2017-04-27 02:30:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 22:45:00\n",
      "2017-04-10 21:50:00\n",
      "2017-04-11 21:55:00\n",
      "2017-04-12 21:50:00\n",
      "2017-04-13 22:10:00\n",
      "2017-04-14 21:50:00\n",
      "2017-04-15 21:50:00\n",
      "2017-04-16 23:00:00\n",
      "2017-04-17 22:30:00\n",
      "2017-04-18 22:30:00\n",
      "2017-04-19 22:45:00\n",
      "2017-04-20 22:30:00\n",
      "2017-04-22 00:15:00\n",
      "2017-04-23 00:30:00\n",
      "2017-04-23 22:30:00\n",
      "2017-04-24 22:30:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-10 00:00:00\n",
      "2017-04-10 23:00:00\n",
      "2017-04-12 00:00:00\n",
      "2017-04-12 23:30:00\n",
      "2017-04-13 23:15:00\n",
      "2017-04-15 01:00:00\n",
      "2017-04-16 00:30:00\n",
      "2017-04-17 01:30:00\n",
      "2017-04-18 00:15:00\n",
      "2017-04-19 00:15:00\n",
      "2017-04-20 02:00:00\n",
      "2017-04-21 01:00:00\n",
      "2017-04-22 00:00:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 23:45:00\n",
      "2017-04-10 23:30:00\n",
      "2017-04-11 23:45:00\n",
      "2017-04-13 00:45:00\n",
      "2017-04-14 00:15:00\n",
      "2017-04-15 01:00:00\n",
      "2017-04-16 00:20:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-18 00:00:00\n",
      "2017-04-19 02:00:00\n",
      "2017-04-20 01:00:00\n",
      "2017-04-20 23:45:00\n",
      "2017-04-22 00:45:00\n",
      "2017-04-22 23:45:00\n",
      "2017-04-24 00:00:00\n",
      "2017-04-24 23:45:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 23:30:00\n",
      "2017-04-10 23:30:00\n",
      "2017-04-11 23:46:00\n",
      "2017-04-13 02:00:00\n",
      "2017-04-14 00:00:00\n",
      "2017-04-15 00:15:00\n",
      "2017-04-15 23:45:00\n",
      "2017-04-16 23:30:00\n",
      "2017-04-18 00:30:00\n",
      "2017-04-19 00:15:00\n",
      "2017-04-19 23:30:00\n",
      "2017-04-21 01:00:00\n",
      "2017-04-22 00:00:00\n",
      "2017-04-22 23:30:00\n",
      "2017-04-23 23:50:00\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "2017-04-09 23:00:00\n",
      "2017-04-11 00:30:00\n",
      "2017-04-11 23:50:00\n",
      "2017-04-12 23:30:00\n",
      "2017-04-13 23:45:00\n",
      "2017-04-14 23:45:00\n",
      "2017-04-15 23:30:00\n",
      "2017-04-17 00:45:00\n",
      "2017-04-18 00:15:00\n",
      "2017-04-18 23:45:00\n",
      "2017-04-19 23:30:00\n",
      "2017-04-20 23:45:00\n",
      "2017-04-21 23:45:00\n",
      "2017-04-22 23:45:00\n",
      "2017-04-24 02:00:00\n",
      "2017-04-24 23:45:00\n"
     ]
    }
   ],
   "source": [
    "print_column_vertically(\"bed_time_three_days_ago\", daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn data to array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>ON HOLD</font>\n",
    "- May not be necessary if we are to work on Orange\n",
    "- Including additional data types in a numpy array may turn out to be a challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge intake and daily datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>ON HOLD</font>\n",
    "- If intake and daily datasets are merged:\n",
    "    - There will either be many columns with the same name\n",
    "    - Or there will be many rows with the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 12)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(daily_data), len(intake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [1,3]\n",
    "b.insert(4,\"b\")\n",
    "\n",
    "try:\n",
    "    b[10]\n",
    "except IndexError:\n",
    "    print(\"y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
